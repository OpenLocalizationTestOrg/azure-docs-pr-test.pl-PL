---
title: "Wprowadzenie do platformy Spark w usłudze Azure HDInsight | Microsoft Docs"
description: "Ten artykuł przedstawia wprowadzenie do platformy Spark w usłudze HDInsight i różne scenariusze korzystania z klastra Spark w usłudze HDInsight."
keywords: "co to jest apache spark,klaster spark,wprowadzenie do platformy spark,platforma spark w usłudze hdinsight"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: acb80aa98cc978a906ccd6e4b4132a439e505bc8
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 07/11/2017
---
# <a name="introduction-to-spark-on-hdinsight"></a><span data-ttu-id="90ab8-104">Wprowadzenie do platformy Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="90ab8-104">Introduction to Spark on HDInsight</span></span>

<span data-ttu-id="90ab8-105">Ten artykuł przedstawia wprowadzenie do platformy Spark w usłudze HDInsight.</span><span class="sxs-lookup"><span data-stu-id="90ab8-105">This article provides you with an introduction to Spark on HDInsight.</span></span> <span data-ttu-id="90ab8-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> to platforma przetwarzania równoległego typu open source, która obsługuje przetwarzanie w pamięci w celu zwiększania wydajności aplikacji do analizy danych big data.</span><span class="sxs-lookup"><span data-stu-id="90ab8-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="90ab8-107">Klaster Spark w usłudze HDInsight jest zgodny z usługą Azure Storage (WASB) oraz usługą Azure Data Lake Store, co pozwala na łatwe przetwarzanie istniejących danych przechowywanych na platformie Azure za pośrednictwem klastra Spark.</span><span class="sxs-lookup"><span data-stu-id="90ab8-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="90ab8-108">Tworząc klaster Spark w usłudze HDInsight, tworzysz zasoby obliczeniowe platformy Azure z zainstalowaną i skonfigurowaną platformą Spark.</span><span class="sxs-lookup"><span data-stu-id="90ab8-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="90ab8-109">Utworzenie klastra Spark w usłudze HDInsight trwa tylko około 10 minut.</span><span class="sxs-lookup"><span data-stu-id="90ab8-109">It only takes about ten minutes to create a Spark cluster in HDInsight.</span></span> <span data-ttu-id="90ab8-110">Dane, które mają być przetwarzane, są przechowywane w usłudze Azure Storage lub Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="90ab8-110">The data to be processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="90ab8-111">Zobacz temat [Korzystanie z usługi Azure Storage z usługą HDInsight](hdinsight-hadoop-use-blob-storage.md).</span><span class="sxs-lookup"><span data-stu-id="90ab8-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="90ab8-112">**Aby utworzyć klaster Spark w usłudze HDInsight**, zobacz temat [Wprowadzenie: tworzenie klastra Apache Spark w usłudze HDInsight i uruchamianie interakcyjnych zapytań Spark SQL](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="90ab8-112">**To create a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="90ab8-113">Co to jest klaster Apache Spark w usłudze Azure HDInsight?</span><span class="sxs-lookup"><span data-stu-id="90ab8-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="90ab8-114">Klastry Spark w usłudze HDInsight oferują w pełni zarządzaną usługę Spark.</span><span class="sxs-lookup"><span data-stu-id="90ab8-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="90ab8-115">Poniżej przedstawiono korzyści związane z utworzeniem klastra Spark w usłudze HDInsight.</span><span class="sxs-lookup"><span data-stu-id="90ab8-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="90ab8-116">Funkcja</span><span class="sxs-lookup"><span data-stu-id="90ab8-116">Feature</span></span> | <span data-ttu-id="90ab8-117">Opis</span><span class="sxs-lookup"><span data-stu-id="90ab8-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="90ab8-118">Łatwość tworzenia klastrów Spark</span><span class="sxs-lookup"><span data-stu-id="90ab8-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="90ab8-119">Nowy klaster Spark w usłudze HDInsight można utworzyć w kilka minut przy użyciu witryny Azure Portal, programu Azure PowerShell lub zestawu .NET SDK usługi HDInsight.</span><span class="sxs-lookup"><span data-stu-id="90ab8-119">You can create a new Spark cluster on HDInsight in minutes using the Azure Portal, Azure PowerShell, or the HDInsight .NET SDK.</span></span> <span data-ttu-id="90ab8-120">Zobacz temat [Wprowadzenie do klastra Spark w usłudze HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="90ab8-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="90ab8-121">Łatwość obsługi</span><span class="sxs-lookup"><span data-stu-id="90ab8-121">Ease of use</span></span> |<span data-ttu-id="90ab8-122">Klaster Spark w usłudze HDInsight zawiera notesy Jupyter i Zeppelin.</span><span class="sxs-lookup"><span data-stu-id="90ab8-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="90ab8-123">Można ich używać do interakcyjnego przetwarzania danych i wizualizacji.</span><span class="sxs-lookup"><span data-stu-id="90ab8-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="90ab8-124">Interfejsy API REST</span><span class="sxs-lookup"><span data-stu-id="90ab8-124">REST APIs</span></span> |<span data-ttu-id="90ab8-125">Klastry Spark w usłudze HDInsight obejmują [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), czyli serwer zadań Spark oparty na interfejsie API REST do zdalnego przesyłania i monitorowania zadań.</span><span class="sxs-lookup"><span data-stu-id="90ab8-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server to remotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="90ab8-126">Obsługa usługi Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="90ab8-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="90ab8-127">Klaster Spark w usłudze HDInsight można skonfigurować do korzystania z usługi Azure Data Lake Store jako magazynu dodatkowego, a także jako magazynu podstawowego (wyłącznie przy użyciu klastrów HDInsight 3.5).</span><span class="sxs-lookup"><span data-stu-id="90ab8-127">Spark cluster on HDInsight can be configured to use Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="90ab8-128">Aby uzyskać więcej informacji o usłudze Data Lake — magazyn, zobacz temat [Przegląd usługi Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span><span class="sxs-lookup"><span data-stu-id="90ab8-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="90ab8-129">Integracja z usługami Azure</span><span class="sxs-lookup"><span data-stu-id="90ab8-129">Integration with Azure services</span></span> |<span data-ttu-id="90ab8-130">Klaster Spark w usłudze HDInsight zawiera łącznik usługi Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="90ab8-130">Spark cluster on HDInsight comes with a connector to Azure Event Hubs.</span></span> <span data-ttu-id="90ab8-131">Klienci mogą tworzyć aplikacje do przesyłania strumieniowego przy użyciu usługi Event Hubs w uzupełnieniu do oprogramowania [Kafka](http://kafka.apache.org/), które jest już dostępne w ramach platformy Spark.</span><span class="sxs-lookup"><span data-stu-id="90ab8-131">Customers can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="90ab8-132">Obsługa platformy R Server</span><span class="sxs-lookup"><span data-stu-id="90ab8-132">Support for R Server</span></span> | <span data-ttu-id="90ab8-133">Możesz skonfigurować platformę R Server w klastrze Spark w usłudze HDInsight, aby uruchamiać rozproszone obliczenia R z szybkością zapewnianą przez klaster Spark.</span><span class="sxs-lookup"><span data-stu-id="90ab8-133">You can set up a R Server on HDInsight Spark cluster to run distributed R computations with the speeds promised with a Spark cluster.</span></span> <span data-ttu-id="90ab8-134">Aby uzyskać więcej informacji, zobacz temat [Rozpoczęcie pracy z platformą R Server w usłudze HDInsight](hdinsight-hadoop-r-server-get-started.md).</span><span class="sxs-lookup"><span data-stu-id="90ab8-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="90ab8-135">Integracja ze zintegrowanymi środowiskami projektowymi innych firm</span><span class="sxs-lookup"><span data-stu-id="90ab8-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="90ab8-136">Usługa HDInsight zapewnia wtyczki dla takich zintegrowanych środowisk projektowych, jak IntelliJ IDEA i Eclipse, które umożliwiają tworzenie i przesyłanie aplikacji do klastra Spark w usłudze HDInsight.</span><span class="sxs-lookup"><span data-stu-id="90ab8-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use to create and submit applications to an HDInsight Spark cluster.</span></span> <span data-ttu-id="90ab8-137">Aby uzyskać więcej informacji, zobacz tematy [Korzystanie z zestawu narzędzi platformy Azure dla środowiska IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) i [Korzystanie z zestawu narzędzi platformy Azure dla środowiska Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span><span class="sxs-lookup"><span data-stu-id="90ab8-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="90ab8-138">Zapytania jednoczesne</span><span class="sxs-lookup"><span data-stu-id="90ab8-138">Concurrent Queries</span></span> |<span data-ttu-id="90ab8-139">Klastry Spark w usłudze HDInsight obsługują zapytania jednoczesne.</span><span class="sxs-lookup"><span data-stu-id="90ab8-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="90ab8-140">Dzięki temu wielu zapytań od jednego użytkownika lub wiele zapytań od różnych użytkowników i aplikacji może współdzielić te same zasoby klastra.</span><span class="sxs-lookup"><span data-stu-id="90ab8-140">This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</span></span> |
| <span data-ttu-id="90ab8-141">Buforowanie na dyskach SSD</span><span class="sxs-lookup"><span data-stu-id="90ab8-141">Caching on SSDs</span></span> |<span data-ttu-id="90ab8-142">Istnieje możliwość buforowania danych w pamięci lub na dyskach SSD podłączonych do węzłów klastra.</span><span class="sxs-lookup"><span data-stu-id="90ab8-142">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</span></span> <span data-ttu-id="90ab8-143">Buforowanie w pamięci zapewnia najlepszą wydajność zapytań, ale może być kosztowne. Buforowanie na dyskach SSD stanowi doskonałe rozwiązanie umożliwiające poprawę wydajności zapytań bez konieczności tworzenia klastra o rozmiarze obejmującym cały zestaw danych w pamięci.</span><span class="sxs-lookup"><span data-stu-id="90ab8-143">Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</span></span> |
| <span data-ttu-id="90ab8-144">Integracja z narzędziami do analizy biznesowej</span><span class="sxs-lookup"><span data-stu-id="90ab8-144">Integration with BI Tools</span></span> |<span data-ttu-id="90ab8-145">Klastry Spark w usłudze HDInsight zawierają łączniki dla narzędzi do analizy biznesowej danych, takich jak [Power BI](http://www.powerbi.com/) i [Tableau](http://www.tableau.com/products/desktop).</span><span class="sxs-lookup"><span data-stu-id="90ab8-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="90ab8-146">Wstępnie załadowane biblioteki Anaconda</span><span class="sxs-lookup"><span data-stu-id="90ab8-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="90ab8-147">Klastry Spark w usłudze HDInsight są dostarczane z wstępnie zainstalowanymi bibliotekami Anaconda.</span><span class="sxs-lookup"><span data-stu-id="90ab8-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="90ab8-148">Platforma [Anaconda](http://docs.continuum.io/anaconda/) dostarcza prawie 200 bibliotek do uczenia maszynowego, analizy danych, wizualizacji itp.</span><span class="sxs-lookup"><span data-stu-id="90ab8-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="90ab8-149">Skalowalność</span><span class="sxs-lookup"><span data-stu-id="90ab8-149">Scalability</span></span> |<span data-ttu-id="90ab8-150">Chociaż można określić liczbę węzłów w klastrze podczas tworzenia, przydatna może okazać się możliwość zwiększania i zmniejszania klastra w celu dopasowania go do obciążeń.</span><span class="sxs-lookup"><span data-stu-id="90ab8-150">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</span></span> <span data-ttu-id="90ab8-151">Wszystkie klastry usługi HDInsight umożliwiają zmianę liczby węzłów w klastrze.</span><span class="sxs-lookup"><span data-stu-id="90ab8-151">All HDInsight clusters allow you to change the number of nodes in the cluster.</span></span> <span data-ttu-id="90ab8-152">Ponadto klastry Spark można porzucić bez utraty danych, ponieważ wszystkie dane są przechowywane w usłudze Azure Storage lub Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="90ab8-152">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="90ab8-153">Całodobowa pomoc techniczna</span><span class="sxs-lookup"><span data-stu-id="90ab8-153">24/7 Support</span></span> |<span data-ttu-id="90ab8-154">Oferta klastrów Spark w usłudze HDInsight obejmuje całodobową pomoc techniczną dla przedsiębiorstw oraz umowę SLA gwarantującą 99,9% czasu działania.</span><span class="sxs-lookup"><span data-stu-id="90ab8-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-the-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="90ab8-155">Jakie są przypadki użycia platformy Spark w usłudze HDInsight?</span><span class="sxs-lookup"><span data-stu-id="90ab8-155">What are the use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="90ab8-156">Klastry Spark w usłudze HDInsight umożliwiają realizację następujących głównych scenariuszy.</span><span class="sxs-lookup"><span data-stu-id="90ab8-156">Spark clusters in HDInsight enable the following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="90ab8-157">Interakcyjna analiza danych i analiza biznesowa</span><span class="sxs-lookup"><span data-stu-id="90ab8-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="90ab8-158">Zobacz samouczek</span><span class="sxs-lookup"><span data-stu-id="90ab8-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="90ab8-159">Klaster Apache Spark w usłudze HDInsight przechowuje dane w usłudze Azure Storage lub Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="90ab8-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="90ab8-160">Eksperci biznesowi i osoby podejmujące kluczowe decyzje mogą analizować i tworzyć raporty na podstawie danych oraz korzystać z usługi Microsoft Power BI w celu sporządzania interakcyjnych raportów na podstawie analizowanych danych.</span><span class="sxs-lookup"><span data-stu-id="90ab8-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</span></span> <span data-ttu-id="90ab8-161">Analitycy mogą rozpocząć pracę od danych o częściowej strukturze lub bez struktury w magazynie klastra, zdefiniować schemat danych za pomocą notesów, a następnie skompilować modele danych przy użyciu usługi Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="90ab8-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for the data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="90ab8-162">Klastry Spark w usłudze HDInsight obsługują również wiele narzędzi do analizy biznesowej innych firm, takich jak Tableau, dzięki czemu platforma Spark jest idealnym wyborem dla analityków danych, ekspertów biznesowych i osób podejmujących kluczowe decyzje.</span><span class="sxs-lookup"><span data-stu-id="90ab8-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="90ab8-163">Spark Machine Learning</span><span class="sxs-lookup"><span data-stu-id="90ab8-163">Spark Machine Learning</span></span>
[<span data-ttu-id="90ab8-164">Zobacz samouczek: przewidywanie temperatur w budynkach z użyciem danych HVAC</span><span class="sxs-lookup"><span data-stu-id="90ab8-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="90ab8-165">Zobacz samouczek: przewidywanie wyników inspekcji żywności</span><span class="sxs-lookup"><span data-stu-id="90ab8-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="90ab8-166">Platforma Apache Spark jest dostarczana z biblioteką [MLlib](http://spark.apache.org/mllib/) do uczenia maszynowego opartą na platformie Spark, której można używać z klastra Spark w usłudze HDInsight.</span><span class="sxs-lookup"><span data-stu-id="90ab8-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="90ab8-167">Klaster Spark w usłudze HDInsight obejmuje również platformę Anaconda — dystrybucję oprogramowania Python z szeregiem różnych pakietów do uczenia maszynowego.</span><span class="sxs-lookup"><span data-stu-id="90ab8-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="90ab8-168">W połączeniu z wbudowaną obsługą notesów Jupyter i Zeppelin platforma zapewnia najwyższej jakości środowisko do tworzenia aplikacji do uczenia maszynowego.</span><span class="sxs-lookup"><span data-stu-id="90ab8-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="90ab8-169">Przesyłanie strumieniowe i analiza danych w czasie rzeczywistym na platformie Spark</span><span class="sxs-lookup"><span data-stu-id="90ab8-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="90ab8-170">Zobacz samouczek</span><span class="sxs-lookup"><span data-stu-id="90ab8-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="90ab8-171">Klastry Spark w usłudze HDInsight zapewniają szeroką obsługę tworzenia rozwiązań do analizy w czasie rzeczywistym.</span><span class="sxs-lookup"><span data-stu-id="90ab8-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="90ab8-172">Platforma Spark jest już wyposażona w łączniki do przyjmowania danych z wielu źródeł, takich jak Kafka, Flume, Twitter, ZeroMQ lub gniazda TCP, a ponadto platforma Spark w usłudze HDInsight oferuje wysokiej klasy obsługę pobierania danych z usługi Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="90ab8-172">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="90ab8-173">Event Hubs to najczęściej używana usługa kolejkowania w systemie Azure.</span><span class="sxs-lookup"><span data-stu-id="90ab8-173">Event Hubs are the most widely used queuing service on Azure.</span></span> <span data-ttu-id="90ab8-174">Wbudowana obsługa centrum zdarzeń sprawia, że klastry Spark w usłudze HDInsight stanowią idealną platformę do tworzenia potoku analizy w czasie rzeczywistym.</span><span class="sxs-lookup"><span data-stu-id="90ab8-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="90ab8-175"><a name="next-steps"></a>Jakie składniki wchodzą w skład klastra Spark?</span><span class="sxs-lookup"><span data-stu-id="90ab8-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="90ab8-176">Klastry Spark w usłudze HDInsight obejmują następujące składniki, które są domyślnie dostępne w klastrach.</span><span class="sxs-lookup"><span data-stu-id="90ab8-176">Spark clusters in HDInsight include the following components that are available on the clusters by default.</span></span>

* <span data-ttu-id="90ab8-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="90ab8-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="90ab8-178">Obejmuje takie składniki, jak Spark Core, Spark SQL, interfejsy API przesyłania strumieniowego Spark, GraphX oraz MLlib.</span><span class="sxs-lookup"><span data-stu-id="90ab8-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="90ab8-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="90ab8-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="90ab8-180">Livy</span><span class="sxs-lookup"><span data-stu-id="90ab8-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="90ab8-181">Notes Jupyter</span><span class="sxs-lookup"><span data-stu-id="90ab8-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="90ab8-182">Notes Zeppelin</span><span class="sxs-lookup"><span data-stu-id="90ab8-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="90ab8-183">Klastry Spark w usłudze HDInsight obejmują też [sterownik ODBC](http://go.microsoft.com/fwlink/?LinkId=616229) zapewniający łączność z klastrami Spark w usłudze HDInsight z poziomu narzędzi do analizy biznesowej, takich jak Microsoft Power BI i Tableau.</span><span class="sxs-lookup"><span data-stu-id="90ab8-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="90ab8-184">Od czego zacząć?</span><span class="sxs-lookup"><span data-stu-id="90ab8-184">Where do I start?</span></span>
<span data-ttu-id="90ab8-185">Rozpocznij od utworzenia klastra Spark w usłudze HDInsight.</span><span class="sxs-lookup"><span data-stu-id="90ab8-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="90ab8-186">Zobacz temat [Wprowadzenie: tworzenie klastra Apache Spark w usłudze HDInsight i uruchamianie interakcyjnych zapytań Spark SQL](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="90ab8-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="90ab8-187">Następne kroki</span><span class="sxs-lookup"><span data-stu-id="90ab8-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="90ab8-188">Scenariusze</span><span class="sxs-lookup"><span data-stu-id="90ab8-188">Scenarios</span></span>
* [<span data-ttu-id="90ab8-189">Platforma Spark i analiza biznesowa: interakcyjna analiza danych na platformie Spark w usłudze HDInsight z użyciem narzędzi do analizy biznesowej</span><span class="sxs-lookup"><span data-stu-id="90ab8-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="90ab8-190">Platforma Spark i usługa Machine Learning: korzystanie z platformy Spark w usłudze HDInsight do analizy temperatury w budynku z użyciem danych HVAC</span><span class="sxs-lookup"><span data-stu-id="90ab8-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="90ab8-191">Platforma Spark i usługa Machine Learning: korzystanie z platformy Spark w usłudze HDInsight do przewidywania wyników kontroli żywności</span><span class="sxs-lookup"><span data-stu-id="90ab8-191">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="90ab8-192">Przesyłanie strumieniowe Spark: korzystanie z platformy Spark w usłudze HDInsight do tworzenia aplikacji do przesyłania strumieniowego w czasie rzeczywistym</span><span class="sxs-lookup"><span data-stu-id="90ab8-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="90ab8-193">Analiza dzienników witryny sieci Web na platformie Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="90ab8-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="90ab8-194">Tworzenie i uruchamianie aplikacji</span><span class="sxs-lookup"><span data-stu-id="90ab8-194">Create and run applications</span></span>
* [<span data-ttu-id="90ab8-195">Tworzenie autonomicznych aplikacji przy użyciu języka Scala</span><span class="sxs-lookup"><span data-stu-id="90ab8-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="90ab8-196">Zdalne uruchamianie zadań w klastrze Spark przy użyciu programu Livy</span><span class="sxs-lookup"><span data-stu-id="90ab8-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="90ab8-197">Narzędzia i rozszerzenia</span><span class="sxs-lookup"><span data-stu-id="90ab8-197">Tools and extensions</span></span>
* [<span data-ttu-id="90ab8-198">Tworzenie i przesyłanie aplikacji Spark Scala przy użyciu dodatku HDInsight Tools Plugin for IntelliJ IDEA</span><span class="sxs-lookup"><span data-stu-id="90ab8-198">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="90ab8-199">Zdalne debugowanie aplikacji Spark przy użyciu dodatku HDInsight Tools Plugin for IntelliJ IDEA</span><span class="sxs-lookup"><span data-stu-id="90ab8-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="90ab8-200">Korzystanie z notesów Zeppelin w klastrze Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="90ab8-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="90ab8-201">Jądra dostępne dla notesu Jupyter w klastrze Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="90ab8-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="90ab8-202">Korzystanie z zewnętrznych pakietów z notesami Jupyter</span><span class="sxs-lookup"><span data-stu-id="90ab8-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="90ab8-203">Instalacja oprogramowania Jupyter na komputerze i nawiązywanie połączenia z klastrem Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="90ab8-203">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="90ab8-204">Zarządzanie zasobami</span><span class="sxs-lookup"><span data-stu-id="90ab8-204">Manage resources</span></span>
* [<span data-ttu-id="90ab8-205">Zarządzanie zasobami klastra Apache Spark w usłudze Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="90ab8-205">Manage resources for the Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="90ab8-206">Śledzenie i debugowanie zadań uruchamianych w klastrze Apache Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="90ab8-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="90ab8-207">[Znane problemy dotyczące platformy Apache Spark w usłudze Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span><span class="sxs-lookup"><span data-stu-id="90ab8-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>

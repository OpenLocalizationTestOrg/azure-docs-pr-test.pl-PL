---
title: "klastry aaaKernels dla notesu Jupyter na Spark w usłudze Azure HDInsight | Dokumentacja firmy Microsoft"
description: "Więcej informacji na temat hello jądra PySpark, PySpark3 i Spark dla notesu Jupyter dostępne z klastrami Spark w usłudze Azure HDInsight."
keywords: notesu jupyter na spark, jupyter spark
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="fd6fd-104">Jądra dla notesu Jupyter w klastrze Spark w usłudze Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd6fd-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="fd6fd-105">Klastry HDInsight Spark zapewniają jądra, których można używać do testowania aplikacji z notesu Jupyter hello na Spark.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="fd6fd-106">Jądra to program, który uruchamia i interpretuje kodu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="fd6fd-107">są trzy jądra Hello:</span><span class="sxs-lookup"><span data-stu-id="fd6fd-107">hello three kernels are:</span></span>

- <span data-ttu-id="fd6fd-108">**PySpark** — dla aplikacji napisanych w Python2</span><span class="sxs-lookup"><span data-stu-id="fd6fd-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="fd6fd-109">**PySpark3** — dla aplikacji napisanych w Python3</span><span class="sxs-lookup"><span data-stu-id="fd6fd-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="fd6fd-110">**Platforma Spark** — dla aplikacji napisanych w języku Scala</span><span class="sxs-lookup"><span data-stu-id="fd6fd-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="fd6fd-111">W tym artykule dowiesz się, jak toouse te jądra i hello zalety korzystania z nich.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="fd6fd-112">Wymagania wstępne</span><span class="sxs-lookup"><span data-stu-id="fd6fd-112">Prerequisites</span></span>

* <span data-ttu-id="fd6fd-113">Klaster Apache Spark w usłudze HDInsight.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="fd6fd-114">Aby uzyskać instrukcje, zobacz [klastrów utworzyć Apache Spark w usłudze Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="fd6fd-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="fd6fd-115">Tworzenie notesu Jupyter w usłudze HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="fd6fd-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="fd6fd-116">Z hello [portalu Azure](https://portal.azure.com/), otwórz klastra.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="fd6fd-117">Zobacz [klastrów listy i Pokaż](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) hello instrukcje.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="fd6fd-118">klaster Hello jest otwarty w nowym bloku portalu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="fd6fd-119">Z hello **szybkie linki** kliknij **klastra pulpity nawigacyjne** tooopen hello **klastra pulpity nawigacyjne** bloku.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="fd6fd-120">Jeśli nie widzisz **szybkie linki**, kliknij przycisk **omówienie** z menu po lewej stronie powitania na powitania bloku.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="fd6fd-121">![Notesu Jupyter na Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "notesu Jupyter na Spark")</span><span class="sxs-lookup"><span data-stu-id="fd6fd-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="fd6fd-122">Kliknij przycisk **notesu Jupyter**.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="fd6fd-123">Jeśli zostanie wyświetlony monit, wprowadź poświadczenia administratora hello hello klastra.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="fd6fd-124">Można również przejść hello notesu Jupyter w klastrze Spark przy hello otwarcia następującego adresu URL w przeglądarce.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="fd6fd-125">Zastąp **CLUSTERNAME** o nazwie hello klastra:</span><span class="sxs-lookup"><span data-stu-id="fd6fd-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="fd6fd-126">Kliknij przycisk **nowy**, a następnie kliknij opcję **Pyspark**, **PySpark3**, lub **Spark** toocreate notesu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="fd6fd-127">Użyj hello jądra Spark Scala aplikacji jądra PySpark Python2 aplikacji i PySpark3 jądra dla Python3 aplikacji.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="fd6fd-128">![Jądra dla notesu Jupyter na Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "jądra dla notesu Jupyter na Spark")</span><span class="sxs-lookup"><span data-stu-id="fd6fd-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="fd6fd-129">Otwiera notes z hello jądra, które wybrano.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="fd6fd-130">Zalety używania hello jądra</span><span class="sxs-lookup"><span data-stu-id="fd6fd-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="fd6fd-131">Poniżej przedstawiono kilka korzyści wynikające ze stosowania nowych jądra hello z notesu Jupyter w klastrach Spark HDInsight.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="fd6fd-132">**Ustawienie wstępne kontekstów**.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-132">**Preset contexts**.</span></span> <span data-ttu-id="fd6fd-133">Z **PySpark**, **PySpark3**, lub hello **Spark** jądra, nie trzeba konteksty Spark i Hive hello tooset jawnie przed rozpoczęciem pracy z aplikacjami.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="fd6fd-134">Są one dostępne domyślnie.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-134">These are available by default.</span></span> <span data-ttu-id="fd6fd-135">Konteksty te są:</span><span class="sxs-lookup"><span data-stu-id="fd6fd-135">These contexts are:</span></span>
   
   * <span data-ttu-id="fd6fd-136">**sc** — Spark kontekstu</span><span class="sxs-lookup"><span data-stu-id="fd6fd-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="fd6fd-137">**Element sqlContext** — dla kontekstu gałęzi</span><span class="sxs-lookup"><span data-stu-id="fd6fd-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="fd6fd-138">Nie masz, instrukcje toorun, takie jak powitania po kontekstów hello tooset:</span><span class="sxs-lookup"><span data-stu-id="fd6fd-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="fd6fd-139">sc = element sqlContext SparkContext('yarn-client') = HiveContext(sc)</span><span class="sxs-lookup"><span data-stu-id="fd6fd-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="fd6fd-140">Zamiast tego możesz bezpośrednio użyć hello ustawienia wstępnego kontekstów w aplikacji.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="fd6fd-141">**Komórki poleceń magicznych**.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-141">**Cell magics**.</span></span> <span data-ttu-id="fd6fd-142">Witaj jądra PySpark zawiera kilka wstępnie zdefiniowanych "poleceń magicznych", które są specjalne polecenia, które można wywoływać z `%%` (na przykład `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="fd6fd-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="fd6fd-143">polecenie magic Hello musi być hello pierwsze słowo w komórce kodu i mogą zostać w wielu wierszach zawartości.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="fd6fd-144">Hello magic word powinna być hello pierwsze słowo w komórce hello.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="fd6fd-145">Dodawanie czegokolwiek przed magic hello, nawet komentarzy powoduje błąd.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="fd6fd-146">Aby uzyskać więcej informacji dotyczących poleceń magicznych, zobacz [tutaj](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="fd6fd-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="fd6fd-147">Witaj poniższej tabeli wymieniono hello różnych poleceń magicznych dostępnych za pośrednictwem hello jądra.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="fd6fd-148">Magiczna</span><span class="sxs-lookup"><span data-stu-id="fd6fd-148">Magic</span></span> | <span data-ttu-id="fd6fd-149">Przykład</span><span class="sxs-lookup"><span data-stu-id="fd6fd-149">Example</span></span> | <span data-ttu-id="fd6fd-150">Opis</span><span class="sxs-lookup"><span data-stu-id="fd6fd-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="fd6fd-151">Pomoc</span><span class="sxs-lookup"><span data-stu-id="fd6fd-151">help</span></span> |`%%help` |<span data-ttu-id="fd6fd-152">Generuje spis wszystkich hello dostępnych poleceń magicznych przykład i opis</span><span class="sxs-lookup"><span data-stu-id="fd6fd-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="fd6fd-153">Informacje o</span><span class="sxs-lookup"><span data-stu-id="fd6fd-153">info</span></span> |`%%info` |<span data-ttu-id="fd6fd-154">Dane wyjściowe informacji o sesji dla punktu końcowego hello bieżącego Livy</span><span class="sxs-lookup"><span data-stu-id="fd6fd-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="fd6fd-155">Konfigurowanie</span><span class="sxs-lookup"><span data-stu-id="fd6fd-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="fd6fd-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="fd6fd-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="fd6fd-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="fd6fd-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="fd6fd-158">Konfiguruje parametry hello w celu utworzenia sesji.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="fd6fd-159">Witaj flagi force (-f) jest wymagane, jeśli sesja została już utworzona, co zapewnia sesji hello jest porzucenia i ponownego utworzenia.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="fd6fd-160">Przyjrzyj się [/sessions POST Livy w treści żądania](https://github.com/cloudera/livy#request-body) listę prawidłowych parametrów.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="fd6fd-161">Parametry muszą być przekazywane w postaci ciągu JSON i musi być w następnym wierszu powitania po hello magic, jak pokazano w kolumnie przykład hello.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="fd6fd-162">SQL</span><span class="sxs-lookup"><span data-stu-id="fd6fd-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="fd6fd-163">Wykonuje zapytanie Hive względem element sqlContext hello.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="fd6fd-164">Jeśli hello `-o` parametr jest przekazywany, w hello jest trwały hello wynik zapytania hello %% lokalny kontekst Python jako [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="fd6fd-165">lokalne</span><span class="sxs-lookup"><span data-stu-id="fd6fd-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="fd6fd-166">Cały kod hello w kolejnych wierszy jest wykonywana lokalnie.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="fd6fd-167">Kod musi być prawidłowym kodem Python2 nawet niezależnie od jądra hello, którego używasz.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="fd6fd-168">Tak, nawet w przypadku wybrania **PySpark3** lub **Spark** jądra podczas tworzenia notesu hello, jeśli używasz hello `%%local` magic w komórce, tej komórki musi mieć tylko prawidłowy kod Python2...</span><span class="sxs-lookup"><span data-stu-id="fd6fd-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="fd6fd-169">dzienniki</span><span class="sxs-lookup"><span data-stu-id="fd6fd-169">logs</span></span> |`%%logs` |<span data-ttu-id="fd6fd-170">Dane wyjściowe hello dzienniki dla bieżącej sesji programu Livy hello.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="fd6fd-171">Usuń</span><span class="sxs-lookup"><span data-stu-id="fd6fd-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="fd6fd-172">Usuwa określonej sesji hello bieżący punkt końcowy programu Livy.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="fd6fd-173">Należy pamiętać, że nie można usunąć sesji hello inicjowane dla jądra hello, sama.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="fd6fd-174">Czyszczenie</span><span class="sxs-lookup"><span data-stu-id="fd6fd-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="fd6fd-175">Usuwa wszystkie sesje hello hello bieżącego Livy punktu końcowego, łącznie z sesji tego notesu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="fd6fd-176">Wymuś Hello flagi -f jest obowiązkowe.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="fd6fd-177">Ponadto poleceń magicznych toohello dodane przez hello jądra PySpark, można również użyć hello [wbudowanych IPython poleceń magicznych](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), takie jak `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="fd6fd-178">Można użyć hello `%%sh` Magiczna toorun skryptów i blok kodu na powitania headnode klastra.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="fd6fd-179">**Automatyczna wizualizacja**.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-179">**Auto visualization**.</span></span> <span data-ttu-id="fd6fd-180">Witaj **Pyspark** jądra automatycznie wizualizuje hello dane wyjściowe zapytań Hive i SQL.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="fd6fd-181">Można wybrać kilka różnych typów wizualizacji, łącznie z tabeli, kołowego, wiersza, obszar, paska.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="fd6fd-182">Parametry są obsługiwane z hello %% sql magic</span><span class="sxs-lookup"><span data-stu-id="fd6fd-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="fd6fd-183">Witaj `%%sql` magic obsługuje parametry, których można używać typu hello toocontrol wyjściowego, który jest wyświetlany podczas uruchamiania kwerend.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="fd6fd-184">Witaj w poniższej tabeli wymieniono hello danych wyjściowych.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="fd6fd-185">Parametr</span><span class="sxs-lookup"><span data-stu-id="fd6fd-185">Parameter</span></span> | <span data-ttu-id="fd6fd-186">Przykład</span><span class="sxs-lookup"><span data-stu-id="fd6fd-186">Example</span></span> | <span data-ttu-id="fd6fd-187">Opis</span><span class="sxs-lookup"><span data-stu-id="fd6fd-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="fd6fd-188">-o</span><span class="sxs-lookup"><span data-stu-id="fd6fd-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="fd6fd-189">Użyj tego parametru toopersist hello wyniku zapytania hello w hello %% lokalny kontekst Python, jako [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="fd6fd-190">Nazwa Hello zmiennej dataframe hello jest hello nazwę zmiennej, które określisz.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="fd6fd-191">-q</span><span class="sxs-lookup"><span data-stu-id="fd6fd-191">-q</span></span> |`-q` |<span data-ttu-id="fd6fd-192">Użyj tego tooturn poza wizualizacjami hello komórki.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="fd6fd-193">Jeśli nie chcesz tooauto-wizualizacji hello zawartość komórki, a jedynie chcesz toocapture go jako dataframe, następnie użyć `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="fd6fd-194">Jeśli chcesz tooturn poza wizualizacjami bez Przechwytywanie hello wyników (na przykład do uruchomienia zapytania SQL, tak samo, jak `CREATE TABLE` instrukcji), użyj `-q` bez określania `-o` argumentu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="fd6fd-195">-m</span><span class="sxs-lookup"><span data-stu-id="fd6fd-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="fd6fd-196">Gdzie **— metoda** jest **zająć** lub **próbki** (domyślnie jest **zająć**).</span><span class="sxs-lookup"><span data-stu-id="fd6fd-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="fd6fd-197">Jeśli metoda hello jest **zająć**, jądra hello wybiera elementy z góry hello zestawu danych wyników hello określony przez maksymalna liczba wierszy (opisane w dalszej części tej tabeli).</span><span class="sxs-lookup"><span data-stu-id="fd6fd-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="fd6fd-198">Jeśli metoda hello jest **próbki**, jądra hello losowo przykłady elementy hello zestawu danych zgodnie z zbyt`-r` parametru opisane dalej w tej tabeli.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="fd6fd-199">-r</span><span class="sxs-lookup"><span data-stu-id="fd6fd-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="fd6fd-200">W tym miejscu **UŁAMEK** jest liczba zmiennoprzecinkowa od 0,0 do 1,0.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="fd6fd-201">Jeśli hello przykładowej metody dla zapytania SQL hello jest `sample`, a następnie jądra hello losowo przykłady hello określona część hello elementy hello zestawu wyników dla należy.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="fd6fd-202">Na przykład, jeśli uruchomienie zapytania SQL z argumentami hello `-m sample -r 0.01`, następnie losowo próbkowanych 1% hello wynik wierszy.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="fd6fd-203">**Maksymalna liczba wierszy** jest wartością całkowitą.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="fd6fd-204">jądra Hello ogranicza hello liczby wierszy danych wyjściowych za**maksymalna liczba wierszy**.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="fd6fd-205">Jeśli **maksymalna liczba wierszy** jest liczbą ujemną, takich jak **-1**, a następnie hello liczbę wierszy w zestawie wyników hello nie jest ograniczona.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="fd6fd-206">**Przykład:**</span><span class="sxs-lookup"><span data-stu-id="fd6fd-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="fd6fd-207">Instrukcja Hello powyżej hello następujące:</span><span class="sxs-lookup"><span data-stu-id="fd6fd-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="fd6fd-208">Wybiera wszystkie rekordy z **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="fd6fd-209">Ponieważ używamy - q, wyłącza automatyczne wizualizacji.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="fd6fd-210">Ponieważ używamy `-m sample -r 0.1 -n 500` losowo przykłady 10% hello wierszy w hello hivesampletable i limity hello rozmiar hello wynik zestaw too500 wierszy.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="fd6fd-211">Ponadto ponieważ użyliśmy `-o query2` zapisuje dane wyjściowe hello do dataframe, nazywany **kwerenda2**.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="fd6fd-212">Zagadnienia dotyczące podczas korzystania z nowego jądra hello</span><span class="sxs-lookup"><span data-stu-id="fd6fd-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="fd6fd-213">Niezależnie od jądra używasz, pozostawiając notesów hello systemem wykorzystuje zasoby klastra hello.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="fd6fd-214">Z tych jądra ponieważ kontekstów hello są zdefiniowane, po prostu Kończenie notesów hello nie kill hello kontekstu i dlatego zasobów klastra hello kontynuować toobe w użyciu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="fd6fd-215">Dobrym rozwiązaniem jest toouse hello **zamknąć i zatrzymuje** opcji z notesu hello **pliku** menu po zakończeniu korzystania notesie hello kasuje hello kontekstu i następnie zamyka hello notesu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="fd6fd-216">Pokaż niektóre przykłady</span><span class="sxs-lookup"><span data-stu-id="fd6fd-216">Show me some examples</span></span>

<span data-ttu-id="fd6fd-217">Po otwarciu notesu Jupyter wyświetlany dwa foldery dostępna na poziomie głównym hello.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="fd6fd-218">Witaj **PySpark** znajduje się w nim notesów próbki tego hello Użyj nowego **Python** jądra.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="fd6fd-219">Witaj **Scala** znajduje się w nim notesów próbki tego hello Użyj nowego **Spark** jądra.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="fd6fd-220">Możesz otworzyć hello **00 — [odczytu w pierwszej kolejności] funkcje jądra Magic Spark** notesu z hello **PySpark** lub **Spark** toolearn folderu o hello różnych poleceń magicznych dostępnych.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="fd6fd-221">Można również użyć hello innych dostępnych w ramach hello dwa foldery toolearn notesów przykładowy sposób różnych scenariuszy tooachieve za pomocą notesów Jupyter z klastrami HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="fd6fd-222">Gdzie są przechowywane notesów hello?</span><span class="sxs-lookup"><span data-stu-id="fd6fd-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="fd6fd-223">Notesów Jupyter są zapisywane toohello konta magazynu skojarzone z klastrem hello w obszarze hello **/HdiNotebooks** folderu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="fd6fd-224">Notesów, pliki tekstowe i folderów tworzonych z wewnątrz Jupyter są dostępne z hello konta magazynu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="fd6fd-225">Na przykład, jeśli używasz Jupyter toocreate folder **MójFolder** i notebook **myfolder/mynotebook.ipynb**, można uzyskać dostępu do tego notesu w `/HdiNotebooks/myfolder/mynotebook.ipynb` w ramach konta magazynu hello.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="fd6fd-226">odwrotnej Hello jest również ma wartość true, oznacza to, bezpośrednio tooyour magazynu konta w przypadku przekazywania Notes `/HdiNotebooks/mynotebook1.ipynb`, notesu hello jest także widoczny Jupyter.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="fd6fd-227">Notesów pozostają na koncie magazynu hello nawet po usunięciu hello klastra.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="fd6fd-228">sposób Hello notesów zapisywania toohello konta magazynu jest zgodny z systemem plików HDFS.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="fd6fd-229">Tak, jeśli plik należy SSH do klastra hello, których można używać polecenia zarządzania, pokazane na powitania po fragment kodu:</span><span class="sxs-lookup"><span data-stu-id="fd6fd-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="fd6fd-230">W przypadku, gdy występują problemy dotyczące uzyskiwania dostępu do konta magazynu hello hello klastra, notesy hello zostały także zapisane na powitania headnode `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="fd6fd-231">Obsługiwana przeglądarka</span><span class="sxs-lookup"><span data-stu-id="fd6fd-231">Supported browser</span></span>

<span data-ttu-id="fd6fd-232">Notesów Jupyter w klastrze Spark w usłudze HDInsight są obsługiwane tylko w Google Chrome.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="fd6fd-233">Opinia</span><span class="sxs-lookup"><span data-stu-id="fd6fd-233">Feedback</span></span>
<span data-ttu-id="fd6fd-234">nowe jądra Hello znajdują się w rozwijającymi etap i będzie dojrzałych wraz z upływem czasu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="fd6fd-235">Może to również oznaczać, że interfejsy API można zmienić, ponieważ te jądra dla dorosłych.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="fd6fd-236">Czy Dziękujemy za opinię, czy masz podczas korzystania z tych nowych jądra.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="fd6fd-237">Jest to przydatne w tworzeniu hello ostatecznej wersji programu te jądra.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="fd6fd-238">Możesz pozostawić komentarzy/opinii w obszarze hello **komentarze** sekcji hello dolnej części tego artykułu.</span><span class="sxs-lookup"><span data-stu-id="fd6fd-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="fd6fd-239"><a name="seealso"></a>Zobacz też</span><span class="sxs-lookup"><span data-stu-id="fd6fd-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="fd6fd-240">Przegląd: platforma Apache Spark w usłudze Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd6fd-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="fd6fd-241">Scenariusze</span><span class="sxs-lookup"><span data-stu-id="fd6fd-241">Scenarios</span></span>
* [<span data-ttu-id="fd6fd-242">Platforma Spark i analiza biznesowa: interakcyjna analiza danych na platformie Spark w usłudze HDInsight z użyciem narzędzi do analizy biznesowej</span><span class="sxs-lookup"><span data-stu-id="fd6fd-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="fd6fd-243">Platforma Spark i usługa Machine Learning: korzystanie z platformy Spark w usłudze HDInsight do analizy temperatury w budynku z użyciem danych HVAC</span><span class="sxs-lookup"><span data-stu-id="fd6fd-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="fd6fd-244">Platforma Spark przy użyciu Machine Learning: Korzystanie z platformy Spark w wyników inspekcji żywności toopredict HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd6fd-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="fd6fd-245">Przesyłanie strumieniowe Spark: korzystanie z platformy Spark w usłudze HDInsight do tworzenia aplikacji do przesyłania strumieniowego w czasie rzeczywistym</span><span class="sxs-lookup"><span data-stu-id="fd6fd-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="fd6fd-246">Analiza dzienników witryny sieci Web na platformie Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd6fd-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="fd6fd-247">Tworzenie i uruchamianie aplikacji</span><span class="sxs-lookup"><span data-stu-id="fd6fd-247">Create and run applications</span></span>
* [<span data-ttu-id="fd6fd-248">Tworzenie autonomicznych aplikacji przy użyciu języka Scala</span><span class="sxs-lookup"><span data-stu-id="fd6fd-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="fd6fd-249">Zdalne uruchamianie zadań w klastrze Spark przy użyciu programu Livy</span><span class="sxs-lookup"><span data-stu-id="fd6fd-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="fd6fd-250">Narzędzia i rozszerzenia</span><span class="sxs-lookup"><span data-stu-id="fd6fd-250">Tools and extensions</span></span>
* [<span data-ttu-id="fd6fd-251">Użyj dodatku HDInsight Tools Plugin dla toocreate IntelliJ IDEA i przesyłanie aplikacji Spark Scala</span><span class="sxs-lookup"><span data-stu-id="fd6fd-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="fd6fd-252">Użyj dodatku HDInsight Tools Plugin zdalnie dla aplikacji Spark toodebug IntelliJ IDEA</span><span class="sxs-lookup"><span data-stu-id="fd6fd-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="fd6fd-253">Korzystanie z notesów Zeppelin w klastrze Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd6fd-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="fd6fd-254">Korzystanie z zewnętrznych pakietów z notesami Jupyter</span><span class="sxs-lookup"><span data-stu-id="fd6fd-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="fd6fd-255">Instalacja oprogramowania Jupyter na komputerze i połącz tooan klastra Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd6fd-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="fd6fd-256">Zarządzanie zasobami</span><span class="sxs-lookup"><span data-stu-id="fd6fd-256">Manage resources</span></span>
* [<span data-ttu-id="fd6fd-257">Zarządzanie zasobami hello klastra Apache Spark w usłudze Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd6fd-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="fd6fd-258">Śledzenie i debugowanie zadań uruchamianych w klastrze Apache Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="fd6fd-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

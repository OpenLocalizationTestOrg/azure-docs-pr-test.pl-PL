---
title: "Opcje kontekstu platformy R Server w usłudze HDInsight - Azure obliczania | Dokumentacja firmy Microsoft"
description: "Informacje na temat opcji kontekstu obliczeń różne dostępne dla użytkowników z serwerem R w usłudze HDInsight"
services: HDInsight
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 0deb0b1c-4094-459b-94fc-ec9b774c1f8a
ms.service: HDInsight
ms.custom: hdinsightactive
ms.devlang: R
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/19/2017
ms.author: bradsev
ms.openlocfilehash: 47f4441612be4f363ba82cc22b09786a6f3bfdc3
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 08/29/2017
---
# <a name="compute-context-options-for-r-server-on-hdinsight"></a><span data-ttu-id="73001-103">Obliczenia bazy danych kontekstu opcje serwera R w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="73001-103">Compute context options for R Server on HDInsight</span></span>

<span data-ttu-id="73001-104">Microsoft R Server w usłudze Azure HDInsight kontroluje sposób wywołania są wykonywane przez ustawienie kontekstu obliczeń.</span><span class="sxs-lookup"><span data-stu-id="73001-104">Microsoft R Server on Azure HDInsight controls how calls are executed by setting the compute context.</span></span> <span data-ttu-id="73001-105">W tym artykule opisano opcje, które są dostępne określić, czy i jak wykonanie jest zarządzana z przetwarzaniem na rdzeni węzła krawędzi lub klastra usługi HDInsight.</span><span class="sxs-lookup"><span data-stu-id="73001-105">This article outlines the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span>

<span data-ttu-id="73001-106">Węzeł krawędzi klastra umożliwia wygodne Połącz się z klastrem i uruchamiania skryptów R.</span><span class="sxs-lookup"><span data-stu-id="73001-106">The edge node of a cluster provides a convenient place to connect to the cluster and to run your R scripts.</span></span> <span data-ttu-id="73001-107">Z węzłem krawędzi istnieje możliwość uruchomionych zrównoleglone funkcje rozproszonej ScaleR na rdzeni serwera węzła krawędzi.</span><span class="sxs-lookup"><span data-stu-id="73001-107">With an edge node, you have the option of running the parallelized distributed functions of ScaleR across the cores of the edge node server.</span></span> <span data-ttu-id="73001-108">Można również uruchomić je w węzłach klastra przy użyciu jego ScaleR Hadoop mapy zmniejszyć lub Spark obliczeniowe kontekstach.</span><span class="sxs-lookup"><span data-stu-id="73001-108">You can also run them across the nodes of the cluster by using ScaleR’s Hadoop Map Reduce or Spark compute contexts.</span></span>

## <a name="microsoft-r-server-on-azure-hdinsight"></a><span data-ttu-id="73001-109">Serwer Microsoft R w usłudze Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="73001-109">Microsoft R Server on Azure HDInsight</span></span>
<span data-ttu-id="73001-110">[Microsoft R Server w usłudze Azure HDInsight](hdinsight-hadoop-r-server-overview.md) zawiera najnowsze funkcje analizy na podstawie R.</span><span class="sxs-lookup"><span data-stu-id="73001-110">[Microsoft R Server on Azure HDInsight](hdinsight-hadoop-r-server-overview.md) provides the latest capabilities for R-based analytics.</span></span> <span data-ttu-id="73001-111">Można użyć danych przechowywanych w kontenerze systemu plików HDFS w Twojej [obiektów Blob platformy Azure](../storage/common/storage-introduction.md "magazynu obiektów Blob Azure") konta magazynu, Data Lake store lub lokalny system plików w systemie Linux.</span><span class="sxs-lookup"><span data-stu-id="73001-111">It can use data that is stored in an HDFS container in your [Azure Blob](../storage/common/storage-introduction.md "Azure Blob storage") storage account, a Data Lake store, or the local Linux file system.</span></span> <span data-ttu-id="73001-112">Ponieważ R Server jest zbudowany na typu open source R, można zastosować R aplikacji tworzonych żadnych pakietów 8000 + R typu open source.</span><span class="sxs-lookup"><span data-stu-id="73001-112">Since R Server is built on open source R, the R-based applications you build can apply any of the 8000+ open source R packages.</span></span> <span data-ttu-id="73001-113">Można też procedury w [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), pakiet analizy danych big data firmy Microsoft jest dołączony serwer R.</span><span class="sxs-lookup"><span data-stu-id="73001-113">They can also use the routines in [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), Microsoft’s big data analytics package that is included with R Server.</span></span>  

## <a name="compute-contexts-for-an-edge-node"></a><span data-ttu-id="73001-114">Obliczenia bazy danych kontekstów dla węzła krawędzi</span><span class="sxs-lookup"><span data-stu-id="73001-114">Compute contexts for an edge node</span></span>
<span data-ttu-id="73001-115">Ogólnie rzecz biorąc skrypt języka R, uruchamiany w R Server dla węzła krawędzi jest uruchamiany w ramach interpreter języka R w tym węźle.</span><span class="sxs-lookup"><span data-stu-id="73001-115">In general, an R script that's run in R Server on the edge node runs within the R interpreter on that node.</span></span> <span data-ttu-id="73001-116">Wyjątki są te kroki, które wywołują funkcję ScaleR.</span><span class="sxs-lookup"><span data-stu-id="73001-116">The exceptions are those steps that call a ScaleR function.</span></span> <span data-ttu-id="73001-117">Wywołania ScaleR uruchomione w środowisku obliczeniowe, które określają sposób ustawiania kontekstu obliczeń ScaleR.</span><span class="sxs-lookup"><span data-stu-id="73001-117">The ScaleR calls run in a compute environment that is determined by how you set the ScaleR compute context.</span></span>  <span data-ttu-id="73001-118">Po uruchomieniu skryptu języka R z węzłem krawędzi, możliwe wartości kontekstu obliczeń to:</span><span class="sxs-lookup"><span data-stu-id="73001-118">When you run your R script from an edge node, the possible values of the compute context are:</span></span>

- <span data-ttu-id="73001-119">lokalny sekwencyjnych (*"local"*)</span><span class="sxs-lookup"><span data-stu-id="73001-119">local sequential (*‘local’*)</span></span>
- <span data-ttu-id="73001-120">równoległe lokalnego (*"localpar"*)</span><span class="sxs-lookup"><span data-stu-id="73001-120">local parallel (*‘localpar’*)</span></span>
- <span data-ttu-id="73001-121">Zmniejsz mapy</span><span class="sxs-lookup"><span data-stu-id="73001-121">Map Reduce</span></span>
- <span data-ttu-id="73001-122">platforma Spark</span><span class="sxs-lookup"><span data-stu-id="73001-122">Spark</span></span>

<span data-ttu-id="73001-123">*"Local"* i *"localpar"* opcje różnią się tylko w sposób **rxExec** wywołania są wykonywane.</span><span class="sxs-lookup"><span data-stu-id="73001-123">The *‘local’* and *‘localpar’* options differ only in how **rxExec** calls are executed.</span></span> <span data-ttu-id="73001-124">Oba wykonać inne wywołania funkcji odbierania w sposób równoległy między wszystkie dostępne rdzenie chyba że określono inaczej, za pomocą ScaleR **numCoresToUse** opcji, na przykład `rxOptions(numCoresToUse=6)`.</span><span class="sxs-lookup"><span data-stu-id="73001-124">They both execute other rx-function calls in a parallel manner across all available cores unless specified otherwise through use of the ScaleR **numCoresToUse** option, for example `rxOptions(numCoresToUse=6)`.</span></span> <span data-ttu-id="73001-125">Opcje przetwarzania równoległego oferują optymalną wydajność.</span><span class="sxs-lookup"><span data-stu-id="73001-125">Parallel execution options offer optimal performance.</span></span>

<span data-ttu-id="73001-126">W poniższej tabeli przedstawiono różne opcje kontekstu obliczeń ustalenie sposobu wykonywania wywołań:</span><span class="sxs-lookup"><span data-stu-id="73001-126">The following table summarizes the various compute context options to set how calls are executed:</span></span>

| <span data-ttu-id="73001-127">Obliczenia bazy danych kontekstu</span><span class="sxs-lookup"><span data-stu-id="73001-127">Compute context</span></span>  | <span data-ttu-id="73001-128">Jak ustawić</span><span class="sxs-lookup"><span data-stu-id="73001-128">How to set</span></span>                      | <span data-ttu-id="73001-129">Kontekst wykonywania</span><span class="sxs-lookup"><span data-stu-id="73001-129">Execution context</span></span>                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| <span data-ttu-id="73001-130">Lokalny sekwencyjne</span><span class="sxs-lookup"><span data-stu-id="73001-130">Local sequential</span></span> | <span data-ttu-id="73001-131">rxSetComputeContext('local')</span><span class="sxs-lookup"><span data-stu-id="73001-131">rxSetComputeContext(‘local’)</span></span>    | <span data-ttu-id="73001-132">Wykonanie zrównoleglone między rdzenie serwera węzła krawędzi, z wyjątkiem rxExec wywołań, które są wykonywane szeregowo</span><span class="sxs-lookup"><span data-stu-id="73001-132">Parallelized execution across the cores of the edge node server, except for rxExec calls, which are executed serially</span></span> |
| <span data-ttu-id="73001-133">Równoległe lokalnego</span><span class="sxs-lookup"><span data-stu-id="73001-133">Local parallel</span></span>   | <span data-ttu-id="73001-134">rxSetComputeContext('localpar')</span><span class="sxs-lookup"><span data-stu-id="73001-134">rxSetComputeContext(‘localpar’)</span></span> | <span data-ttu-id="73001-135">Wykonanie zrównoleglone między rdzenie serwera granicznego węzła</span><span class="sxs-lookup"><span data-stu-id="73001-135">Parallelized execution across the cores of the edge node server</span></span> |
| <span data-ttu-id="73001-136">platforma Spark</span><span class="sxs-lookup"><span data-stu-id="73001-136">Spark</span></span>            | <span data-ttu-id="73001-137">RxSpark()</span><span class="sxs-lookup"><span data-stu-id="73001-137">RxSpark()</span></span>                       | <span data-ttu-id="73001-138">Zrównoleglone rozproszonego wykonywania za pośrednictwem platformy Spark w węzłach klastra HDI</span><span class="sxs-lookup"><span data-stu-id="73001-138">Parallelized distributed execution via Spark across the nodes of the HDI cluster</span></span> |
| <span data-ttu-id="73001-139">Zmniejsz mapy</span><span class="sxs-lookup"><span data-stu-id="73001-139">Map Reduce</span></span>       | <span data-ttu-id="73001-140">RxHadoopMR()</span><span class="sxs-lookup"><span data-stu-id="73001-140">RxHadoopMR()</span></span>                    | <span data-ttu-id="73001-141">Zrównoleglone rozproszonego wykonywania przy użyciu mapy zmniejszyć w węzłach klastra HDI</span><span class="sxs-lookup"><span data-stu-id="73001-141">Parallelized distributed execution via Map Reduce across the nodes of the HDI cluster</span></span> |

## <a name="guidelines-for-deciding-on-a-compute-context"></a><span data-ttu-id="73001-142">Wytyczne dotyczące podejmowania decyzji o w kontekście obliczeń</span><span class="sxs-lookup"><span data-stu-id="73001-142">Guidelines for deciding on a compute context</span></span>

<span data-ttu-id="73001-143">Z trzech opcji wybierzesz umożliwiających wykonanie zrównoleglone zależnej od charakteru pracy analytics, rozmiar i lokalizację danych.</span><span class="sxs-lookup"><span data-stu-id="73001-143">Which of the three options you choose that provide parallelized execution depends on the nature of your analytics work, the size, and the location of your data.</span></span> <span data-ttu-id="73001-144">Nie ma żadnych prostej formuły, informujący o którym obliczeniowe kontekst do użycia.</span><span class="sxs-lookup"><span data-stu-id="73001-144">There is no simple formula that tells you which compute context to use.</span></span> <span data-ttu-id="73001-145">Istnieją jednak niektóre wytyczne, które mogą pomóc Ci wybrać odpowiednie opcje lub co najmniej pomóc zawęzić wybór przed uruchomieniem testu porównawczego.</span><span class="sxs-lookup"><span data-stu-id="73001-145">There are, however, some guiding principles that can help you make the right choice, or, at least, help you narrow down your choices before you run a benchmark.</span></span> <span data-ttu-id="73001-146">Obejmują one wytyczne:</span><span class="sxs-lookup"><span data-stu-id="73001-146">These guiding principles include:</span></span>

- <span data-ttu-id="73001-147">Lokalny system plików systemu Linux jest szybsza niż system plików HDFS.</span><span class="sxs-lookup"><span data-stu-id="73001-147">The local Linux file system is faster than HDFS.</span></span>
- <span data-ttu-id="73001-148">Jeśli dane są lokalne, a jeśli XDF, szybsze są powtarzane analizy.</span><span class="sxs-lookup"><span data-stu-id="73001-148">Repeated analyses are faster if the data is local, and if it's in XDF.</span></span>
- <span data-ttu-id="73001-149">Zaleca się do przesyłania strumieniowego niewielkich ilości danych ze źródła danych tekstowych.</span><span class="sxs-lookup"><span data-stu-id="73001-149">It's preferable to stream small amounts of data from a text data source.</span></span> <span data-ttu-id="73001-150">W przypadku większych ilości danych, przekonwertować go na XDF przed analizą.</span><span class="sxs-lookup"><span data-stu-id="73001-150">If the amount of data is larger, convert it to XDF before analysis.</span></span>
- <span data-ttu-id="73001-151">Koszty kopiowania lub strumieniowe przesyłanie danych z węzłem krawędzi do analizy staje się bezproblemowego zarządzania dla bardzo dużych ilości danych.</span><span class="sxs-lookup"><span data-stu-id="73001-151">The overhead of copying or streaming the data to the edge node for analysis becomes unmanageable for very large amounts of data.</span></span>
- <span data-ttu-id="73001-152">Platforma Spark jest szybsza niż mapa zmniejszyć do analizy w Hadoop.</span><span class="sxs-lookup"><span data-stu-id="73001-152">Spark is faster than Map Reduce for analysis in Hadoop.</span></span>

<span data-ttu-id="73001-153">Podana tych zasad, poniższe sekcje zapewniają pewne ogólne reguły przyjąć wybierania kontekstu obliczeń.</span><span class="sxs-lookup"><span data-stu-id="73001-153">Given these principles, the following sections offer some general rules of thumb for selecting a compute context.</span></span>

### <a name="local"></a><span data-ttu-id="73001-154">Lokalna</span><span class="sxs-lookup"><span data-stu-id="73001-154">Local</span></span>
* <span data-ttu-id="73001-155">Jeśli ilość danych w celu przeanalizowania jest mała i nie wymaga oczekiwanego, następnie strumienia go bezpośrednio do analizy rutynowych użyciu *"local"* lub *"localpar"*.</span><span class="sxs-lookup"><span data-stu-id="73001-155">If the amount of data to analyze is small and does not require repeated analysis, then stream it directly into the analysis routine using *'local'* or *'localpar'*.</span></span>
* <span data-ttu-id="73001-156">Jeśli ilość danych w celu przeanalizowania jest małych i średnich i wymaga oczekiwanego, następnie skopiować go do lokalnego systemu plików, zaimportuj go do XDF i analizować go za pomocą *"local"* lub *"localpar"*.</span><span class="sxs-lookup"><span data-stu-id="73001-156">If the amount of data to analyze is small or medium-sized and requires repeated analysis, then copy it to the local file system, import it to XDF, and analyze it via *'local'* or *'localpar'*.</span></span>

### <a name="hadoop-spark"></a><span data-ttu-id="73001-157">Hadoop, Spark</span><span class="sxs-lookup"><span data-stu-id="73001-157">Hadoop Spark</span></span>
* <span data-ttu-id="73001-158">W przypadku dużych ilości danych do analizy, następnie zaimportować go do Spark DataFrame przy użyciu **RxHiveData** lub **RxParquetData**, lub XDF w systemie plików HDFS (chyba, że magazyn jest problemu) i przeanalizuj go przy użyciu obliczeniowych Spark kontekst.</span><span class="sxs-lookup"><span data-stu-id="73001-158">If the amount of data to analyze is large, then import it to a Spark DataFrame using **RxHiveData** or **RxParquetData**, or to XDF in HDFS (unless storage is an issue), and analyze it using the Spark compute context.</span></span>

### <a name="hadoop-map-reduce"></a><span data-ttu-id="73001-159">Zmniejsz mapy usługi Hadoop</span><span class="sxs-lookup"><span data-stu-id="73001-159">Hadoop Map Reduce</span></span>
* <span data-ttu-id="73001-160">Tylko wtedy, gdy wystąpią porównania problem z kontekstem obliczeń Spark, ponieważ jest ono zazwyczaj wolniej, należy używać kontekstu obliczeń zmniejszyć mapy.</span><span class="sxs-lookup"><span data-stu-id="73001-160">Use the Map Reduce compute context only if you encounter an insurmountable problem with the Spark compute context since it is generally slower.</span></span>  

## <a name="inline-help-on-rxsetcomputecontext"></a><span data-ttu-id="73001-161">Wbudowany pomoc na temat rxSetComputeContext</span><span class="sxs-lookup"><span data-stu-id="73001-161">Inline help on rxSetComputeContext</span></span>
<span data-ttu-id="73001-162">Dodatkowe informacje i przykłady ScaleR kontekstów obliczeń dla wbudowanego pomoc w R w metodzie rxSetComputeContext, na przykład:</span><span class="sxs-lookup"><span data-stu-id="73001-162">For more information and examples of ScaleR compute contexts, see the inline help in R on the rxSetComputeContext method, for example:</span></span>

    > ?rxSetComputeContext

<span data-ttu-id="73001-163">Można także odwoływać się do "[przewodnik rozproszonego przetwarzania danych ScaleR](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)" nie jest dostępna z [R Server w witrynie MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server w witrynie MSDN") biblioteki.</span><span class="sxs-lookup"><span data-stu-id="73001-163">You can also refer to the “[ScaleR Distributed Computing Guide](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)” that's available from the [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server on MSDN") library.</span></span>

## <a name="next-steps"></a><span data-ttu-id="73001-164">Następne kroki</span><span class="sxs-lookup"><span data-stu-id="73001-164">Next steps</span></span>
<span data-ttu-id="73001-165">W tym artykule przedstawiono o opcjach, które są dostępne określić, czy i jak wykonanie jest zarządzana z przetwarzaniem na rdzeni węzła krawędzi lub klastra usługi HDInsight.</span><span class="sxs-lookup"><span data-stu-id="73001-165">In this article, you learned about the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span> <span data-ttu-id="73001-166">Aby dowiedzieć się więcej o sposobie używania R Server z klastrami usługi HDInsight, zobacz następujące tematy:</span><span class="sxs-lookup"><span data-stu-id="73001-166">To learn more about how to use R Server with HDInsight clusters, see the following topics:</span></span>

* [<span data-ttu-id="73001-167">Omówienie R Server dla usługi Hadoop</span><span class="sxs-lookup"><span data-stu-id="73001-167">Overview of R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-overview.md)
* [<span data-ttu-id="73001-168">Rozpoczynanie pracy z R Server dla platformy Hadoop</span><span class="sxs-lookup"><span data-stu-id="73001-168">Get started with R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-get-started.md)
* [<span data-ttu-id="73001-169">Dodaj serwer programu RStudio do HDInsight (Jeśli nie dodano podczas tworzenia klastra)</span><span class="sxs-lookup"><span data-stu-id="73001-169">Add RStudio Server to HDInsight (if not added during cluster creation)</span></span>](hdinsight-hadoop-r-server-install-r-studio.md)
* <span data-ttu-id="73001-170">[Azure Storage options for R Server on HDInsight](hdinsight-hadoop-r-server-storage.md) (Opcje usługi Azure Storage dla oprogramowania R Server w usłudze HDInsight)</span><span class="sxs-lookup"><span data-stu-id="73001-170">[Azure Storage options for R Server on HDInsight](hdinsight-hadoop-r-server-storage.md)</span></span>


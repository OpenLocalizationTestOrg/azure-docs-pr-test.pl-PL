---
title: "klaster zasobów aaaManage platformy Apache Spark w usłudze Azure HDInsight | Dokumentacja firmy Microsoft"
description: "Dowiedz się, jak toouse zarządzanie zasobami klastry Spark w usłudze Azure HDInsight w celu zapewnienia lepszej wydajności."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: e18682a24f77494db884105f9db03c0a350ddad6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 10/06/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="1f85c-103">Zarządzanie zasobami klastra Apache Spark w usłudze Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="1f85c-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="1f85c-104">W tym artykule dowiesz się, jak skojarzonych z interfejsami hello tooaccess jak interfejsu użytkownika narzędzia Ambari, interfejsie użytkownika YARN i hello Spark historii serwera w klastrze Spark.</span><span class="sxs-lookup"><span data-stu-id="1f85c-104">In this article you will learn how tooaccess hello interfaces like Ambari UI, YARN UI, and hello Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="1f85c-105">Możesz także informacje dotyczące sposobu tootune hello konfiguracji klastra, aby zapewnić optymalną wydajność.</span><span class="sxs-lookup"><span data-stu-id="1f85c-105">You will also learn about how tootune hello cluster configuration for optimal performance.</span></span>

<span data-ttu-id="1f85c-106">**Wymagania wstępne:**</span><span class="sxs-lookup"><span data-stu-id="1f85c-106">**Prerequisites:**</span></span>

<span data-ttu-id="1f85c-107">Musi mieć następujące hello:</span><span class="sxs-lookup"><span data-stu-id="1f85c-107">You must have hello following:</span></span>

* <span data-ttu-id="1f85c-108">Subskrypcja platformy Azure.</span><span class="sxs-lookup"><span data-stu-id="1f85c-108">An Azure subscription.</span></span> <span data-ttu-id="1f85c-109">Zobacz temat [Uzyskiwanie bezpłatnej wersji próbnej platformy Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="1f85c-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="1f85c-110">Klaster Apache Spark w usłudze HDInsight.</span><span class="sxs-lookup"><span data-stu-id="1f85c-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="1f85c-111">Aby uzyskać instrukcje, zobacz [klastrów utworzyć Apache Spark w usłudze Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="1f85c-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-hello-ambari-web-ui"></a><span data-ttu-id="1f85c-112">Jak uruchomić hello Interfejsu sieci Web Ambari?</span><span class="sxs-lookup"><span data-stu-id="1f85c-112">How do I launch hello Ambari Web UI?</span></span>
1. <span data-ttu-id="1f85c-113">Z hello [Azure Portal](https://portal.azure.com/), hello tablicy startowej, kliknij Kafelek hello klastra Spark (jeśli został przypięty toohello tablicy startowej).</span><span class="sxs-lookup"><span data-stu-id="1f85c-113">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span> <span data-ttu-id="1f85c-114">Można także przechodzić tooyour klastra w obszarze **Przeglądaj wszystko** > **klastrów usługi HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-114">You can also navigate tooyour cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="1f85c-115">W bloku klastra Spark powitania kliknij **pulpitu nawigacyjnego**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-115">From hello Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="1f85c-116">Po wyświetleniu monitu wprowadź poświadczenia administratora hello hello klastra Spark.</span><span class="sxs-lookup"><span data-stu-id="1f85c-116">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

    <span data-ttu-id="1f85c-117">![Uruchamianie narzędzia Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Uruchom Menedżera zasobów")</span><span class="sxs-lookup"><span data-stu-id="1f85c-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="1f85c-118">Powinno to uruchomienie hello Interfejsu sieci Web Ambari, jak pokazano poniżej.</span><span class="sxs-lookup"><span data-stu-id="1f85c-118">This should launch hello Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="1f85c-119">![Interfejs użytkownika sieci Web Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span><span class="sxs-lookup"><span data-stu-id="1f85c-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-hello-spark-history-server"></a><span data-ttu-id="1f85c-120">Jak uruchomić powitania serwera historii Spark?</span><span class="sxs-lookup"><span data-stu-id="1f85c-120">How do I launch hello Spark History Server?</span></span>
1. <span data-ttu-id="1f85c-121">Z hello [Azure Portal](https://portal.azure.com/), hello tablicy startowej, kliknij Kafelek hello klastra Spark (jeśli został przypięty toohello tablicy startowej).</span><span class="sxs-lookup"><span data-stu-id="1f85c-121">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span>
2. <span data-ttu-id="1f85c-122">Z hello klastra bloku, w obszarze **szybkie linki**, kliknij przycisk **pulpit nawigacyjny klastra**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-122">From hello cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="1f85c-123">W hello **pulpit nawigacyjny klastra** bloku, kliknij przycisk **Spark historii serwera**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-123">In hello **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="1f85c-124">![Platforma Spark jest serwer historii](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark historii serwera")</span><span class="sxs-lookup"><span data-stu-id="1f85c-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="1f85c-125">Po wyświetleniu monitu wprowadź poświadczenia administratora hello hello klastra Spark.</span><span class="sxs-lookup"><span data-stu-id="1f85c-125">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

## <a name="how-do-i-launch-hello-yarn-ui"></a><span data-ttu-id="1f85c-126">Jak uruchomić hello interfejsie użytkownika Yarn?</span><span class="sxs-lookup"><span data-stu-id="1f85c-126">How do I launch hello Yarn UI?</span></span>
<span data-ttu-id="1f85c-127">Możesz użyć hello interfejsie użytkownika YARN toomonitor aplikacji, które są aktualnie uruchomione w klastrze Spark hello.</span><span class="sxs-lookup"><span data-stu-id="1f85c-127">You can use hello YARN UI toomonitor applications that are currently running on hello Spark cluster.</span></span>

1. <span data-ttu-id="1f85c-128">W bloku klastra powitania kliknij **pulpit nawigacyjny klastra**, a następnie kliknij przycisk **YARN**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-128">From hello cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Uruchom interfejs użytkownika YARN](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="1f85c-130">Można również będzie można uruchomić hello interfejsie użytkownika YARN z hello interfejsu użytkownika narzędzia Ambari.</span><span class="sxs-lookup"><span data-stu-id="1f85c-130">Alternatively, you can also launch hello YARN UI from hello Ambari UI.</span></span> <span data-ttu-id="1f85c-131">toolaunch hello interfejsu użytkownika narzędzia Ambari, w bloku klastra powitania kliknij **pulpit nawigacyjny klastra**, a następnie kliknij przycisk **pulpit nawigacyjny klastra usługi HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-131">toolaunch hello Ambari UI, from hello cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="1f85c-132">Hello interfejsu użytkownika narzędzia Ambari, kliknij **YARN**, kliknij przycisk **szybkie linki**, kliknij pozycję Menedżer zasobów active hello, a następnie kliknij przycisk **interfejsu użytkownika Menedżera ResourceManager**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-132">From hello Ambari UI, click **YARN**, click **Quick Links**, click hello active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-hello-optimum-cluster-configuration-toorun-spark-applications"></a><span data-ttu-id="1f85c-133">Co to jest aplikacji Spark toorun konfiguracji klastra optymalne hello?</span><span class="sxs-lookup"><span data-stu-id="1f85c-133">What is hello optimum cluster configuration toorun Spark applications?</span></span>
<span data-ttu-id="1f85c-134">Parametry klucza Hello trzech, które mogą służyć do konfiguracji platformy Spark w zależności od wymagań aplikacji są `spark.executor.instances`, `spark.executor.cores`, i `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="1f85c-134">hello three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="1f85c-135">Moduł wykonujący jest uruchomiona aplikacji Spark.</span><span class="sxs-lookup"><span data-stu-id="1f85c-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="1f85c-136">Działa na powitania węzła procesu roboczego, a jest odpowiedzialny toocarry zadań hello aplikacji hello.</span><span class="sxs-lookup"><span data-stu-id="1f85c-136">It runs on hello worker node and is responsible toocarry out hello tasks for hello application.</span></span> <span data-ttu-id="1f85c-137">Witaj domyślna liczba modułów i hello rozmiary Moduł wykonujący dla każdego klastra jest obliczany na podstawie hello liczba węzłów procesu roboczego i rozmiaru węzła procesu roboczego hello.</span><span class="sxs-lookup"><span data-stu-id="1f85c-137">hello default number of executors and hello executor sizes for each cluster is calculated based on hello number of worker nodes and hello worker node size.</span></span> <span data-ttu-id="1f85c-138">Są one przechowywane w `spark-defaults.conf` na powitania głównymi węzłami klastra.</span><span class="sxs-lookup"><span data-stu-id="1f85c-138">These are stored in `spark-defaults.conf` on hello cluster head nodes.</span></span>

<span data-ttu-id="1f85c-139">Witaj trzy parametry konfiguracji można skonfigurować na poziomie klastra hello (dla wszystkich aplikacji uruchomionych w klastrze hello) lub można określić dla każdej poszczególnych aplikacji.</span><span class="sxs-lookup"><span data-stu-id="1f85c-139">hello three configuration parameters can be configured at hello cluster level (for all applications that run on hello cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-hello-parameters-using-ambari-ui"></a><span data-ttu-id="1f85c-140">Zmień parametry hello za pomocą interfejsu użytkownika narzędzia Ambari</span><span class="sxs-lookup"><span data-stu-id="1f85c-140">Change hello parameters using Ambari UI</span></span>
1. <span data-ttu-id="1f85c-141">Hello interfejsu użytkownika narzędzia Ambari kliknij **Spark**, kliknij przycisk **Configs**, a następnie rozwiń węzeł **niestandardowe spark — domyślne**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-141">From hello Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Ustawianie parametrów przy użyciu narzędzia Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="1f85c-143">wartości domyślne Hello są dobrym toohave 4 aplikacji Spark działać jednocześnie w klastrze hello.</span><span class="sxs-lookup"><span data-stu-id="1f85c-143">hello default values are good toohave 4 Spark applications run concurrently on hello cluster.</span></span> <span data-ttu-id="1f85c-144">Możesz zmiany tych wartości z hello interfejsu użytkownika, jak pokazano poniżej.</span><span class="sxs-lookup"><span data-stu-id="1f85c-144">You can changes these values from hello user interface, as shown below.</span></span>

    ![Ustawianie parametrów przy użyciu narzędzia Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="1f85c-146">Kliknij przycisk **zapisać** zmian konfiguracji hello toosave.</span><span class="sxs-lookup"><span data-stu-id="1f85c-146">Click **Save** toosave hello configuration changes.</span></span> <span data-ttu-id="1f85c-147">U góry hello hello strony, zostanie wyświetlony monit toorestart wszystkie hello uwzględnione usługi.</span><span class="sxs-lookup"><span data-stu-id="1f85c-147">At hello top of hello page, you will be prompted toorestart all hello affected services.</span></span> <span data-ttu-id="1f85c-148">Kliknij przycisk **ponownego uruchomienia**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-148">Click **Restart**.</span></span>

    ![Uruchom ponownie usługi](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-hello-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="1f85c-150">Zmiana parametrów hello aplikacji uruchomionej w notesu Jupyter</span><span class="sxs-lookup"><span data-stu-id="1f85c-150">Change hello parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="1f85c-151">Dla aplikacji działających w notesu Jupyter hello, można użyć hello `%%configure` Magiczna zmian konfiguracji hello toomake.</span><span class="sxs-lookup"><span data-stu-id="1f85c-151">For applications running in hello Jupyter notebook, you can use hello `%%configure` magic toomake hello configuration changes.</span></span> <span data-ttu-id="1f85c-152">W idealnym przypadku należy takie zmiany na początku hello aplikacji hello, przed uruchomieniem pierwszej komórki kodu.</span><span class="sxs-lookup"><span data-stu-id="1f85c-152">Ideally, you must make such changes at hello beginning of hello application, before you run your first code cell.</span></span> <span data-ttu-id="1f85c-153">Dzięki tej konfiguracji hello jest stosowane toohello Livy sesji, gdy zostanie utworzony.</span><span class="sxs-lookup"><span data-stu-id="1f85c-153">This ensures that hello configuration is applied toohello Livy session, when it gets created.</span></span> <span data-ttu-id="1f85c-154">Jeśli konfiguracja hello toochange na późniejszym etapie w aplikacji hello, należy użyć hello `-f` parametru.</span><span class="sxs-lookup"><span data-stu-id="1f85c-154">If you want toochange hello configuration at a later stage in hello application, you must use hello `-f` parameter.</span></span> <span data-ttu-id="1f85c-155">Jednakże wykonując, wszystkie postęp w hello aplikacji zostaną utracone.</span><span class="sxs-lookup"><span data-stu-id="1f85c-155">However, by doing so all progress in hello application will be lost.</span></span>

<span data-ttu-id="1f85c-156">Poniższy fragment Hello pokazuje, jak toochange hello konfiguracji dla aplikacji działających w oprogramowaniu Jupyter.</span><span class="sxs-lookup"><span data-stu-id="1f85c-156">hello snippet below shows how toochange hello configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="1f85c-157">Parametry konfiguracji muszą być przekazywane w postaci ciągu JSON i musi być w następnym wierszu powitania po hello magic, jak pokazano w kolumnie przykład hello.</span><span class="sxs-lookup"><span data-stu-id="1f85c-157">Configuration parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span>

### <a name="change-hello-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="1f85c-158">Przedstawia spark parametry hello zmiany przesłane za pomocą aplikacji</span><span class="sxs-lookup"><span data-stu-id="1f85c-158">Change hello parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="1f85c-159">Następujące polecenia znajduje się przykład sposobu toochange hello parametry konfiguracji, dla której zostało przesłane za pomocą aplikacji partii `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="1f85c-159">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <hello application class tooexecute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-hello-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="1f85c-160">Zmień parametry hello aplikacji przesłane przy użyciu programu cURL</span><span class="sxs-lookup"><span data-stu-id="1f85c-160">Change hello parameters for an application submitted using cURL</span></span>
<span data-ttu-id="1f85c-161">Następujące polecenia jest przykładem sposobu toochange hello parametry konfiguracji, dla której zostało przesłane za pomocą przy użyciu programu cURL aplikacji partii.</span><span class="sxs-lookup"><span data-stu-id="1f85c-161">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<hello application class tooexecute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="1f85c-162">Jak zmienić tych parametrów, na serwerze Spark Thrift?</span><span class="sxs-lookup"><span data-stu-id="1f85c-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="1f85c-163">Spark Thrift serwer udostępnia klastra Spark tooa dostępu JDBC/ODBC i używane tooservice zapytań Spark SQL.</span><span class="sxs-lookup"><span data-stu-id="1f85c-163">Spark Thrift Server provides JDBC/ODBC access tooa Spark cluster and is used tooservice Spark SQL queries.</span></span> <span data-ttu-id="1f85c-164">Narzędzia takie jak usługi Power BI, Tableau itp.</span><span class="sxs-lookup"><span data-stu-id="1f85c-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="1f85c-165">za pomocą toocommunicate protokołu ODBC zapytań Spark SQL tooexecute Spark Thrift serwera jako aplikacji Spark.</span><span class="sxs-lookup"><span data-stu-id="1f85c-165">use ODBC protocol toocommunicate with Spark Thrift Server tooexecute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="1f85c-166">Po utworzeniu klastra Spark, dwa wystąpienia hello Spark Thrift serwera jest uruchomiona, i jeden w każdym węźle głównym.</span><span class="sxs-lookup"><span data-stu-id="1f85c-166">When a Spark cluster is created, two instances of hello Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="1f85c-167">Każdy serwer Thrift Spark jest widoczny jako aplikacji Spark w interfejsie użytkownika YARN hello.</span><span class="sxs-lookup"><span data-stu-id="1f85c-167">Each Spark Thrift Server is visible as a Spark application in hello YARN UI.</span></span>

<span data-ttu-id="1f85c-168">Używa Spark Thrift serwera Spark Moduł wykonujący dynamicznej alokacji i dlatego hello `spark.executor.instances` nie jest używany.</span><span class="sxs-lookup"><span data-stu-id="1f85c-168">Spark Thrift Server uses Spark dynamic executor allocation and hence hello `spark.executor.instances` is not used.</span></span> <span data-ttu-id="1f85c-169">Zamiast tego Spark Thrift serwer używa `spark.dynamicAllocation.minExecutors` i `spark.dynamicAllocation.maxExecutors` toospecify hello Moduł wykonujący count.</span><span class="sxs-lookup"><span data-stu-id="1f85c-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` toospecify hello executor count.</span></span> <span data-ttu-id="1f85c-170">Witaj parametry konfiguracji `spark.executor.cores` i `spark.executor.memory` jest używany rozmiar modułu wykonującego hello toomodify.</span><span class="sxs-lookup"><span data-stu-id="1f85c-170">hello configuration parameters `spark.executor.cores` and `spark.executor.memory` is used toomodify hello executor size.</span></span> <span data-ttu-id="1f85c-171">Te parametry można zmienić, jak pokazano poniżej.</span><span class="sxs-lookup"><span data-stu-id="1f85c-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="1f85c-172">Rozwiń węzeł hello **zaawansowane spark-thrift-sparkconf** kategorii tooupdate hello parametry `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, i `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="1f85c-172">Expand hello **Advanced spark-thrift-sparkconf** category tooupdate hello parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Konfigurowanie Spark thrift serwera](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="1f85c-174">Rozwiń węzeł hello **niestandardowe spark-thrift-sparkconf** kategorii tooupdate hello parametru `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="1f85c-174">Expand hello **Custom spark-thrift-sparkconf** category tooupdate hello parameter `spark.executor.cores`.</span></span>

    ![Konfigurowanie Spark thrift serwera](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-hello-driver-memory-of-hello-spark-thrift-server"></a><span data-ttu-id="1f85c-176">Jak zmienić hello sterownik pamięci hello Spark Thrift serwera?</span><span class="sxs-lookup"><span data-stu-id="1f85c-176">How do I change hello driver memory of hello Spark Thrift Server?</span></span>
<span data-ttu-id="1f85c-177">Spark Thrift sterownik pamięci jest skonfigurowany too25% hello rozmiaru węzła głównego pamięci RAM, podane całkowity rozmiar pamięci RAM hello węzła głównego hello jest większa niż 14GB.</span><span class="sxs-lookup"><span data-stu-id="1f85c-177">Spark Thrift Server driver memory is configured too25% of hello head node RAM size, provided hello total RAM size of hello head node is greater than 14GB.</span></span> <span data-ttu-id="1f85c-178">Można użyć hello konfiguracji pamięci interfejsu użytkownika narzędzia Ambari toochange hello sterownika, jak pokazano poniżej.</span><span class="sxs-lookup"><span data-stu-id="1f85c-178">You can use hello Ambari UI toochange hello driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="1f85c-179">Hello interfejsu użytkownika narzędzia Ambari kliknij **Spark**, kliknij przycisk **Configs**, rozwiń węzeł **zaawansowane spark env**, a następnie podaj wartość hello **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-179">From hello Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide hello value for **spark_thrift_cmd_opts**.</span></span>

    ![Konfigurowanie Spark thrift serwera pamięci RAM](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-hello-resources-back"></a><span data-ttu-id="1f85c-181">BI nie jest używany z klastrem Spark.</span><span class="sxs-lookup"><span data-stu-id="1f85c-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="1f85c-182">Jak ponownie zająć zasobów hello?</span><span class="sxs-lookup"><span data-stu-id="1f85c-182">How do I take hello resources back?</span></span>
<span data-ttu-id="1f85c-183">Ponieważ używamy Spark dynamiczna alokacja hello tylko tych zasobów, które są używane przez serwer thrift są hello zasobów dla dwóch głównych aplikacji hello.</span><span class="sxs-lookup"><span data-stu-id="1f85c-183">Since we use Spark dynamic allocation, hello only resources that are consumed by thrift server are hello resources for hello two application masters.</span></span> <span data-ttu-id="1f85c-184">tooreclaim tych zasobów, które należy zatrzymać hello Thrift serwera usługi działające na powitania klastra.</span><span class="sxs-lookup"><span data-stu-id="1f85c-184">tooreclaim these resources you must stop hello Thrift Server services running on hello cluster.</span></span>

1. <span data-ttu-id="1f85c-185">Witaj interfejsu użytkownika narzędzia Ambari, w okienku po lewej stronie powitania kliknij **Spark**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-185">From hello Ambari UI, from hello left pane, click **Spark**.</span></span>
2. <span data-ttu-id="1f85c-186">Na następnej stronie powitania kliknij **Spark Thrift serwerów**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-186">In hello next page, click **Spark Thrift Servers**.</span></span>

    ![Uruchom ponownie serwer thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="1f85c-188">Powinny pojawić się dwa headnodes hello, na które hello Spark Thrift serwer jest uruchomiony.</span><span class="sxs-lookup"><span data-stu-id="1f85c-188">You should see hello two headnodes on which hello Spark Thrift Server is running.</span></span> <span data-ttu-id="1f85c-189">Kliknij jeden z hello headnodes.</span><span class="sxs-lookup"><span data-stu-id="1f85c-189">Click one of hello headnodes.</span></span>

    ![Uruchom ponownie serwer thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="1f85c-191">Hello Następna strona zawiera listę wszystkich usług hello uruchomionych na tym headnode.</span><span class="sxs-lookup"><span data-stu-id="1f85c-191">hello next page lists all hello services running on that headnode.</span></span> <span data-ttu-id="1f85c-192">Z listy powitania kliknij przycisk Dalej tooSpark przycisku rozwijanego powitania serwera Thrift, a następnie kliknij **zatrzymać**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-192">From hello list click hello drop-down button next tooSpark Thrift Server, and then click **Stop**.</span></span>

    ![Uruchom ponownie serwer thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="1f85c-194">Powtórz te czynności na powitania również inne headnode.</span><span class="sxs-lookup"><span data-stu-id="1f85c-194">Repeat these steps on hello other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-hello-service"></a><span data-ttu-id="1f85c-195">Moje notesów Jupyter nie działają zgodnie z oczekiwaniami.</span><span class="sxs-lookup"><span data-stu-id="1f85c-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="1f85c-196">Jak można ponownie uruchomić usługę hello?</span><span class="sxs-lookup"><span data-stu-id="1f85c-196">How can I restart hello service?</span></span>
<span data-ttu-id="1f85c-197">Uruchom hello Interfejsu sieci Web Ambari, zgodnie z powyższym.</span><span class="sxs-lookup"><span data-stu-id="1f85c-197">Launch hello Ambari Web UI as shown above.</span></span> <span data-ttu-id="1f85c-198">W okienku nawigacji po lewej stronie powitania kliknij **Jupyter**, kliknij przycisk **akcji usługi**, a następnie kliknij przycisk **ponowne uruchomienie wszystkich**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-198">From hello left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="1f85c-199">Spowoduje to uruchomienie usługi Jupyter hello na wszystkich headnodes hello.</span><span class="sxs-lookup"><span data-stu-id="1f85c-199">This will start hello Jupyter service on all hello headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="1f85c-200">Jak sprawdzić, jeśli używam wszystkich zasobów?</span><span class="sxs-lookup"><span data-stu-id="1f85c-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="1f85c-201">Uruchom hello interfejsie użytkownika Yarn, zgodnie z powyższym.</span><span class="sxs-lookup"><span data-stu-id="1f85c-201">Launch hello Yarn UI as shown above.</span></span> <span data-ttu-id="1f85c-202">W tabeli metrykę klastra na ekranie powitania, sprawdź wartości **pamięć używana** i **całkowitej pamięci** kolumn.</span><span class="sxs-lookup"><span data-stu-id="1f85c-202">In Cluster Metrics table on top of hello screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="1f85c-203">Jeśli wartości hello 2 są bardzo bliskiej, może nie być wystarczającej ilości zasobów toostart hello następnej aplikacji.</span><span class="sxs-lookup"><span data-stu-id="1f85c-203">If hello 2 values are very close, there might not be enough resources toostart hello next application.</span></span> <span data-ttu-id="1f85c-204">Witaj dotyczy to również toohello **VCores używane** i **łącznie VCores** kolumn.</span><span class="sxs-lookup"><span data-stu-id="1f85c-204">hello same applies toohello **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="1f85c-205">Ponadto w hello widoku głównego, w przypadku aplikacji przebywanie w **ZAAKCEPTOWANE** stanu i nie są przenoszone do **systemem** ani **nie powiodło się** stanu, przyczyną może być również wskazanie czy nie otrzymuje toostart wystarczającej ilości zasobów.</span><span class="sxs-lookup"><span data-stu-id="1f85c-205">Also, in hello main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources toostart.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-toofree-up-resource"></a><span data-ttu-id="1f85c-206">Jak kill uruchomionej aplikacji toofree się zasobów?</span><span class="sxs-lookup"><span data-stu-id="1f85c-206">How do I kill a running application toofree up resource?</span></span>
1. <span data-ttu-id="1f85c-207">W hello interfejsie użytkownika Yarn z lewego panelu powitania kliknij **systemem**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-207">In hello Yarn UI, from hello left panel, click **Running**.</span></span> <span data-ttu-id="1f85c-208">Z listy hello uruchomionych aplikacji, sprawdź toobe aplikacji hello skasowane i kliknij na powitania **identyfikator**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-208">From hello list of running applications, determine hello application toobe killed and click on hello **ID**.</span></span>

    <span data-ttu-id="1f85c-209">![Kasowanie App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span><span class="sxs-lookup"><span data-stu-id="1f85c-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="1f85c-210">Kliknij przycisk **Kill aplikacji** na powitania prawym górnym rogu, następnie kliknij przycisk **OK**.</span><span class="sxs-lookup"><span data-stu-id="1f85c-210">Click **Kill Application** on hello top right corner, then click **OK**.</span></span>

    <span data-ttu-id="1f85c-211">![Kasowanie App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span><span class="sxs-lookup"><span data-stu-id="1f85c-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="1f85c-212">Zobacz też</span><span class="sxs-lookup"><span data-stu-id="1f85c-212">See also</span></span>
* [<span data-ttu-id="1f85c-213">Śledzenie i debugowanie zadań uruchamianych w klastrze Apache Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="1f85c-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="1f85c-214">Dla analityków danych</span><span class="sxs-lookup"><span data-stu-id="1f85c-214">For data analysts</span></span>

* [<span data-ttu-id="1f85c-215">Platforma Spark i usługa Machine Learning: korzystanie z platformy Spark w usłudze HDInsight do analizy temperatury w budynku z użyciem danych HVAC</span><span class="sxs-lookup"><span data-stu-id="1f85c-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="1f85c-216">Platforma Spark przy użyciu Machine Learning: Korzystanie z platformy Spark w wyników inspekcji żywności toopredict HDInsight</span><span class="sxs-lookup"><span data-stu-id="1f85c-216">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="1f85c-217">Analiza dzienników witryny sieci Web na platformie Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="1f85c-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="1f85c-218">Analiza danych telemetrycznych usługi Application Insight przy użyciu platformy Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="1f85c-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="1f85c-219">Użyj Caffe Azure HDInsight Spark dla rozproszonych learning bezpośrednich</span><span class="sxs-lookup"><span data-stu-id="1f85c-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="1f85c-220">Dla deweloperów platformy Spark</span><span class="sxs-lookup"><span data-stu-id="1f85c-220">For Spark developers</span></span>

* [<span data-ttu-id="1f85c-221">Tworzenie autonomicznych aplikacji przy użyciu języka Scala</span><span class="sxs-lookup"><span data-stu-id="1f85c-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="1f85c-222">Zdalne uruchamianie zadań w klastrze Spark przy użyciu programu Livy</span><span class="sxs-lookup"><span data-stu-id="1f85c-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="1f85c-223">Użyj dodatku HDInsight Tools Plugin dla toocreate IntelliJ IDEA i przesyłanie aplikacji Spark Scala</span><span class="sxs-lookup"><span data-stu-id="1f85c-223">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="1f85c-224">Przesyłanie strumieniowe Spark: korzystanie z platformy Spark w usłudze HDInsight do tworzenia aplikacji do przesyłania strumieniowego w czasie rzeczywistym</span><span class="sxs-lookup"><span data-stu-id="1f85c-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="1f85c-225">Użyj dodatku HDInsight Tools Plugin zdalnie dla aplikacji Spark toodebug IntelliJ IDEA</span><span class="sxs-lookup"><span data-stu-id="1f85c-225">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="1f85c-226">Korzystanie z notesów Zeppelin w klastrze Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="1f85c-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="1f85c-227">Jądra dostępne dla notesu Jupyter w klastrze Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="1f85c-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="1f85c-228">Korzystanie z zewnętrznych pakietów z notesami Jupyter</span><span class="sxs-lookup"><span data-stu-id="1f85c-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="1f85c-229">Instalacja oprogramowania Jupyter na komputerze i połącz tooan klastra Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="1f85c-229">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

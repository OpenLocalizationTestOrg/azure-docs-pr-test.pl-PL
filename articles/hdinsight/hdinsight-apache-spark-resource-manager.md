---
title: "Zarządzanie zasobami klastra Apache Spark w usłudze Azure HDInsight | Dokumentacja firmy Microsoft"
description: "Dowiedz się, jak używać zarządzanie zasobami klastry Spark w usłudze Azure HDInsight w celu zapewnienia lepszej wydajności."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: 952fa15162a40bccb3f8c7a88508556757ca6675
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 08/03/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="efabf-103">Zarządzanie zasobami klastra Apache Spark w usłudze Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="efabf-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="efabf-104">W w tym artykule przedstawiono sposób uzyskać dostępu do interfejsów, takich jak Ambari interfejsie użytkownika YARN interfejsu użytkownika, i serwerze historii Spark skojarzone z klastrem Spark.</span><span class="sxs-lookup"><span data-stu-id="efabf-104">In this article you will learn how to access the interfaces like Ambari UI, YARN UI, and the Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="efabf-105">Możesz także informacje dotyczące sposobu dostosowywania konfiguracji klastra, aby zapewnić optymalną wydajność.</span><span class="sxs-lookup"><span data-stu-id="efabf-105">You will also learn about how to tune the cluster configuration for optimal performance.</span></span>

<span data-ttu-id="efabf-106">**Wymagania wstępne:**</span><span class="sxs-lookup"><span data-stu-id="efabf-106">**Prerequisites:**</span></span>

<span data-ttu-id="efabf-107">Należy dysponować następującymi elementami:</span><span class="sxs-lookup"><span data-stu-id="efabf-107">You must have the following:</span></span>

* <span data-ttu-id="efabf-108">Subskrypcja platformy Azure.</span><span class="sxs-lookup"><span data-stu-id="efabf-108">An Azure subscription.</span></span> <span data-ttu-id="efabf-109">Zobacz temat [Uzyskiwanie bezpłatnej wersji próbnej platformy Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="efabf-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="efabf-110">Klaster Apache Spark w usłudze HDInsight.</span><span class="sxs-lookup"><span data-stu-id="efabf-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="efabf-111">Aby uzyskać instrukcje, zobacz [klastrów utworzyć Apache Spark w usłudze Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="efabf-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-the-ambari-web-ui"></a><span data-ttu-id="efabf-112">Jak uruchomić interfejs użytkownika sieci Web Ambari?</span><span class="sxs-lookup"><span data-stu-id="efabf-112">How do I launch the Ambari Web UI?</span></span>
1. <span data-ttu-id="efabf-113">W [Portalu Azure](https://portal.azure.com/) na tablicy startowej kliknij kafelek klastra Spark (jeśli został przypięty do tablicy startowej).</span><span class="sxs-lookup"><span data-stu-id="efabf-113">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span> <span data-ttu-id="efabf-114">Możesz także przejść do klastra, wybierając polecenia **Przeglądaj wszystko** > **Klastry usługi HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="efabf-114">You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="efabf-115">W bloku klastra Spark kliknij **pulpitu nawigacyjnego**.</span><span class="sxs-lookup"><span data-stu-id="efabf-115">From the Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="efabf-116">Po wyświetleniu monitu wprowadź poświadczenia administratora klastra Spark.</span><span class="sxs-lookup"><span data-stu-id="efabf-116">When prompted, enter the admin credentials for the Spark cluster.</span></span>

    <span data-ttu-id="efabf-117">![Uruchamianie narzędzia Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Uruchom Menedżera zasobów")</span><span class="sxs-lookup"><span data-stu-id="efabf-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="efabf-118">Powinno to uruchomienie Interfejsu sieci Web Ambari, jak pokazano poniżej.</span><span class="sxs-lookup"><span data-stu-id="efabf-118">This should launch the Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="efabf-119">![Interfejs użytkownika sieci Web Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span><span class="sxs-lookup"><span data-stu-id="efabf-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-the-spark-history-server"></a><span data-ttu-id="efabf-120">Jak uruchomić serwera historii Spark?</span><span class="sxs-lookup"><span data-stu-id="efabf-120">How do I launch the Spark History Server?</span></span>
1. <span data-ttu-id="efabf-121">W [Portalu Azure](https://portal.azure.com/) na tablicy startowej kliknij kafelek klastra Spark (jeśli został przypięty do tablicy startowej).</span><span class="sxs-lookup"><span data-stu-id="efabf-121">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span>
2. <span data-ttu-id="efabf-122">W bloku klastra w obszarze **szybkie linki**, kliknij przycisk **pulpit nawigacyjny klastra**.</span><span class="sxs-lookup"><span data-stu-id="efabf-122">From the cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="efabf-123">W **pulpit nawigacyjny klastra** bloku, kliknij przycisk **Spark historii serwera**.</span><span class="sxs-lookup"><span data-stu-id="efabf-123">In the **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="efabf-124">![Platforma Spark jest serwer historii](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark historii serwera")</span><span class="sxs-lookup"><span data-stu-id="efabf-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="efabf-125">Po wyświetleniu monitu wprowadź poświadczenia administratora klastra Spark.</span><span class="sxs-lookup"><span data-stu-id="efabf-125">When prompted, enter the admin credentials for the Spark cluster.</span></span>

## <a name="how-do-i-launch-the-yarn-ui"></a><span data-ttu-id="efabf-126">Jak uruchomić interfejs użytkownika Yarn?</span><span class="sxs-lookup"><span data-stu-id="efabf-126">How do I launch the Yarn UI?</span></span>
<span data-ttu-id="efabf-127">Interfejs użytkownika YARN służy do monitorowania aplikacji, które są aktualnie uruchomione w klastrze Spark.</span><span class="sxs-lookup"><span data-stu-id="efabf-127">You can use the YARN UI to monitor applications that are currently running on the Spark cluster.</span></span>

1. <span data-ttu-id="efabf-128">W bloku klastra, kliknij **pulpit nawigacyjny klastra**, a następnie kliknij przycisk **YARN**.</span><span class="sxs-lookup"><span data-stu-id="efabf-128">From the cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Uruchom interfejs użytkownika YARN](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="efabf-130">Alternatywnie można również uruchomić interfejsie użytkownika YARN z poziomu interfejsu użytkownika narzędzia Ambari.</span><span class="sxs-lookup"><span data-stu-id="efabf-130">Alternatively, you can also launch the YARN UI from the Ambari UI.</span></span> <span data-ttu-id="efabf-131">Aby uruchomić interfejs użytkownika narzędzia Ambari w bloku klastra, kliknij przycisk **pulpit nawigacyjny klastra**, a następnie kliknij przycisk **pulpit nawigacyjny klastra usługi HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="efabf-131">To launch the Ambari UI, from the cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="efabf-132">W interfejsie użytkownika narzędzia Ambari, kliknij przycisk **YARN**, kliknij przycisk **szybkie linki**, kliknij pozycję Menedżer zasobów aktywne, a następnie kliknij przycisk **interfejsu użytkownika Menedżera ResourceManager**.</span><span class="sxs-lookup"><span data-stu-id="efabf-132">From the Ambari UI, click **YARN**, click **Quick Links**, click the active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-the-optimum-cluster-configuration-to-run-spark-applications"></a><span data-ttu-id="efabf-133">Co to jest Konfiguracja klastra optymalne do uruchamiania aplikacji Spark?</span><span class="sxs-lookup"><span data-stu-id="efabf-133">What is the optimum cluster configuration to run Spark applications?</span></span>
<span data-ttu-id="efabf-134">Są trzy parametry kluczy, które mogą służyć do konfiguracji platformy Spark w zależności od wymagań aplikacji `spark.executor.instances`, `spark.executor.cores`, i `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="efabf-134">The three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="efabf-135">Moduł wykonujący jest uruchomiona aplikacji Spark.</span><span class="sxs-lookup"><span data-stu-id="efabf-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="efabf-136">Działa w węźle procesu roboczego, a odpowiada do wykonywania zadań dla aplikacji.</span><span class="sxs-lookup"><span data-stu-id="efabf-136">It runs on the worker node and is responsible to carry out the tasks for the application.</span></span> <span data-ttu-id="efabf-137">Domyślna liczba modułów i rozmiary Moduł wykonujący dla każdego klastra jest obliczany na podstawie liczby węzłów procesu roboczego i rozmiaru węzła procesu roboczego.</span><span class="sxs-lookup"><span data-stu-id="efabf-137">The default number of executors and the executor sizes for each cluster is calculated based on the number of worker nodes and the worker node size.</span></span> <span data-ttu-id="efabf-138">Są one przechowywane w `spark-defaults.conf` na głównymi węzłami klastra.</span><span class="sxs-lookup"><span data-stu-id="efabf-138">These are stored in `spark-defaults.conf` on the cluster head nodes.</span></span>

<span data-ttu-id="efabf-139">Parametry trzech konfiguracji można skonfigurować na poziomie klastra (dla wszystkich aplikacji, które są uruchamiane w klastrze) lub można określić dla każdej poszczególnych aplikacji.</span><span class="sxs-lookup"><span data-stu-id="efabf-139">The three configuration parameters can be configured at the cluster level (for all applications that run on the cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-the-parameters-using-ambari-ui"></a><span data-ttu-id="efabf-140">Zmień parametry za pomocą interfejsu użytkownika narzędzia Ambari</span><span class="sxs-lookup"><span data-stu-id="efabf-140">Change the parameters using Ambari UI</span></span>
1. <span data-ttu-id="efabf-141">W interfejsie użytkownika narzędzia Ambari kliknij **Spark**, kliknij przycisk **Configs**, a następnie rozwiń węzeł **niestandardowe spark — domyślne**.</span><span class="sxs-lookup"><span data-stu-id="efabf-141">From the Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Ustawianie parametrów przy użyciu narzędzia Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="efabf-143">Wartości domyślne są warto mieć 4 Spark aplikacje są uruchamiane jednocześnie w klastrze.</span><span class="sxs-lookup"><span data-stu-id="efabf-143">The default values are good to have 4 Spark applications run concurrently on the cluster.</span></span> <span data-ttu-id="efabf-144">Możesz zmiany tych wartości, przy użyciu interfejsu użytkownika, jak pokazano poniżej.</span><span class="sxs-lookup"><span data-stu-id="efabf-144">You can changes these values from the user interface, as shown below.</span></span>

    ![Ustawianie parametrów przy użyciu narzędzia Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="efabf-146">Kliknij przycisk **zapisać** można zapisać zmian konfiguracji.</span><span class="sxs-lookup"><span data-stu-id="efabf-146">Click **Save** to save the configuration changes.</span></span> <span data-ttu-id="efabf-147">W górnej części strony pojawi się monit o ponowne uruchomienie wszystkich odpowiednich usług.</span><span class="sxs-lookup"><span data-stu-id="efabf-147">At the top of the page, you will be prompted to restart all the affected services.</span></span> <span data-ttu-id="efabf-148">Kliknij przycisk **ponownego uruchomienia**.</span><span class="sxs-lookup"><span data-stu-id="efabf-148">Click **Restart**.</span></span>

    ![Uruchom ponownie usługi](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-the-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="efabf-150">Zmień parametry dla aplikacji działających w notesu Jupyter</span><span class="sxs-lookup"><span data-stu-id="efabf-150">Change the parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="efabf-151">W przypadku aplikacji uruchomionych w notesu Jupyter, można użyć `%%configure` magic zmian konfiguracji.</span><span class="sxs-lookup"><span data-stu-id="efabf-151">For applications running in the Jupyter notebook, you can use the `%%configure` magic to make the configuration changes.</span></span> <span data-ttu-id="efabf-152">W idealnym przypadku należy takie zmiany na początku aplikacji, przed uruchomieniem pierwszej komórki kodu.</span><span class="sxs-lookup"><span data-stu-id="efabf-152">Ideally, you must make such changes at the beginning of the application, before you run your first code cell.</span></span> <span data-ttu-id="efabf-153">Dzięki temu, że konfiguracja zostanie zastosowana do sesji programu Livy, gdy zostanie utworzony.</span><span class="sxs-lookup"><span data-stu-id="efabf-153">This ensures that the configuration is applied to the Livy session, when it gets created.</span></span> <span data-ttu-id="efabf-154">Jeśli chcesz zmienić konfigurację na późniejszym etapie w aplikacji, należy użyć `-f` parametru.</span><span class="sxs-lookup"><span data-stu-id="efabf-154">If you want to change the configuration at a later stage in the application, you must use the `-f` parameter.</span></span> <span data-ttu-id="efabf-155">Jednak przez grozi postępu wszystkich w aplikacji zostaną utracone.</span><span class="sxs-lookup"><span data-stu-id="efabf-155">However, by doing so all progress in the application will be lost.</span></span>

<span data-ttu-id="efabf-156">Poniższy fragment pokazano, jak zmiana konfiguracji dla aplikacji działających w oprogramowaniu Jupyter.</span><span class="sxs-lookup"><span data-stu-id="efabf-156">The snippet below shows how to change the configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="efabf-157">Parametry konfiguracji muszą być przekazywane w postaci ciągu JSON i musi być w następnym wierszu po magic, jak pokazano w przykładzie kolumny.</span><span class="sxs-lookup"><span data-stu-id="efabf-157">Configuration parameters must be passed in as a JSON string and must be on the next line after the magic, as shown in the example column.</span></span>

### <a name="change-the-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="efabf-158">Zmiana, którą przesłać spark parametry przesłane za pomocą aplikacji</span><span class="sxs-lookup"><span data-stu-id="efabf-158">Change the parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="efabf-159">Następujące polecenia są przykładem zmienić parametry konfiguracji, dla której zostało przesłane za pomocą aplikacji partii `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="efabf-159">Following command is an example of how to change the configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <the application class to execute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-the-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="efabf-160">Zmień parametry dla aplikacji przesłane przy użyciu programu cURL</span><span class="sxs-lookup"><span data-stu-id="efabf-160">Change the parameters for an application submitted using cURL</span></span>
<span data-ttu-id="efabf-161">Następujące polecenia są przykładem zmienić parametry konfiguracji, dla której zostało przesłane za pomocą przy użyciu programu cURL aplikacji partii.</span><span class="sxs-lookup"><span data-stu-id="efabf-161">Following command is an example of how to change the configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<the application class to execute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="efabf-162">Jak zmienić tych parametrów, na serwerze Spark Thrift?</span><span class="sxs-lookup"><span data-stu-id="efabf-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="efabf-163">Spark Thrift Server JDBC/ODBC udostępnia klastra Spark i służy do zapytań Spark SQL usługi.</span><span class="sxs-lookup"><span data-stu-id="efabf-163">Spark Thrift Server provides JDBC/ODBC access to a Spark cluster and is used to service Spark SQL queries.</span></span> <span data-ttu-id="efabf-164">Narzędzia takie jak usługi Power BI, Tableau itp.</span><span class="sxs-lookup"><span data-stu-id="efabf-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="efabf-165">Używanie protokołu ODBC do komunikowania się z serwerem Thrift Spark do wykonywania zapytań Spark SQL jako aplikacji Spark.</span><span class="sxs-lookup"><span data-stu-id="efabf-165">use ODBC protocol to communicate with Spark Thrift Server to execute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="efabf-166">Po utworzeniu klastra Spark są uruchamiane dwa wystąpienia serwera Spark Thrift, jeden w każdym węźle głównym.</span><span class="sxs-lookup"><span data-stu-id="efabf-166">When a Spark cluster is created, two instances of the Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="efabf-167">Każdy serwer Thrift Spark jest widoczny jako aplikacji Spark w Interfejsie użytkownika YARN.</span><span class="sxs-lookup"><span data-stu-id="efabf-167">Each Spark Thrift Server is visible as a Spark application in the YARN UI.</span></span>

<span data-ttu-id="efabf-168">Platforma Spark Thrift serwer używa Spark Moduł wykonujący dynamicznej alokacji i dlatego `spark.executor.instances` nie jest używany.</span><span class="sxs-lookup"><span data-stu-id="efabf-168">Spark Thrift Server uses Spark dynamic executor allocation and hence the `spark.executor.instances` is not used.</span></span> <span data-ttu-id="efabf-169">Zamiast tego Spark Thrift serwer używa `spark.dynamicAllocation.minExecutors` i `spark.dynamicAllocation.maxExecutors` można określić liczbę Moduł wykonujący.</span><span class="sxs-lookup"><span data-stu-id="efabf-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` to specify the executor count.</span></span> <span data-ttu-id="efabf-170">Parametry konfiguracji `spark.executor.cores` i `spark.executor.memory` służy do zmiany rozmiaru Moduł wykonujący.</span><span class="sxs-lookup"><span data-stu-id="efabf-170">The configuration parameters `spark.executor.cores` and `spark.executor.memory` is used to modify the executor size.</span></span> <span data-ttu-id="efabf-171">Te parametry można zmienić, jak pokazano poniżej.</span><span class="sxs-lookup"><span data-stu-id="efabf-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="efabf-172">Rozwiń węzeł **zaawansowane spark-thrift-sparkconf** kategorię, aby zaktualizować parametry `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, i `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="efabf-172">Expand the **Advanced spark-thrift-sparkconf** category to update the parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Konfigurowanie Spark thrift serwera](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="efabf-174">Rozwiń węzeł **niestandardowe spark-thrift-sparkconf** kategorię, aby zaktualizować parametr `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="efabf-174">Expand the **Custom spark-thrift-sparkconf** category to update the parameter `spark.executor.cores`.</span></span>

    ![Konfigurowanie Spark thrift serwera](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-the-driver-memory-of-the-spark-thrift-server"></a><span data-ttu-id="efabf-176">Jak zmienić pamięci sterownika serwera Spark Thrift?</span><span class="sxs-lookup"><span data-stu-id="efabf-176">How do I change the driver memory of the Spark Thrift Server?</span></span>
<span data-ttu-id="efabf-177">Pamięć sterownik Spark Thrift serwera jest skonfigurowany do 25% rozmiar pamięci RAM węzła głównego, pod warunkiem że całkowity rozmiar pamięci RAM węzła głównego jest większa niż 14 GB.</span><span class="sxs-lookup"><span data-stu-id="efabf-177">Spark Thrift Server driver memory is configured to 25% of the head node RAM size, provided the total RAM size of the head node is greater than 14GB.</span></span> <span data-ttu-id="efabf-178">Interfejs użytkownika narzędzia Ambari służy do zmiany konfiguracji pamięci sterownika, jak pokazano poniżej.</span><span class="sxs-lookup"><span data-stu-id="efabf-178">You can use the Ambari UI to change the driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="efabf-179">W interfejsie użytkownika narzędzia Ambari kliknij **Spark**, kliknij przycisk **Configs**, rozwiń węzeł **zaawansowane spark env**, a następnie podaj wartość dla **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="efabf-179">From the Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide the value for **spark_thrift_cmd_opts**.</span></span>

    ![Konfigurowanie Spark thrift serwera pamięci RAM](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-the-resources-back"></a><span data-ttu-id="efabf-181">BI nie jest używany z klastrem Spark.</span><span class="sxs-lookup"><span data-stu-id="efabf-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="efabf-182">Jak ponownie podjąć zasobów?</span><span class="sxs-lookup"><span data-stu-id="efabf-182">How do I take the resources back?</span></span>
<span data-ttu-id="efabf-183">Ponieważ używamy Spark dynamiczna alokacja tylko zasoby, które są używane przez serwer thrift są zasoby wzorców dwóch aplikacji.</span><span class="sxs-lookup"><span data-stu-id="efabf-183">Since we use Spark dynamic allocation, the only resources that are consumed by thrift server are the resources for the two application masters.</span></span> <span data-ttu-id="efabf-184">Aby odzyskać te zasoby należy zatrzymać usługi serwera Thrift działające w klastrze.</span><span class="sxs-lookup"><span data-stu-id="efabf-184">To reclaim these resources you must stop the Thrift Server services running on the cluster.</span></span>

1. <span data-ttu-id="efabf-185">W interfejsie użytkownika narzędzia Ambari, w lewym okienku kliknij **Spark**.</span><span class="sxs-lookup"><span data-stu-id="efabf-185">From the Ambari UI, from the left pane, click **Spark**.</span></span>
2. <span data-ttu-id="efabf-186">Na następnej stronie kliknij **Spark Thrift serwerów**.</span><span class="sxs-lookup"><span data-stu-id="efabf-186">In the next page, click **Spark Thrift Servers**.</span></span>

    ![Uruchom ponownie serwer thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="efabf-188">Powinny pojawić się dwa headnodes, na których działa serwera Spark Thrift.</span><span class="sxs-lookup"><span data-stu-id="efabf-188">You should see the two headnodes on which the Spark Thrift Server is running.</span></span> <span data-ttu-id="efabf-189">Kliknij jeden z headnodes.</span><span class="sxs-lookup"><span data-stu-id="efabf-189">Click one of the headnodes.</span></span>

    ![Uruchom ponownie serwer thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="efabf-191">Dalej znajduje się lista wszystkich usług, które są uruchomione na tym headnode.</span><span class="sxs-lookup"><span data-stu-id="efabf-191">The next page lists all the services running on that headnode.</span></span> <span data-ttu-id="efabf-192">Na liście kliknij przycisk listy rozwijanej obok Spark Thrift serwera, a następnie kliknij przycisk **zatrzymać**.</span><span class="sxs-lookup"><span data-stu-id="efabf-192">From the list click the drop-down button next to Spark Thrift Server, and then click **Stop**.</span></span>

    ![Uruchom ponownie serwer thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="efabf-194">Powtórz te kroki dla innych headnode również.</span><span class="sxs-lookup"><span data-stu-id="efabf-194">Repeat these steps on the other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-the-service"></a><span data-ttu-id="efabf-195">Moje notesów Jupyter nie działają zgodnie z oczekiwaniami.</span><span class="sxs-lookup"><span data-stu-id="efabf-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="efabf-196">Jak można ponownie uruchomić usługę?</span><span class="sxs-lookup"><span data-stu-id="efabf-196">How can I restart the service?</span></span>
<span data-ttu-id="efabf-197">Uruchamianie Interfejsu sieci Web Ambari, jak pokazano powyżej.</span><span class="sxs-lookup"><span data-stu-id="efabf-197">Launch the Ambari Web UI as shown above.</span></span> <span data-ttu-id="efabf-198">W okienku nawigacji po lewej stronie kliknij **Jupyter**, kliknij przycisk **akcji usługi**, a następnie kliknij przycisk **ponowne uruchomienie wszystkich**.</span><span class="sxs-lookup"><span data-stu-id="efabf-198">From the left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="efabf-199">Spowoduje to uruchomienie usługi Jupyter na wszystkich headnodes.</span><span class="sxs-lookup"><span data-stu-id="efabf-199">This will start the Jupyter service on all the headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="efabf-200">Jak sprawdzić, jeśli używam wszystkich zasobów?</span><span class="sxs-lookup"><span data-stu-id="efabf-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="efabf-201">Uruchom interfejs użytkownika Yarn, jak pokazano powyżej.</span><span class="sxs-lookup"><span data-stu-id="efabf-201">Launch the Yarn UI as shown above.</span></span> <span data-ttu-id="efabf-202">W tabeli metrykę klastra u góry ekranu, sprawdź wartości **pamięć używana** i **całkowitej pamięci** kolumn.</span><span class="sxs-lookup"><span data-stu-id="efabf-202">In Cluster Metrics table on top of the screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="efabf-203">Jeśli wartości 2 są bardzo bliskiej, może nie być wystarczającej ilości zasobów, aby uruchomić następnej aplikacji.</span><span class="sxs-lookup"><span data-stu-id="efabf-203">If the 2 values are very close, there might not be enough resources to start the next application.</span></span> <span data-ttu-id="efabf-204">To samo dotyczy **używane VCores** i **łącznie VCores** kolumn.</span><span class="sxs-lookup"><span data-stu-id="efabf-204">The same applies to the **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="efabf-205">Ponadto w widoku głównego, w przypadku aplikacji przebywanie w **ZAAKCEPTOWANE** stanu i nie są przenoszone do **systemem** ani **nie powiodło się** stanu, przyczyną może być również wskazanie, że nie otrzymuje wystarczającej liczby zasobów, aby uruchomić.</span><span class="sxs-lookup"><span data-stu-id="efabf-205">Also, in the main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources to start.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-to-free-up-resource"></a><span data-ttu-id="efabf-206">Jak kill działającej aplikacji w celu zwolnienia zasobów?</span><span class="sxs-lookup"><span data-stu-id="efabf-206">How do I kill a running application to free up resource?</span></span>
1. <span data-ttu-id="efabf-207">W interfejsie użytkownika Yarn z lewego panelu, kliknij przycisk **systemem**.</span><span class="sxs-lookup"><span data-stu-id="efabf-207">In the Yarn UI, from the left panel, click **Running**.</span></span> <span data-ttu-id="efabf-208">Z listy uruchomionych aplikacji, należy określić aplikację, aby skasowane i kliknij pozycję **identyfikator**.</span><span class="sxs-lookup"><span data-stu-id="efabf-208">From the list of running applications, determine the application to be killed and click on the **ID**.</span></span>

    <span data-ttu-id="efabf-209">![Kasowanie App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span><span class="sxs-lookup"><span data-stu-id="efabf-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="efabf-210">Kliknij przycisk **Kill aplikacji** w prawym górnym rogu, następnie kliknij polecenie **OK**.</span><span class="sxs-lookup"><span data-stu-id="efabf-210">Click **Kill Application** on the top right corner, then click **OK**.</span></span>

    <span data-ttu-id="efabf-211">![Kasowanie App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span><span class="sxs-lookup"><span data-stu-id="efabf-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="efabf-212">Zobacz też</span><span class="sxs-lookup"><span data-stu-id="efabf-212">See also</span></span>
* [<span data-ttu-id="efabf-213">Śledzenie i debugowanie zadań uruchamianych w klastrze Apache Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="efabf-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="efabf-214">Dla analityków danych</span><span class="sxs-lookup"><span data-stu-id="efabf-214">For data analysts</span></span>

* [<span data-ttu-id="efabf-215">Platforma Spark i usługa Machine Learning: korzystanie z platformy Spark w usłudze HDInsight do analizy temperatury w budynku z użyciem danych HVAC</span><span class="sxs-lookup"><span data-stu-id="efabf-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="efabf-216">Platforma Spark i usługa Machine Learning: korzystanie z platformy Spark w usłudze HDInsight do przewidywania wyników kontroli żywności</span><span class="sxs-lookup"><span data-stu-id="efabf-216">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="efabf-217">Analiza dzienników witryny sieci Web na platformie Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="efabf-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="efabf-218">Analiza danych telemetrycznych usługi Application Insight przy użyciu platformy Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="efabf-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="efabf-219">Użyj Caffe Azure HDInsight Spark dla rozproszonych learning bezpośrednich</span><span class="sxs-lookup"><span data-stu-id="efabf-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="efabf-220">Dla deweloperów platformy Spark</span><span class="sxs-lookup"><span data-stu-id="efabf-220">For Spark developers</span></span>

* [<span data-ttu-id="efabf-221">Tworzenie autonomicznych aplikacji przy użyciu języka Scala</span><span class="sxs-lookup"><span data-stu-id="efabf-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="efabf-222">Zdalne uruchamianie zadań w klastrze Spark przy użyciu programu Livy</span><span class="sxs-lookup"><span data-stu-id="efabf-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="efabf-223">Tworzenie i przesyłanie aplikacji Spark Scala przy użyciu dodatku HDInsight Tools Plugin for IntelliJ IDEA</span><span class="sxs-lookup"><span data-stu-id="efabf-223">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="efabf-224">Przesyłanie strumieniowe Spark: korzystanie z platformy Spark w usłudze HDInsight do tworzenia aplikacji do przesyłania strumieniowego w czasie rzeczywistym</span><span class="sxs-lookup"><span data-stu-id="efabf-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="efabf-225">Zdalne debugowanie aplikacji Spark przy użyciu dodatku HDInsight Tools Plugin for IntelliJ IDEA</span><span class="sxs-lookup"><span data-stu-id="efabf-225">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="efabf-226">Korzystanie z notesów Zeppelin w klastrze Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="efabf-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="efabf-227">Jądra dostępne dla notesu Jupyter w klastrze Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="efabf-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="efabf-228">Korzystanie z zewnętrznych pakietów z notesami Jupyter</span><span class="sxs-lookup"><span data-stu-id="efabf-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="efabf-229">Instalacja oprogramowania Jupyter na komputerze i nawiązywanie połączenia z klastrem Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="efabf-229">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

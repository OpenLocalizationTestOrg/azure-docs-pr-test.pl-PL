---
title: "Omówienie nauki danych przy użyciu platformy Spark w usłudze Azure HDInsight | Dokumentacja firmy Microsoft"
description: "Zestaw narzędzi platformy Spark MLlib łączy uczenia maszynowego znaczne modelowanie się środowisku rozproszonym usługi HDInsight."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 379b32f4e533f48f1593a97e73737a0c5bfb9135
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 07/11/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="9d2ac-103">Omówienie nauki danych przy użyciu platformy Spark w usłudze Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="9d2ac-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="9d2ac-104">Ten pakiet tematy przedstawia sposób użycia Spark w usłudze HDInsight do wykonywania typowych zadań analizy danych, takich jak wprowadzanie danych, funkcja engineering modelowania i oceny modelu.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-104">This suite of topics shows how to use HDInsight Spark to complete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="9d2ac-105">Dane używane jest przykładowe 2013 NYC taksówki podróży i taryfy zestawu danych.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-105">The data used is a sample of the 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="9d2ac-106">Modele wbudowane obejmują Regresja logistyczna i liniowych, losowe lasów i gradientu boosted drzewa.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-106">The models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="9d2ac-107">W tematach opisano również do przechowywania tych modeli w magazynie obiektów blob platformy Azure (WASB) oraz sposobu wynik i ocena wydajności predykcyjnej.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-107">The topics also show how to store these models in Azure blob storage (WASB) and how to score and evaluate their predictive performance.</span></span> <span data-ttu-id="9d2ac-108">Bardziej zaawansowanych tematów dotyczących opisano, jak można modeli uczenia przy użyciu kominów krzyżowego sprawdzania poprawności i parametru funkcji hyper.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="9d2ac-109">Ten temat odwołuje się również do tematów opisujących sposób konfigurowania klastra Spark, które należy wykonać czynności opisane w wskazówki podane.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-109">This overview topic also references the topics that describe how to set up the Spark cluster that you need to complete the steps in the walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="9d2ac-110">Platforma Spark i MLlib</span><span class="sxs-lookup"><span data-stu-id="9d2ac-110">Spark and MLlib</span></span>
<span data-ttu-id="9d2ac-111">[Platforma Spark](http://spark.apache.org/) jest przetwarzanie platforma przetwarzania równoległego open source, który obsługuje w pamięci w celu zwiększania wydajności aplikacji do analizy danych big data.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="9d2ac-112">Aparat przetwarzania Spark zaprojektowano pod kątem szybkości, łatwości użycia i zaawansowanych możliwości analitycznych.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-112">The Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="9d2ac-113">Możliwości rozproszone obliczenia w pamięci platforma Spark stanowić dobry wybór w przypadku algorytmów iteracyjnych w machine learning i obliczeniach na grafach.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-113">Spark's in-memory distributed computation capabilities make it a good choice for the iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="9d2ac-114">[MLlib](http://spark.apache.org/mllib/) jest platforma Spark skalowalne maszyny learning biblioteki wprowadzający algorytmicznego modelowanie tej środowisku rozproszonym.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings the algorithmic modeling capabilities to this distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="9d2ac-115">Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="9d2ac-115">HDInsight Spark</span></span>
<span data-ttu-id="9d2ac-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) jest platformy Azure hostowanej oferty open source platformy Spark.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is the Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="9d2ac-117">Obejmuje również obsługę **notesów Jupyter PySpark** w klastrze Spark, który można uruchomić interakcyjnych zapytań Spark SQL Przekształcanie, filtrowania i wizualizacja danych przechowywanych w obiektach blob Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-117">It also includes support for **Jupyter PySpark notebooks** on the Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="9d2ac-118">PySpark to interfejs API języka Python dla platformy Spark.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-118">PySpark is the Python API for Spark.</span></span> <span data-ttu-id="9d2ac-119">Wstawki kodu dostarczające rozwiązań i Pokaż odpowiednich powierzchni do wizualizacji danych w tym miejscu Uruchom w notesach Jupyter zainstalowany w klastrze Spark.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-119">The code snippets that provide the solutions and show the relevant plots to visualize the data here run in Jupyter notebooks installed on the Spark clusters.</span></span> <span data-ttu-id="9d2ac-120">Kroki modelowania w tych tematach zawiera kod, który pokazuje, jak uczenia, ocenić, zapisywania i korzystać z każdego typu modelu.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-120">The modeling steps in these topics contain code that shows how to train, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="9d2ac-121">Instalatora: Klastry Spark i notesów Jupyter</span><span class="sxs-lookup"><span data-stu-id="9d2ac-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="9d2ac-122">Kroki instalacji i kodu są dostępne w tym przewodniku dla przy użyciu wersji 1.6 HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="9d2ac-123">Ale notesów Jupyter znajdują się w przypadku klastrów HDInsight Spark 1.6 jak Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="9d2ac-124">Opis notesów i łącza do nich znajdują się w [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) dla repozytorium GitHub zawierające je.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-124">A description of the notebooks and links to them are provided in the [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for the GitHub repository containing them.</span></span> <span data-ttu-id="9d2ac-125">Ponadto kod w tym miejscu w notesach połączony jest rodzajowy i powinny działać na dowolnym klastra Spark.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-125">Moreover, the code here and in the linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="9d2ac-126">Jeśli nie używasz Spark w usłudze HDInsight, konfiguracja klastra i czynności administracyjne mogą być nieco inne niż to, co przedstawiono w tym miejscu.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-126">If you are not using HDInsight Spark, the cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="9d2ac-127">Dla wygody Oto łącza do notesu Jupyter w klastrze Spark w wersji 1.6 (do uruchomienia jądra pySpark serwera notesu Jupyter) i 2.0 Spark (do uruchomienia jądra pySpark3 serwera notesu Jupyter):</span><span class="sxs-lookup"><span data-stu-id="9d2ac-127">For convenience, here are the links to the Jupyter notebooks for Spark 1.6 (to be run in the pySpark kernel of the Jupyter Notebook server) and  Spark 2.0 (to be run in the pySpark3 kernel of the Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="9d2ac-128">Notesów Spark w wersji 1.6</span><span class="sxs-lookup"><span data-stu-id="9d2ac-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="9d2ac-129">Te komputery przenośne są uruchamiane w jądra pySpark serwera notesu Jupyter.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-129">These notebooks are to be run in the pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="9d2ac-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): zawiera informacje na temat sposobu wykonywania Eksploracja danych, modelowania i oceniania z kilku różnych algorytmów.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how to perform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="9d2ac-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): zawiera tematy w notesie #1 i tworzenia modelu przy użyciu hyperparameter dostrajanie i krzyżowego sprawdzania poprawności.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="9d2ac-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): pokazano, jak operacjonalizacji zapisany model przy użyciu języka Python w klastrach usługi HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how to operationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="9d2ac-133">Notesów Spark 2.0</span><span class="sxs-lookup"><span data-stu-id="9d2ac-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="9d2ac-134">Te komputery przenośne są uruchamiane w pySpark3 jądra serwera notesu Jupyter.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-134">These notebooks are to be run in the pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="9d2ac-135">[Spark2.0-pySpark3-Machine-Learning-Data-Science-Spark-Advanced-Data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): ten plik zawiera informacje na temat sposobu wykonywania Eksploracja danych, modelowania, i oceniania w Spark 2.0 klastrów za pomocą taksówki NYC podróży i taryfy zestawu danych opisane [tutaj](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how to perform data exploration, modeling, and scoring in Spark 2.0 clusters using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="9d2ac-136">Ten notes może być dobry punkt wyjścia do eksplorowania szybko kod, który firma Microsoft umieściła 2.0 Spark.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-136">This notebook may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> <span data-ttu-id="9d2ac-137">Dla bardziej szczegółowe notesu analizuje dane taksówki NYC, zobacz notesu dalej na tej liście.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-137">For a more detailed notebook analyzes the NYC Taxi data, see the next notebook in this list.</span></span> <span data-ttu-id="9d2ac-138">Zobacz uwagi na końcu tej listy pozwalające porównać te komputery przenośne.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-138">See the notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="9d2ac-139">[Spark2.0 pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): ten plik pokazano, jak wykonać danych wrangling (operacje Spark SQL i dataframe) eksploracji, modelowania i oceniania przy użyciu taksówki NYC podróży i taryfy zestawu danych opisane [tutaj](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="9d2ac-140">[Spark2.0 pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): ten plik pokazano, jak wykonać danych wrangling (operacje Spark SQL i dataframe) eksploracji, modelowania i oceniania przy użyciu znanych linii lotniczych na czas wyjścia zestawu danych z 2011 i 2012.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="9d2ac-141">Zintegrowane firma Microsoft linii lotniczych zestawu danych z danymi pogody lotniska (np. prędkość wiatru, temperatury, wysokość itp.) przed modelowania, więc te funkcje pogody można dołączyć do modelu.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-141">We integrated the airline dataset with the airport weather data (e.g. windspeed, temperature, altitude etc.) prior to modeling, so these weather features can be included in the model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="9d2ac-142">Zestaw danych linii lotniczych został dodany do notesów Spark 2.0, aby lepiej zilustrować użyciem algorytmów klasyfikacji.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-142">The airline dataset was added to the Spark 2.0 notebooks to better illustrate the use of classification algorithms.</span></span> <span data-ttu-id="9d2ac-143">Zobacz następujące linki do informacji na temat linii lotniczych na czas wyjścia zestawu danych i pogody dataset:</span><span class="sxs-lookup"><span data-stu-id="9d2ac-143">See the following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="9d2ac-144">Dane na czas wyjścia linii lotniczych: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="9d2ac-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="9d2ac-145">Dane pogody lotnisku: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="9d2ac-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="9d2ac-146">Notesy Spark 2.0 na NYC taksówkami i linii lotniczych transmitowane opóźnienie-zestawów danych może potrwać 10 minut lub dłużej (w zależności od wielkości klastra HDI).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-146">The Spark 2.0 notebooks on the NYC taxi and airline flight delay data-sets can take 10 mins or more to run (depending on the size of your HDI cluster).</span></span> <span data-ttu-id="9d2ac-147">Pierwszy notesu na powyższej liście zawiera wiele aspektów Eksploracja danych, wizualizacji i ML szkolenia w notesie, który zajmuje mniej czasu do uruchomienia z próbkowany dół NYC zestaw danych, w którym pliki taksówkami i taryfy zostały wstępnie dołączonego do modelu: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) tego notesu przyjmuje znacznie krótszy czas na zakończenie (2 – 3 min) i może być bardzo punkt początkowy dla szybko Eksploracja kodu, firma Microsoft umieściła 2.0 Spark.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-147">The first notebook in the above list shows many aspects of the data exploration, visualization and ML model training in a notebook that takes less time to run with down-sampled NYC data set, in which the taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time to finish (2-3 mins) and may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="9d2ac-148">Wskazówki dotyczące operationalization model Spark 2.0 i zużycia modelu do oceniania, zobacz [Spark 1.6 dokumentu o zużyciu](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) przykład zwijania kroki wymagane.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-148">For guidance on the operationalization of a Spark 2.0 model and model consumption for scoring, see the [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining the steps required.</span></span> <span data-ttu-id="9d2ac-149">Aby użyć tej funkcji na Spark 2.0, Zastąp plik kodu Python z [ten plik](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-149">To use this on Spark 2.0, replace the Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="9d2ac-150">Wymagania wstępne</span><span class="sxs-lookup"><span data-stu-id="9d2ac-150">Prerequisites</span></span>
<span data-ttu-id="9d2ac-151">Poniższe procedury dotyczą Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-151">The following procedures are related to Spark 1.6.</span></span> <span data-ttu-id="9d2ac-152">W wersji Spark 2.0 Użyj notesów opisane i połączone z wcześniej.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-152">For  the Spark 2.0 version, use the notebooks described and linked to previously.</span></span> 

<span data-ttu-id="9d2ac-153">1 użytkownik musi mieć subskrypcję platformy Azure.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="9d2ac-154">Jeśli nie masz już jeden, zobacz [Azure Pobierz bezpłatną wersję próbną](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="9d2ac-155">2. należy klastra Spark w wersji 1.6, w tym przewodniku.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-155">2.You need a Spark 1.6 cluster to complete this walkthrough.</span></span> <span data-ttu-id="9d2ac-156">Aby go utworzyć, zobacz instrukcje podane w [wprowadzenie: tworzenie Apache Spark w usłudze Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-156">To create one, see the instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="9d2ac-157">Typ klastra i wersji określonego z **wybierz typ klastra** menu.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-157">The cluster type and version is specified from the **Select Cluster Type** menu.</span></span> 

![Konfigurowanie klastra](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="9d2ac-159">Na temat, który przedstawia sposób użycia Scala zamiast Python do wykonywania zadań w procesie nauki danych na całej trasie, zobacz [nauki danych przy użyciu języka Scala z łącznikiem Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-159">For a topic that shows how to use Scala rather than Python to complete tasks for an end-to-end data science process, see the [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="the-nyc-2013-taxi-data"></a><span data-ttu-id="9d2ac-160">Dane NYC taksówki 2013</span><span class="sxs-lookup"><span data-stu-id="9d2ac-160">The NYC 2013 Taxi data</span></span>
<span data-ttu-id="9d2ac-161">Dane podróży taksówki NYC to około 20 GB skompresowanego wartości rozdzielanych przecinkami (CSV) plików (~ 48 GB nieskompresowane), składającej się z więcej niż 173 milionów poszczególnych podróży i opłaty płatnej dla każdej podróży.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-161">The NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and the fares paid for each trip.</span></span> <span data-ttu-id="9d2ac-162">Każdy rekord podróży obejmuje odbioru i przyjmowania lokalizacji i czasu, hack anonimowe (sterownik) numer licencji i numer Medalionu (taksówki jego unikatowy identyfikator).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-162">Each trip record includes the pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="9d2ac-163">Dane obejmuje wszystkie rund w roku 2013 i jest dostępne w następujących dwóch zestawów danych dla każdego miesiąca:</span><span class="sxs-lookup"><span data-stu-id="9d2ac-163">The data covers all trips in the year 2013 and is provided in the following two datasets for each month:</span></span>

1. <span data-ttu-id="9d2ac-164">Pliki CSV "trip_data" zawierają szczegóły podróży, takie jak liczba pasażerów, podnieś i dropoff punktów, rzeczy przed wyjazdem czas trwania i długości podróży.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-164">The 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="9d2ac-165">Poniżej przedstawiono kilka przykładowych rekordów:</span><span class="sxs-lookup"><span data-stu-id="9d2ac-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="9d2ac-166">Pliki CSV "trip_fare" zawierają szczegółowe informacje o klasie za każdym razem, takie jak typ płatności, kwota taryfy, przeciążenia i podatków, porady i przejazd i sumy płatnej.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-166">The 'trip_fare' CSV files contain details of the fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and the total amount paid.</span></span> <span data-ttu-id="9d2ac-167">Poniżej przedstawiono kilka przykładowych rekordów:</span><span class="sxs-lookup"><span data-stu-id="9d2ac-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="9d2ac-168">Firma Microsoft ma próbkę 0,1% tych plików i połączonych podróż\_danych i podróży\_taryfy CVS plików do jednego zestawu danych do użycia jako danych wejściowych dla tego przewodnika.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-168">We have taken a 0.1% sample of these files and joined the trip\_data and trip\_fare CVS files into a single dataset to use as the input dataset for this walkthrough.</span></span> <span data-ttu-id="9d2ac-169">Unikatowy klucz do przyłączenia podróży\_danych i podróży\_taryfy składa się z pola: Medalionu, hack\_licencji i pobrania\_daty/godziny.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-169">The unique key to join trip\_data and trip\_fare is composed of the fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="9d2ac-170">Każdy rekord zestaw danych zawiera następujące atrybuty reprezentujący podróży taksówki NYC:</span><span class="sxs-lookup"><span data-stu-id="9d2ac-170">Each record of the dataset contains the following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="9d2ac-171">Pole</span><span class="sxs-lookup"><span data-stu-id="9d2ac-171">Field</span></span> | <span data-ttu-id="9d2ac-172">Krótki opis</span><span class="sxs-lookup"><span data-stu-id="9d2ac-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="9d2ac-173">Medalionu</span><span class="sxs-lookup"><span data-stu-id="9d2ac-173">medallion</span></span> |<span data-ttu-id="9d2ac-174">Anonimowe taksówki Medalionu (taksówki Unikatowy identyfikator)</span><span class="sxs-lookup"><span data-stu-id="9d2ac-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="9d2ac-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="9d2ac-175">hack_license</span></span> |<span data-ttu-id="9d2ac-176">Numer licencji karetki Hackney anonimowe</span><span class="sxs-lookup"><span data-stu-id="9d2ac-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="9d2ac-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="9d2ac-177">vendor_id</span></span> |<span data-ttu-id="9d2ac-178">Identyfikator dostawcy taksówki</span><span class="sxs-lookup"><span data-stu-id="9d2ac-178">Taxi vendor id</span></span> |
| <span data-ttu-id="9d2ac-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="9d2ac-179">rate_code</span></span> |<span data-ttu-id="9d2ac-180">Szybkość taksówki NYC Taryfy</span><span class="sxs-lookup"><span data-stu-id="9d2ac-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="9d2ac-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="9d2ac-181">store_and_fwd_flag</span></span> |<span data-ttu-id="9d2ac-182">Magazyn i flagi do przodu</span><span class="sxs-lookup"><span data-stu-id="9d2ac-182">Store and forward flag</span></span> |
| <span data-ttu-id="9d2ac-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="9d2ac-183">pickup_datetime</span></span> |<span data-ttu-id="9d2ac-184">Wybierz datę i godzinę</span><span class="sxs-lookup"><span data-stu-id="9d2ac-184">Pick up date & time</span></span> |
| <span data-ttu-id="9d2ac-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="9d2ac-185">dropoff_datetime</span></span> |<span data-ttu-id="9d2ac-186">Dropoff wartość daty i godziny</span><span class="sxs-lookup"><span data-stu-id="9d2ac-186">Dropoff date & time</span></span> |
| <span data-ttu-id="9d2ac-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="9d2ac-187">pickup_hour</span></span> |<span data-ttu-id="9d2ac-188">Wybierz godzinę</span><span class="sxs-lookup"><span data-stu-id="9d2ac-188">Pick up hour</span></span> |
| <span data-ttu-id="9d2ac-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="9d2ac-189">pickup_week</span></span> |<span data-ttu-id="9d2ac-190">Wybierz tydzień roku</span><span class="sxs-lookup"><span data-stu-id="9d2ac-190">Pick up week of the year</span></span> |
| <span data-ttu-id="9d2ac-191">dzień tygodnia</span><span class="sxs-lookup"><span data-stu-id="9d2ac-191">weekday</span></span> |<span data-ttu-id="9d2ac-192">Dzień tygodnia (zakresu 1-7)</span><span class="sxs-lookup"><span data-stu-id="9d2ac-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="9d2ac-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="9d2ac-193">passenger_count</span></span> |<span data-ttu-id="9d2ac-194">Liczba osób w podróży taksówki</span><span class="sxs-lookup"><span data-stu-id="9d2ac-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="9d2ac-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="9d2ac-195">trip_time_in_secs</span></span> |<span data-ttu-id="9d2ac-196">Podróży czas w sekundach</span><span class="sxs-lookup"><span data-stu-id="9d2ac-196">Trip time in seconds</span></span> |
| <span data-ttu-id="9d2ac-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="9d2ac-197">trip_distance</span></span> |<span data-ttu-id="9d2ac-198">Dystans podróży w milach</span><span class="sxs-lookup"><span data-stu-id="9d2ac-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="9d2ac-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="9d2ac-199">pickup_longitude</span></span> |<span data-ttu-id="9d2ac-200">Wybierz długość geograficzna</span><span class="sxs-lookup"><span data-stu-id="9d2ac-200">Pick up longitude</span></span> |
| <span data-ttu-id="9d2ac-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="9d2ac-201">pickup_latitude</span></span> |<span data-ttu-id="9d2ac-202">Podnieś współrzędnych</span><span class="sxs-lookup"><span data-stu-id="9d2ac-202">Pick up latitude</span></span> |
| <span data-ttu-id="9d2ac-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="9d2ac-203">dropoff_longitude</span></span> |<span data-ttu-id="9d2ac-204">Długość geograficzna Dropoff</span><span class="sxs-lookup"><span data-stu-id="9d2ac-204">Dropoff longitude</span></span> |
| <span data-ttu-id="9d2ac-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="9d2ac-205">dropoff_latitude</span></span> |<span data-ttu-id="9d2ac-206">Współrzędne Dropoff</span><span class="sxs-lookup"><span data-stu-id="9d2ac-206">Dropoff latitude</span></span> |
| <span data-ttu-id="9d2ac-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="9d2ac-207">direct_distance</span></span> |<span data-ttu-id="9d2ac-208">Bezpośrednie odległość między pobrania w górę i lokalizacje dropoff</span><span class="sxs-lookup"><span data-stu-id="9d2ac-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="9d2ac-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="9d2ac-209">payment_type</span></span> |<span data-ttu-id="9d2ac-210">Typ płatności (urzędów certyfikacji, karta kredytowa itp.)</span><span class="sxs-lookup"><span data-stu-id="9d2ac-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="9d2ac-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="9d2ac-211">fare_amount</span></span> |<span data-ttu-id="9d2ac-212">Kwota taryfy w</span><span class="sxs-lookup"><span data-stu-id="9d2ac-212">Fare amount in</span></span> |
| <span data-ttu-id="9d2ac-213">Przeciążenia</span><span class="sxs-lookup"><span data-stu-id="9d2ac-213">surcharge</span></span> |<span data-ttu-id="9d2ac-214">Przeciążenia</span><span class="sxs-lookup"><span data-stu-id="9d2ac-214">Surcharge</span></span> |
| <span data-ttu-id="9d2ac-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="9d2ac-215">mta_tax</span></span> |<span data-ttu-id="9d2ac-216">Podatek MTA</span><span class="sxs-lookup"><span data-stu-id="9d2ac-216">Mta tax</span></span> |
| <span data-ttu-id="9d2ac-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="9d2ac-217">tip_amount</span></span> |<span data-ttu-id="9d2ac-218">Porada kwota</span><span class="sxs-lookup"><span data-stu-id="9d2ac-218">Tip amount</span></span> |
| <span data-ttu-id="9d2ac-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="9d2ac-219">tolls_amount</span></span> |<span data-ttu-id="9d2ac-220">Kwota przejazd</span><span class="sxs-lookup"><span data-stu-id="9d2ac-220">Tolls amount</span></span> |
| <span data-ttu-id="9d2ac-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="9d2ac-221">total_amount</span></span> |<span data-ttu-id="9d2ac-222">Suma</span><span class="sxs-lookup"><span data-stu-id="9d2ac-222">Total amount</span></span> |
| <span data-ttu-id="9d2ac-223">Przechylony</span><span class="sxs-lookup"><span data-stu-id="9d2ac-223">tipped</span></span> |<span data-ttu-id="9d2ac-224">Przechylony (0/1 dla nie lub tak)</span><span class="sxs-lookup"><span data-stu-id="9d2ac-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="9d2ac-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="9d2ac-225">tip_class</span></span> |<span data-ttu-id="9d2ac-226">Porada klasy (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span><span class="sxs-lookup"><span data-stu-id="9d2ac-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-the-spark-cluster"></a><span data-ttu-id="9d2ac-227">Wykonanie kodu z notesu Jupyter w klastrze Spark</span><span class="sxs-lookup"><span data-stu-id="9d2ac-227">Execute code from a Jupyter notebook on the Spark cluster</span></span>
<span data-ttu-id="9d2ac-228">Można uruchomić notesu Jupyter z portalu Azure.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-228">You can launch the Jupyter Notebook from the Azure portal.</span></span> <span data-ttu-id="9d2ac-229">Znajdź klastra Spark na pulpicie nawigacyjnym i kliknij go, aby wprowadzić strony zarządzania dla klastra.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-229">Find your Spark cluster on your dashboard and click it to enter management page for your cluster.</span></span> <span data-ttu-id="9d2ac-230">Aby otworzyć notesu skojarzony z klastrem Spark, kliknij przycisk **pulpitów nawigacyjnych klastrów** -> **notesu Jupyter** .</span><span class="sxs-lookup"><span data-stu-id="9d2ac-230">To open the notebook associated with the Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Pulpitów nawigacyjnych klastrów](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="9d2ac-232">Możesz również przejść do ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** do notesów Jupyter.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-232">You can also browse to ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** to access the Jupyter Notebooks.</span></span> <span data-ttu-id="9d2ac-233">Zamień na nazwę własnego klastra NAZWAKLASTRA częścią tego adresu URL.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-233">Replace the CLUSTERNAME part of this URL with the name of your own cluster.</span></span> <span data-ttu-id="9d2ac-234">Potrzebne hasło do konta administratora dostęp do notesów.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-234">You need the password for your admin account to access the notebooks.</span></span>

![Przeglądaj notesów Jupyter](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="9d2ac-236">Wybierz PySpark, aby wyświetlić katalog, który zawiera kilka przykładów opakowanych notebooki, które korzystają z interfejsu API PySpark. Notesy, które zawierają przykłady kodu dla tego zestawu Spark tematu są dostępne pod adresem [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="9d2ac-236">Select PySpark to see a directory that contains a few examples of pre-packaged notebooks that use the PySpark API.The notebooks that contain the code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="9d2ac-237">Możesz przekazać notesów bezpośrednio z [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) serwerowi notesu Jupyter w klastrze Spark.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-237">You can upload the notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) to the Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="9d2ac-238">Na stronie głównej programu Jupyter kliknij **przekazać** przycisk w prawej części ekranu.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-238">On the home page of your Jupyter, click the **Upload** button on the right part of the screen.</span></span> <span data-ttu-id="9d2ac-239">Spowoduje to otwarcie Eksploratora plików.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-239">It opens a file explorer.</span></span> <span data-ttu-id="9d2ac-240">W tym miejscu można wkleić adres URL GitHub (nieprzetworzonej zawartości) notesu i kliknij przycisk **Otwórz**.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-240">Here you can paste the GitHub (raw content) URL of the Notebook and click **Open**.</span></span> 

<span data-ttu-id="9d2ac-241">Nazwa pliku zostanie wyświetlony na liście plików Jupyter z **przekazać** przycisk ponownie.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-241">You see the file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="9d2ac-242">Kliknij tutaj, **przekazać** przycisku.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-242">Click this **Upload** button.</span></span> <span data-ttu-id="9d2ac-243">Teraz zaimportowano notesu.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-243">Now you have imported the notebook.</span></span> <span data-ttu-id="9d2ac-244">Powtórz te kroki, aby przekazać komputery przenośne z tego przewodnika.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-244">Repeat these steps to upload the other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="9d2ac-245">Możesz kliknąć prawym przyciskiem myszy łączy przeglądarki i wybierz **Kopiuj Link** uzyskanie github nieprzetworzonej zawartości adresu URL.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-245">You can right-click the links on your browser and select **Copy Link** to get the github raw content URL.</span></span> <span data-ttu-id="9d2ac-246">Ten adres URL można wkleić do okno dialogowe przekazywania Jupyter Eksploratora plików.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-246">You can paste this URL into the Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="9d2ac-247">Teraz możesz:</span><span class="sxs-lookup"><span data-stu-id="9d2ac-247">Now you can:</span></span>

* <span data-ttu-id="9d2ac-248">Aby wyświetlić kod, należy kliknąć notesu.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-248">See the code by clicking the notebook.</span></span>
* <span data-ttu-id="9d2ac-249">Wykonanie każdej komórki naciskając **wprowadź SHIFT**.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="9d2ac-250">Uruchom cały notes klikając **komórki** -> **Uruchom**.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-250">Run the entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="9d2ac-251">Użyj automatycznego wizualizacji zapytań.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-251">Use the automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="9d2ac-252">Jądro PySpark automatycznie wizualizuje wynik zapytania SQL (HiveQL).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-252">The PySpark kernel automatically visualizes the output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="9d2ac-253">Podano opcję, aby wybrać spośród kilku różnych typów wizualizacji (tabeli, kołowego, wiersz, obszar lub pasek) przy użyciu **typu** przycisków menu w notesie:</span><span class="sxs-lookup"><span data-stu-id="9d2ac-253">You are given the option to select among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using the **Type** menu buttons in the notebook:</span></span>
> 
> 

![Regresja logistyczna krzywą ROC dla metody ogólne](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="9d2ac-255">Co dalej?</span><span class="sxs-lookup"><span data-stu-id="9d2ac-255">What's next?</span></span>
<span data-ttu-id="9d2ac-256">Teraz, gdy są skonfigurowane z klastra Spark w usłudze HDInsight i zostały przekazane z notesów Jupyter, można przystąpić do pracy z tematami, które odpowiadają w notesach trzy PySpark.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-256">Now that you are set up with an HDInsight Spark cluster and have uploaded the Jupyter notebooks, you are ready to work through the topics that correspond to the three PySpark notebooks.</span></span> <span data-ttu-id="9d2ac-257">Przedstawiają sposób eksplorować dane, a następnie tworzenie i korzystanie z modeli.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-257">They show how to explore your data and then how to create and consume models.</span></span> <span data-ttu-id="9d2ac-258">Zaawansowane danych notesu eksploracji i modelowanie pokazuje, jak do uwzględnienia krzyżowego sprawdzania poprawności, funkcji hyper parametr profilach, a model oceny.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-258">The advanced data exploration and modeling notebook shows how to include cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="9d2ac-259">**Eksploracja danych i modelowanie z Spark:** Eksploruj zestawu danych i tworzenie, wynik i ocenić maszyny modeli uczenia przez pracy nad [Tworzenie binarnego klasyfikacji i regresji modeli danych narzędzi Spark MLlib](machine-learning-data-science-spark-data-exploration-modeling.md) tematu.</span><span class="sxs-lookup"><span data-stu-id="9d2ac-259">**Data Exploration and modeling with Spark:** Explore the dataset and create, score, and evaluate the machine learning models by working through the [Create binary classification and regression models for data with the Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="9d2ac-260">**Model zużycia:** informacje na temat wynik modele klasyfikacji i regresji, utworzone w tym temacie, zobacz [wynik i ocena modele uczenia wbudowane Spark maszyny](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="9d2ac-260">**Model consumption:** To learn how to score the classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="9d2ac-261">**Krzyżowe sprawdzanie poprawności i kominów hyperparameter**: zobacz [zaawansowane Eksploracja danych i modelowania z Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) na jak modeli można uczony przy użyciu kominów krzyżowego sprawdzania poprawności i parametru funkcji hyper</span><span class="sxs-lookup"><span data-stu-id="9d2ac-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>


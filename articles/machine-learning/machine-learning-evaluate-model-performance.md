---
title: "Ocena wydajności modelu w uczeniu maszynowym | Dokumentacja firmy Microsoft"
description: "Wyjaśniono, jak do oceny wydajności modelu w usłudze Azure Machine Learning."
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
ms.assetid: 5dc5348a-4488-4536-99eb-ff105be9b160
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/20/2017
ms.author: bradsev;garye
ms.openlocfilehash: d9576e0059f2e77a684e518389182e713f0a4f09
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 07/11/2017
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning"></a><span data-ttu-id="96f45-103">Ocenianie wydajności modelu w usłudze Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="96f45-103">How to evaluate model performance in Azure Machine Learning</span></span>
<span data-ttu-id="96f45-104">W tym artykule przedstawiono sposób oceny wydajności modelu w usłudze Azure Machine Learning Studio i zawiera krótki opis dostępnych metryk dla tego zadania.</span><span class="sxs-lookup"><span data-stu-id="96f45-104">This article demonstrates how to evaluate the performance of a model in Azure Machine Learning Studio and provides a brief explanation of the metrics available for this task.</span></span> <span data-ttu-id="96f45-105">Dostępne są trzy typowe scenariusze uczenia nadzorowanego:</span><span class="sxs-lookup"><span data-stu-id="96f45-105">Three common supervised learning scenarios are presented:</span></span> 

* <span data-ttu-id="96f45-106">Regresja</span><span class="sxs-lookup"><span data-stu-id="96f45-106">regression</span></span>
* <span data-ttu-id="96f45-107">klasyfikacji binarnej</span><span class="sxs-lookup"><span data-stu-id="96f45-107">binary classification</span></span> 
* <span data-ttu-id="96f45-108">wieloklasowej klasyfikacji</span><span class="sxs-lookup"><span data-stu-id="96f45-108">multiclass classification</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="96f45-109">Ocena wydajności modelu jest jednym z podstawowych etapów w procesie nauki danych.</span><span class="sxs-lookup"><span data-stu-id="96f45-109">Evaluating the performance of a model is one of the core stages in the data science process.</span></span> <span data-ttu-id="96f45-110">Wskazuje on, jak pomyślnie oceniania (prognoz) zestaw danych został uczonego modelu.</span><span class="sxs-lookup"><span data-stu-id="96f45-110">It indicates how successful the scoring (predictions) of a dataset has been by a trained model.</span></span> 

<span data-ttu-id="96f45-111">Azure Machine Learning obsługuje oceny modelu za pomocą dwóch jego głównej maszynie modułów szkoleniowych: [Evaluate Model] [ evaluate-model] i [krzyżowa Weryfikacja modelu][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="96f45-111">Azure Machine Learning supports model evaluation through two of its main machine learning modules: [Evaluate Model][evaluate-model] and [Cross-Validate Model][cross-validate-model].</span></span> <span data-ttu-id="96f45-112">Te moduły umożliwiają można zobaczyć, jak model wykonuje pod względem liczba metryki, które są często używane w uczeniu maszynowym i statystyki.</span><span class="sxs-lookup"><span data-stu-id="96f45-112">These modules allow you to see how your model performs in terms of a number of metrics that are commonly used in machine learning and statistics.</span></span>

## <a name="evaluation-vs-cross-validation"></a><span data-ttu-id="96f45-113">Ocena programu vs. Krzyżowe sprawdzanie poprawności</span><span class="sxs-lookup"><span data-stu-id="96f45-113">Evaluation vs. Cross Validation</span></span>
<span data-ttu-id="96f45-114">Ocena i krzyżowego sprawdzania poprawności metodami standardowa do pomiaru wydajności modelu.</span><span class="sxs-lookup"><span data-stu-id="96f45-114">Evaluation and cross validation are standard ways to measure the performance of your model.</span></span> <span data-ttu-id="96f45-115">Oba generować metryki oceny można sprawdzić lub porównać tych innych modeli.</span><span class="sxs-lookup"><span data-stu-id="96f45-115">They both generate evaluation metrics that you can inspect or compare against those of other models.</span></span>

<span data-ttu-id="96f45-116">[Ocena modelu] [ evaluate-model] oczekuje scored zestawu danych jako dane wejściowe (lub 2 w przypadku chcesz porównać wydajność różne modele 2).</span><span class="sxs-lookup"><span data-stu-id="96f45-116">[Evaluate Model][evaluate-model] expects a scored dataset as input (or 2 in case you would like to compare the performance of 2 different models).</span></span> <span data-ttu-id="96f45-117">To oznacza, że konieczne w celu przeszkolenia przy użyciu modelu [Train Model] [ train-model] modułu i dokonywać prognoz na niektórych zestawu danych za pomocą [Score Model] [ score-model] modułu, zanim będziesz w stanie ocenić wyniki.</span><span class="sxs-lookup"><span data-stu-id="96f45-117">This means that you need to train your model using the [Train Model][train-model] module and make predictions on some dataset using the [Score Model][score-model] module, before you can evaluate the results.</span></span> <span data-ttu-id="96f45-118">Obliczanie opiera się na scored etykiety/prawdopodobieństwa wraz z true etykiety, które są danymi wyjściowymi przygotowane przez [Score Model] [ score-model] modułu.</span><span class="sxs-lookup"><span data-stu-id="96f45-118">The evaluation is based on the scored labels/probabilities along with the true labels, all of which are output by the [Score Model][score-model] module.</span></span>

<span data-ttu-id="96f45-119">Alternatywnie służy krzyżowego sprawdzania poprawności do wykonywania wielu ocenić train wynik operacji (10 złożeń) automatycznie na różnych podzbiór danych wejściowych.</span><span class="sxs-lookup"><span data-stu-id="96f45-119">Alternatively, you can use cross validation to perform a number of train-score-evaluate operations (10 folds) automatically on different subsets of the input data.</span></span> <span data-ttu-id="96f45-120">Dane wejściowe jest podzielony na 10 części, w których jeden jest zastrzeżona na potrzeby testowania, a inne 9 szkolenia.</span><span class="sxs-lookup"><span data-stu-id="96f45-120">The input data is split into 10 parts, where one is reserved for testing, and the other 9 for training.</span></span> <span data-ttu-id="96f45-121">Ten proces jest powtarzany 10 razy, a metryki oceny zostały uśrednione.</span><span class="sxs-lookup"><span data-stu-id="96f45-121">This process is repeated 10 times and the evaluation metrics are averaged.</span></span> <span data-ttu-id="96f45-122">Pomaga to w określeniu, jak model czy generalize nowych obiektów DataSet.</span><span class="sxs-lookup"><span data-stu-id="96f45-122">This helps in determining how well a model would generalize to new datasets.</span></span> <span data-ttu-id="96f45-123">[Krzyżowa Weryfikacja modelu] [ cross-validate-model] moduł przyjmuje nieprzeszkolonych modelu i niektóre etykietą zestawu danych i zapisuje wyniki oceny każdego 10 złożeń, oprócz uśrednionej wyników.</span><span class="sxs-lookup"><span data-stu-id="96f45-123">The [Cross-Validate Model][cross-validate-model] module takes in an untrained model and some labeled dataset and outputs the evaluation results of each of the 10 folds, in addition to the averaged results.</span></span>

<span data-ttu-id="96f45-124">W poniższych sekcjach, firma Microsoft będzie utworzyć prosty modele regresji i klasyfikacji i oceny ich wydajności, za pomocą obu [Evaluate Model] [ evaluate-model] i [krzyżowa Weryfikacja modelu] [ cross-validate-model] modułów.</span><span class="sxs-lookup"><span data-stu-id="96f45-124">In the following sections, we will build simple regression and classification models and evaluate their performance, using both the [Evaluate Model][evaluate-model] and the [Cross-Validate Model][cross-validate-model] modules.</span></span>

## <a name="evaluating-a-regression-model"></a><span data-ttu-id="96f45-125">Ocena modelu regresji</span><span class="sxs-lookup"><span data-stu-id="96f45-125">Evaluating a Regression Model</span></span>
<span data-ttu-id="96f45-126">Załóżmy, że chcemy przewidzieć cenę samochodu korzystanie z niektórych funkcji, takich jak wymiary, moc, aparat specyfikacji i tak dalej.</span><span class="sxs-lookup"><span data-stu-id="96f45-126">Assume we want to predict a car’s price using some features such as dimensions, horsepower, engine specs, and so on.</span></span> <span data-ttu-id="96f45-127">Jest to problem typowe regresji, gdzie zmienna docelowa (*cen*) ciągłego wartość liczbową.</span><span class="sxs-lookup"><span data-stu-id="96f45-127">This is a typical regression problem, where the target variable (*price*) is a continuous numeric value.</span></span> <span data-ttu-id="96f45-128">Firma Microsoft może składać się modelu regresji liniowej proste, który podane wartości funkcji samochodu można przewidzieć cenę samochodu tego.</span><span class="sxs-lookup"><span data-stu-id="96f45-128">We can fit a simple linear regression model that, given the feature values of a certain car, can predict the price of that car.</span></span> <span data-ttu-id="96f45-129">Ten model regresji może służyć do tego samego zestawu danych, które firma Microsoft uczony na wynik.</span><span class="sxs-lookup"><span data-stu-id="96f45-129">This regression model can be used to score the same dataset we trained on.</span></span> <span data-ttu-id="96f45-130">Gdy mamy prognozowane ceny dla wszystkich samochodów, firma Microsoft oceny wydajności modelu, analizując ile prognozy różni się od rzeczywistej ceny średnio.</span><span class="sxs-lookup"><span data-stu-id="96f45-130">Once we have the predicted prices for all of the cars, we can evaluate the performance of the model by looking at how much the predictions deviate from the actual prices on average.</span></span> <span data-ttu-id="96f45-131">Na przykład używamy *Automobile price data (Raw) dataset* dostępne w **zapisane zestawów danych** sekcji w usłudze Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="96f45-131">To illustrate this, we use the *Automobile price data (Raw) dataset* available in the **Saved Datasets** section in Azure Machine Learning Studio.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="96f45-132">Tworzenie eksperymentu</span><span class="sxs-lookup"><span data-stu-id="96f45-132">Creating the Experiment</span></span>
<span data-ttu-id="96f45-133">Dodaj następujące moduły do swojego obszaru roboczego w usłudze Azure Machine Learning Studio:</span><span class="sxs-lookup"><span data-stu-id="96f45-133">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="96f45-134">Cen samochodów, data (Raw)</span><span class="sxs-lookup"><span data-stu-id="96f45-134">Automobile price data (Raw)</span></span>
* <span data-ttu-id="96f45-135">[Regresja liniowa][linear-regression]</span><span class="sxs-lookup"><span data-stu-id="96f45-135">[Linear Regression][linear-regression]</span></span>
* <span data-ttu-id="96f45-136">[Train Model][train-model]</span><span class="sxs-lookup"><span data-stu-id="96f45-136">[Train Model][train-model]</span></span>
* <span data-ttu-id="96f45-137">[Score Model][score-model]</span><span class="sxs-lookup"><span data-stu-id="96f45-137">[Score Model][score-model]</span></span>
* <span data-ttu-id="96f45-138">[Ocena modelu][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="96f45-138">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="96f45-139">Połącz porty, jak pokazano poniżej na rysunku 1 i zestawu kolumn etykiety z [Train Model] [ train-model] moduł *cen*.</span><span class="sxs-lookup"><span data-stu-id="96f45-139">Connect the ports as shown below in Figure 1 and set the Label column of the [Train Model][train-model] module to *price*.</span></span>

![Ocena modelu regresji](media/machine-learning-evaluate-model-performance/1.png)

<span data-ttu-id="96f45-141">Rysunek 1.</span><span class="sxs-lookup"><span data-stu-id="96f45-141">Figure 1.</span></span> <span data-ttu-id="96f45-142">Ocena modelu regresji.</span><span class="sxs-lookup"><span data-stu-id="96f45-142">Evaluating a Regression Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="96f45-143">Sprawdzanie wyników oceny</span><span class="sxs-lookup"><span data-stu-id="96f45-143">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="96f45-144">Po zakończeniu eksperymentu, możesz kliknąć portem wyjściowym [Evaluate Model] [ evaluate-model] moduł i zaznacz *wizualizacja* Aby wyświetlić wyniki oceny.</span><span class="sxs-lookup"><span data-stu-id="96f45-144">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results.</span></span> <span data-ttu-id="96f45-145">Jest dostępna dla modeli regresji metryki oceny: *oznacza błąd absolutny*, *głównego oznacza błąd absolutny*, *względny błąd absolutny*, *względny błąd kwadrat*i *współczynnika determinacji*.</span><span class="sxs-lookup"><span data-stu-id="96f45-145">The evaluation metrics available for regression models are: *Mean Absolute Error*, *Root Mean Absolute Error*, *Relative Absolute Error*, *Relative Squared Error*, and the *Coefficient of Determination*.</span></span>

<span data-ttu-id="96f45-146">Termin "błąd" w tym miejscu reprezentuje różnicę między wartością prognozowaną a wartością true.</span><span class="sxs-lookup"><span data-stu-id="96f45-146">The term "error" here represents the difference between the predicted value and the true value.</span></span> <span data-ttu-id="96f45-147">Wartość bezwzględna lub kwadrat tej różnicy zwykle są obliczane do przechwytywania całkowita wielkość błędu we wszystkich wystąpieniach, jako różnica między wartością przewidywane i wartość true, może być liczbą ujemną, w niektórych przypadkach.</span><span class="sxs-lookup"><span data-stu-id="96f45-147">The absolute value or the square of this difference are usually computed to capture the total magnitude of error across all instances, as the difference between the predicted and true value could be negative in some cases.</span></span> <span data-ttu-id="96f45-148">Błąd metryki pomiaru wydajności predykcyjnej modelu regresji pod względem odchylenie średniej jego prognoz z wartości true.</span><span class="sxs-lookup"><span data-stu-id="96f45-148">The error metrics measure the predictive performance of a regression model in terms of the mean deviation of its predictions from the true values.</span></span> <span data-ttu-id="96f45-149">Niższe wartości błąd oznacza, że model jest dokładniejszych prognoz zgłoszenia.</span><span class="sxs-lookup"><span data-stu-id="96f45-149">Lower error values mean the model is more accurate in making predictions.</span></span> <span data-ttu-id="96f45-150">Ogólny błąd metrykę 0 oznacza, że modelu dopasowany danych.</span><span class="sxs-lookup"><span data-stu-id="96f45-150">An overall error metric of 0 means that the model fits the data perfectly.</span></span>

<span data-ttu-id="96f45-151">Współczynnik determinacji, który jest również nazywany R-kwadrat, jest również standardowy sposób pomiaru, jak również dopasowanie do danych w modelu.</span><span class="sxs-lookup"><span data-stu-id="96f45-151">The coefficient of determination, which is also known as R squared, is also a standard way of measuring how well the model fits the data.</span></span> <span data-ttu-id="96f45-152">Mogą być interpretowane jako część odmiany wyjaśnione przy użyciu modelu.</span><span class="sxs-lookup"><span data-stu-id="96f45-152">It can be interpreted as the proportion of variation explained by the model.</span></span> <span data-ttu-id="96f45-153">Wyższy udział jest lepszym rozwiązaniem w przypadku gdzie 1 oznacza, dokładne dopasowanie.</span><span class="sxs-lookup"><span data-stu-id="96f45-153">A higher proportion is better in this case, where 1 indicates a perfect fit.</span></span>

![Metryki oceny regresji liniowej](media/machine-learning-evaluate-model-performance/2.png)

<span data-ttu-id="96f45-155">Rysunek 2.</span><span class="sxs-lookup"><span data-stu-id="96f45-155">Figure 2.</span></span> <span data-ttu-id="96f45-156">Metryki oceny regresji liniowej.</span><span class="sxs-lookup"><span data-stu-id="96f45-156">Linear Regression Evaluation Metrics.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="96f45-157">Za pomocą innej sprawdzania poprawności</span><span class="sxs-lookup"><span data-stu-id="96f45-157">Using Cross Validation</span></span>
<span data-ttu-id="96f45-158">Jak wspomniano wcześniej, można wykonać powtarzane szkolenia, ocenianie i oceny automatycznie za pomocą [krzyżowa Weryfikacja modelu] [ cross-validate-model] modułu.</span><span class="sxs-lookup"><span data-stu-id="96f45-158">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="96f45-159">W takim przypadku wystarczy zestawu danych, model nieprzeszkolonych i [krzyżowa Weryfikacja modelu] [ cross-validate-model] modułu (zobacz rysunek poniżej).</span><span class="sxs-lookup"><span data-stu-id="96f45-159">All you need in this case is a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="96f45-160">Uwaga: należy ustawić etykiety kolumn *cen* w [krzyżowa Weryfikacja modelu] [ cross-validate-model] właściwości modułu.</span><span class="sxs-lookup"><span data-stu-id="96f45-160">Note that you need to set the label column to *price* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span>

![Krzyżowe sprawdzanie modelu regresji](media/machine-learning-evaluate-model-performance/3.png)

<span data-ttu-id="96f45-162">Rysunek 3.</span><span class="sxs-lookup"><span data-stu-id="96f45-162">Figure 3.</span></span> <span data-ttu-id="96f45-163">Weryfikowanie między modelu regresji.</span><span class="sxs-lookup"><span data-stu-id="96f45-163">Cross-Validating a Regression Model.</span></span>

<span data-ttu-id="96f45-164">Po zakończeniu eksperymentu, możesz sprawdzić wyniki oceny, kliknij port wyjściowy prawo [krzyżowa Weryfikacja modelu] [ cross-validate-model] modułu.</span><span class="sxs-lookup"><span data-stu-id="96f45-164">After running the experiment, you can inspect the evaluation results by clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="96f45-165">Zapewni to szczegółowy widok metryki dla każdej iteracji (złożenia) i uśrednionej wyniki każdego z metryki (4 rysunek).</span><span class="sxs-lookup"><span data-stu-id="96f45-165">This will provide a detailed view of the metrics for each iteration (fold), and the averaged results of each of the metrics (Figure 4).</span></span>

![Wyników krzyżowego sprawdzania poprawności modelu regresji](media/machine-learning-evaluate-model-performance/4.png)

<span data-ttu-id="96f45-167">Rysunek 4.</span><span class="sxs-lookup"><span data-stu-id="96f45-167">Figure 4.</span></span> <span data-ttu-id="96f45-168">Wyników krzyżowego sprawdzania poprawności modelu regresji.</span><span class="sxs-lookup"><span data-stu-id="96f45-168">Cross-Validation Results of a Regression Model.</span></span>

## <a name="evaluating-a-binary-classification-model"></a><span data-ttu-id="96f45-169">Ocena modelu klasyfikacji binarnej</span><span class="sxs-lookup"><span data-stu-id="96f45-169">Evaluating a Binary Classification Model</span></span>
<span data-ttu-id="96f45-170">W przypadku klasyfikacji binarnej Zmienna docelowa ma tylko dwa możliwe wyniki, na przykład: {0, 1} lub {false, wartość true}, {ujemną, dodatnią}.</span><span class="sxs-lookup"><span data-stu-id="96f45-170">In a binary classification scenario, the target variable has only two possible outcomes, for example: {0, 1} or {false, true}, {negative, positive}.</span></span> <span data-ttu-id="96f45-171">Załóżmy, można skorzystać z zestawu danych dla dorosłych pracowników z niektórych demograficznych i zmienne zatrudnienia oraz prośba do prognozowania poziomu dochodu binarne zmiennej o wartości {"< = 50K", "> 50K"}.</span><span class="sxs-lookup"><span data-stu-id="96f45-171">Assume you are given a dataset of adult employees with some demographic and employment variables, and that you are asked to predict the income level, a binary variable with the values {“<=50K”, “>50K”}.</span></span> <span data-ttu-id="96f45-172">Innymi słowy ujemna klasy reprezentuje pracowników, którzy tworzą mniejsza lub równa 50K rocznie, a klasa dodatnią — wszystkich innych pracowników.</span><span class="sxs-lookup"><span data-stu-id="96f45-172">In other words, the negative class represents the employees who make less than or equal to 50K per year, and the positive class represents all other employees.</span></span> <span data-ttu-id="96f45-173">Jak w scenariuszu regresji firma Microsoft będzie nauczenia modelu, wynik niektóre dane i ocena wyników.</span><span class="sxs-lookup"><span data-stu-id="96f45-173">As in the regression scenario, we would train a model, score some data, and evaluate the results.</span></span> <span data-ttu-id="96f45-174">Główną różnicą jest wybór metryki, który oblicza uczenie maszynowe Azure i danych wyjściowych.</span><span class="sxs-lookup"><span data-stu-id="96f45-174">The main difference here is the choice of metrics Azure Machine Learning computes and outputs.</span></span> <span data-ttu-id="96f45-175">Aby zilustrować scenariusz poziomu prognozowania przychodów, będziemy używać [dla dorosłych](http://archive.ics.uci.edu/ml/datasets/Adult) zestawu danych do tworzenia eksperymentu uczenia maszynowego Azure i oceny wydajności modelu Regresja logistyczna dwuklasowych, często używane klasyfikatora binarnego.</span><span class="sxs-lookup"><span data-stu-id="96f45-175">To illustrate the income level prediction scenario, we will use the [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) dataset to create an Azure Machine Learning experiment and evaluate the performance of a two-class logistic regression model, a commonly used binary classifier.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="96f45-176">Tworzenie eksperymentu</span><span class="sxs-lookup"><span data-stu-id="96f45-176">Creating the Experiment</span></span>
<span data-ttu-id="96f45-177">Dodaj następujące moduły do swojego obszaru roboczego w usłudze Azure Machine Learning Studio:</span><span class="sxs-lookup"><span data-stu-id="96f45-177">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="96f45-178">Dla dorosłych klasyfikacji binarnej dochodu spisu zestawu danych.</span><span class="sxs-lookup"><span data-stu-id="96f45-178">Adult Census Income Binary Classification dataset</span></span>
* <span data-ttu-id="96f45-179">[Regresja logistyczna Two-Class][two-class-logistic-regression]</span><span class="sxs-lookup"><span data-stu-id="96f45-179">[Two-Class Logistic Regression][two-class-logistic-regression]</span></span>
* <span data-ttu-id="96f45-180">[Train Model][train-model]</span><span class="sxs-lookup"><span data-stu-id="96f45-180">[Train Model][train-model]</span></span>
* <span data-ttu-id="96f45-181">[Score Model][score-model]</span><span class="sxs-lookup"><span data-stu-id="96f45-181">[Score Model][score-model]</span></span>
* <span data-ttu-id="96f45-182">[Ocena modelu][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="96f45-182">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="96f45-183">Połącz porty, jak pokazano poniżej na rysunku 5 i zestawu kolumn etykiety z [Train Model] [ train-model] moduł *dochodu*.</span><span class="sxs-lookup"><span data-stu-id="96f45-183">Connect the ports as shown below in Figure 5 and set the Label column of the [Train Model][train-model] module to *income*.</span></span>

![Ocena modelu klasyfikacji binarnej](media/machine-learning-evaluate-model-performance/5.png)

<span data-ttu-id="96f45-185">Rysunek 5.</span><span class="sxs-lookup"><span data-stu-id="96f45-185">Figure 5.</span></span> <span data-ttu-id="96f45-186">Ocena modelu klasyfikacji binarnej.</span><span class="sxs-lookup"><span data-stu-id="96f45-186">Evaluating a Binary Classification Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="96f45-187">Sprawdzanie wyników oceny</span><span class="sxs-lookup"><span data-stu-id="96f45-187">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="96f45-188">Po zakończeniu eksperymentu, możesz kliknąć portem wyjściowym [Evaluate Model] [ evaluate-model] moduł i zaznacz *wizualizacja* Aby wyświetlić wyniki oceny (rysunek 7).</span><span class="sxs-lookup"><span data-stu-id="96f45-188">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results (Figure 7).</span></span> <span data-ttu-id="96f45-189">Jest dostępna dla modeli klasyfikacji binarnej metryki oceny: *dokładność*, *dokładności*, *odwołania*, *F1 oceny*, i *AUC*.</span><span class="sxs-lookup"><span data-stu-id="96f45-189">The evaluation metrics available for binary classification models are: *Accuracy*, *Precision*, *Recall*, *F1 Score*, and *AUC*.</span></span> <span data-ttu-id="96f45-190">Ponadto moduł generuje macierzy pomyłek, wyświetlana jest liczba alarmów wartość true, fałszywych wyników negatywnych fałszywych alarmów i negatywów wartość true, a także *ROC*, *dokładności/wycofania*, i *Podnieś* krzywych.</span><span class="sxs-lookup"><span data-stu-id="96f45-190">In addition, the module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as *ROC*, *Precision/Recall*, and *Lift* curves.</span></span>

<span data-ttu-id="96f45-191">Dokładność jest po prostu część poprawnie klasyfikowane wystąpień.</span><span class="sxs-lookup"><span data-stu-id="96f45-191">Accuracy is simply the proportion of correctly classified instances.</span></span> <span data-ttu-id="96f45-192">Zazwyczaj jest pierwszym metrykę, które można przyjrzeć się podczas obliczania klasyfikatora.</span><span class="sxs-lookup"><span data-stu-id="96f45-192">It is usually the first metric you look at when evaluating a classifier.</span></span> <span data-ttu-id="96f45-193">Jednakże, gdy dane testowe jest niezrównoważone (gdzie większość wystąpień należą do jednej z klas) lub więcej planuje w czasie wykonywania na jedną z klas, dokładność naprawdę nie przechwytuje skuteczności klasyfikatora.</span><span class="sxs-lookup"><span data-stu-id="96f45-193">However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn’t really capture the effectiveness of a classifier.</span></span> <span data-ttu-id="96f45-194">W tym scenariuszu poziomu klasyfikacji przychodów przyjęto założenie, że podczas testowania niektórych danych, w którym 99% wystąpień reprezentują osoby, tym mniejsza lub równa 50 K rocznie.</span><span class="sxs-lookup"><span data-stu-id="96f45-194">In the income level classification scenario, assume you are testing on some data where 99% of the instances represent people who earn less than or equal to 50K per year.</span></span> <span data-ttu-id="96f45-195">Istnieje możliwość uzyskania 0.99 dokładność przez klasę "< = 50K" dla wszystkich wystąpień.</span><span class="sxs-lookup"><span data-stu-id="96f45-195">It is possible to achieve a 0.99 accuracy by predicting the class “<=50K” for all instances.</span></span> <span data-ttu-id="96f45-196">Klasyfikator w takim przypadku wydaje się być wysoki poziom ogólnej, ale w rzeczywistości nie jest on klasyfikowania tych osób high-income (1%) poprawnie.</span><span class="sxs-lookup"><span data-stu-id="96f45-196">The classifier in this case appears to be doing a good job overall, but in reality, it fails to classify any of the high-income individuals (the 1%) correctly.</span></span>

<span data-ttu-id="96f45-197">Z tego powodu warto obliczeniowe dodatkowe metryki przechwytywania dokładniej aspektów oceny.</span><span class="sxs-lookup"><span data-stu-id="96f45-197">For that reason, it is helpful to compute additional metrics that capture more specific aspects of the evaluation.</span></span> <span data-ttu-id="96f45-198">Przed przejściem do szczegółów tych metryk, ważne jest zrozumienie macierzy pomyłek oceny klasyfikacji binarnej.</span><span class="sxs-lookup"><span data-stu-id="96f45-198">Before going into the details of such metrics, it is important to understand the confusion matrix of a binary classification evaluation.</span></span> <span data-ttu-id="96f45-199">Klasy etykiet w zestawie szkolenia może zająć tylko 2 możliwych wartości, które są zazwyczaj zwane jako dodatnią lub ujemną.</span><span class="sxs-lookup"><span data-stu-id="96f45-199">The class labels in the training set can take on only 2 possible values, which we usually refer to as positive or negative.</span></span> <span data-ttu-id="96f45-200">Dodatnie i ujemne wystąpienia, które klasyfikatora prognozuje poprawnie są nazywane odpowiednio alarmów true (TP) i true negatywów (TN).</span><span class="sxs-lookup"><span data-stu-id="96f45-200">The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively.</span></span> <span data-ttu-id="96f45-201">Podobnie nazywane są niepoprawnie niejawnych wystąpień fałszywych alarmów (FP) i fałszywych wyników negatywnych (FN).</span><span class="sxs-lookup"><span data-stu-id="96f45-201">Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</span></span> <span data-ttu-id="96f45-202">Macierz pomyłek jest po prostu tabelę przedstawiającą liczba wystąpień, które są objęte każdej z tych kategorii 4.</span><span class="sxs-lookup"><span data-stu-id="96f45-202">The confusion matrix is simply a table showing the number of instances that fall under each of these 4 categories.</span></span> <span data-ttu-id="96f45-203">Usługa Azure Machine Learning automatycznie decyduje, które dwie klasy w zestawie danych jest dodatnią klasy.</span><span class="sxs-lookup"><span data-stu-id="96f45-203">Azure Machine Learning automatically decides which of the two classes in the dataset is the positive class.</span></span> <span data-ttu-id="96f45-204">W przypadku typu Boolean lub liczb całkowitych etykiety klasy wystąpień etykietą "prawda" lub "1" są przypisywane dodatnią klasy.</span><span class="sxs-lookup"><span data-stu-id="96f45-204">If the class labels are Boolean or integers, then the ‘true’ or ‘1’ labeled instances are assigned the positive class.</span></span> <span data-ttu-id="96f45-205">Jeśli etykiety są ciągami, tak jak w przypadku zestawu danych przychodów, etykiety są posortowane alfabetycznie i pierwszy poziom jest wybierany jest ujemny klasy, podczas gdy drugi poziom jest dodatnią klasy.</span><span class="sxs-lookup"><span data-stu-id="96f45-205">If the labels are strings, as in the case of the income dataset, the labels are sorted alphabetically and the first level is chosen to be the negative class while the second level is the positive class.</span></span>

![Macierz pomyłek klasyfikacji binarnej](media/machine-learning-evaluate-model-performance/6a.png)

<span data-ttu-id="96f45-207">Rysunek 6.</span><span class="sxs-lookup"><span data-stu-id="96f45-207">Figure 6.</span></span> <span data-ttu-id="96f45-208">Macierz pomyłek klasyfikacji binarnej.</span><span class="sxs-lookup"><span data-stu-id="96f45-208">Binary Classification Confusion Matrix.</span></span>

<span data-ttu-id="96f45-209">Po powrocie do dochodu problemu klasyfikacji, czy chcemy z pytaniem, czy kilka oceny pytania, które pomagają nam zrozumieć wydajności klasyfikatora używane.</span><span class="sxs-lookup"><span data-stu-id="96f45-209">Going back to the income classification problem, we would want to ask several evaluation questions that help us understand the performance of the classifier used.</span></span> <span data-ttu-id="96f45-210">Jest bardzo fizycznych zapytania: ' poza osób, którym modelu przewidzieć z uzyskaniem można > 50 K (TP + FP), ile zostały poprawnie klasyfikowane (TP)? "</span><span class="sxs-lookup"><span data-stu-id="96f45-210">A very natural question is: ‘Out of the individuals whom the model predicted to be earning >50K (TP+FP), how many were classified correctly (TP)?’</span></span> <span data-ttu-id="96f45-211">To pytanie można udzielić odpowiedzi, analizując **dokładności** modelu, który jest część alarmów, które są poprawnie klasyfikowane: TP/(TP+FP).</span><span class="sxs-lookup"><span data-stu-id="96f45-211">This question can be answered by looking at the **Precision** of the model, which is the proportion of positives that are classified correctly: TP/(TP+FP).</span></span> <span data-ttu-id="96f45-212">Jest inny, często zadawane pytania "poza wszystkich wysokiej zdobywanie pracownikom dochodu > 50 k (TP + FN), ile Klasyfikator klasyfikowania poprawnie (TP)".</span><span class="sxs-lookup"><span data-stu-id="96f45-212">Another common question is “Out of all the high earning employees with income >50k (TP+FN), how many did the classifier classify correctly (TP)”.</span></span> <span data-ttu-id="96f45-213">To w rzeczywistości **odwołania**, lub wartość true, szybkość dodatnią: TP/(TP+FN) klasyfikatora.</span><span class="sxs-lookup"><span data-stu-id="96f45-213">This is actually the **Recall**, or the true positive rate: TP/(TP+FN) of the classifier.</span></span> <span data-ttu-id="96f45-214">Może się okazać, czy znajduje się oczywiste kompromis między precision i odwołania.</span><span class="sxs-lookup"><span data-stu-id="96f45-214">You might notice that there is an obvious trade-off between precision and recall.</span></span> <span data-ttu-id="96f45-215">Na przykład podana stosunkowo zrównoważonym zestawu danych, klasyfikatora, który prognozuje przede wszystkim dodatnią wystąpień byłyby wysokiej odwołania, ale raczej niski dokładności jako wiele wystąpień ujemna będzie można nieprawidłowo klasyfikowana powodujące dużą liczbę fałszywych alarmów.</span><span class="sxs-lookup"><span data-stu-id="96f45-215">For example, given a relatively balanced dataset, a classifier that predicts mostly positive instances, would have a high recall, but a rather low precision as many of the negative instances would be misclassified resulting in a large number of false positives.</span></span> <span data-ttu-id="96f45-216">Aby zobaczyć, jak te dwie metryki w zależności od wykres, możesz kliknąć krzywą "Dokładności/ODWOŁAŃ" w danych wyjściowych strony wyników oceny (u góry po lewej części rysunek 7).</span><span class="sxs-lookup"><span data-stu-id="96f45-216">To see a plot of how these two metrics vary, you can click on the ‘PRECISION/RECALL’ curve in the evaluation result output page (top left part of Figure 7).</span></span>

![Wyniki oceny klasyfikacji binarnej](media/machine-learning-evaluate-model-performance/7.png)

<span data-ttu-id="96f45-218">Rysunek 7.</span><span class="sxs-lookup"><span data-stu-id="96f45-218">Figure 7.</span></span> <span data-ttu-id="96f45-219">Wyniki oceny klasyfikacji binarnej.</span><span class="sxs-lookup"><span data-stu-id="96f45-219">Binary Classification Evaluation Results.</span></span>

<span data-ttu-id="96f45-220">Inny powiązane metryki, która jest często używana jest **F1 oceny**, który przyjmuje zarówno precision i odwołania pod uwagę.</span><span class="sxs-lookup"><span data-stu-id="96f45-220">Another related metric that is often used is the **F1 Score**, which takes both precision and recall into consideration.</span></span> <span data-ttu-id="96f45-221">Jest harmoniczną tych metryk 2 i jest obliczana tak: F1 = 2 (precyzja x odwołania) / (precyzja + odwołania).</span><span class="sxs-lookup"><span data-stu-id="96f45-221">It is the harmonic mean of these 2 metrics and is computed as such: F1 = 2 (precision x recall) / (precision + recall).</span></span> <span data-ttu-id="96f45-222">Wynik F1 jest dobrym sposobem podsumowanie oceny w jeden numer, ale zawsze jest dobrym rozwiązaniem, aby przyjrzeć się zarówno precision i odwołania ze sobą, aby lepiej zrozumieć, jak ma zachowywać się klasyfikatora.</span><span class="sxs-lookup"><span data-stu-id="96f45-222">The F1 score is a good way to summarize the evaluation in a single number, but it’s always a good practice to look at both precision and recall together to better understand how a classifier behaves.</span></span>

<span data-ttu-id="96f45-223">Ponadto jedną sprawdzić stopa dodatnią wartość true, a szybkości dodatnią wartość false w **odbiornika operacyjnego cechy (ROC)** krzywej i odpowiadający mu **obszar w krzywej (AUC)** wartość.</span><span class="sxs-lookup"><span data-stu-id="96f45-223">In addition, one can inspect the true positive rate vs. the false positive rate in the **Receiver Operating Characteristic (ROC)** curve and the corresponding **Area Under the Curve (AUC)** value.</span></span> <span data-ttu-id="96f45-224">Bliższe krzywej lewym górnym rogu, tym lepsza wydajność klasyfikatora jest (który jest maksymalizacja stopa dodatnią wartość true, przy jednoczesnym zmniejszeniu stopa dodatnią wartość false).</span><span class="sxs-lookup"><span data-stu-id="96f45-224">The closer this curve is to the upper left corner, the better the classifier’s performance is (that is maximizing the true positive rate while minimizing the false positive rate).</span></span> <span data-ttu-id="96f45-225">Krzywe zbliża się przekątnej wykresu, w wyniku klasyfikatory, które mają na celu tworzenia prognoz, które wkrótce odgadnięcie losowych.</span><span class="sxs-lookup"><span data-stu-id="96f45-225">Curves that are close to the diagonal of the plot, result from classifiers that tend to make predictions that are close to random guessing.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="96f45-226">Za pomocą innej sprawdzania poprawności</span><span class="sxs-lookup"><span data-stu-id="96f45-226">Using Cross Validation</span></span>
<span data-ttu-id="96f45-227">Jak pokazano w przykładzie regresji oferujemy krzyżowego sprawdzania poprawności wielokrotnie uczenia, oceny i automatycznie oceny różnych podzbiór danych.</span><span class="sxs-lookup"><span data-stu-id="96f45-227">As in the regression example, we can perform cross validation to repeatedly train, score and evaluate different subsets of the data automatically.</span></span> <span data-ttu-id="96f45-228">Podobnie, możemy użyć [krzyżowa Weryfikacja modelu] [ cross-validate-model] modułu, model nieprzeszkolonych Regresja logistyczna i zestawu danych.</span><span class="sxs-lookup"><span data-stu-id="96f45-228">Similarly, we can use the [Cross-Validate Model][cross-validate-model] module, an untrained logistic regression model, and a dataset.</span></span> <span data-ttu-id="96f45-229">Kolumna etykiety musi być ustawiona na *dochodu* w [krzyżowa Weryfikacja modelu] [ cross-validate-model] właściwości modułu.</span><span class="sxs-lookup"><span data-stu-id="96f45-229">The label column must be set to *income* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span> <span data-ttu-id="96f45-230">Po wykonać eksperyment, a następnie klikając polecenie po prawej stronie output port [krzyżowa Weryfikacja modelu] [ cross-validate-model] modułu, widać, wartości metryki klasyfikacji binarnej dla każdego złożenia dodatkowo średnią i odchylenie standardowe wszystkich.</span><span class="sxs-lookup"><span data-stu-id="96f45-230">After running the experiment and clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module, we can see the binary classification metric values for each fold, in addition to the mean and standard deviation of each.</span></span> 

![Cross-sprawdzanie poprawności modelu klasyfikacji binarnej](media/machine-learning-evaluate-model-performance/8.png)

<span data-ttu-id="96f45-232">Rysunek 8.</span><span class="sxs-lookup"><span data-stu-id="96f45-232">Figure 8.</span></span> <span data-ttu-id="96f45-233">Weryfikowanie między Model klasyfikacji binarnej.</span><span class="sxs-lookup"><span data-stu-id="96f45-233">Cross-Validating a Binary Classification Model.</span></span>

![Krzyżowe sprawdzanie poprawności wyniki klasyfikatora binarne](media/machine-learning-evaluate-model-performance/9.png)

<span data-ttu-id="96f45-235">Rysunek 9.</span><span class="sxs-lookup"><span data-stu-id="96f45-235">Figure 9.</span></span> <span data-ttu-id="96f45-236">Krzyżowe sprawdzanie poprawności wyniki binarne klasyfikatora.</span><span class="sxs-lookup"><span data-stu-id="96f45-236">Cross-Validation Results of a Binary Classifier.</span></span>

## <a name="evaluating-a-multiclass-classification-model"></a><span data-ttu-id="96f45-237">Ocena modelu Wieloklasowej klasyfikacji</span><span class="sxs-lookup"><span data-stu-id="96f45-237">Evaluating a Multiclass Classification Model</span></span>
<span data-ttu-id="96f45-238">W tym eksperymencie używamy popularnych [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") zestawu danych zawierającego wystąpienia 3 różne rodzaje (klasy) roślin iris.</span><span class="sxs-lookup"><span data-stu-id="96f45-238">In this experiment we will use the popular [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") dataset which contains instances of 3 different types (classes) of the iris plant.</span></span> <span data-ttu-id="96f45-239">Istnieją 4 wartości funkcji (sepal długości do szerokości i długości Motyw Płatek do szerokości) dla każdego wystąpienia.</span><span class="sxs-lookup"><span data-stu-id="96f45-239">There are 4 feature values (sepal length/width and petal length/width) for each instance.</span></span> <span data-ttu-id="96f45-240">W poprzednich eksperymenty możemy uczenia i przetestowane modeli, korzystając z tego samego zestawów danych.</span><span class="sxs-lookup"><span data-stu-id="96f45-240">In the previous experiments we trained and tested the models using the same datasets.</span></span> <span data-ttu-id="96f45-241">W tym miejscu użyjemy [podziału danych] [ split] modułu do tworzenia 2 podzestawy danych, uczenia pierwszego i wynik i ocenę na sekundę.</span><span class="sxs-lookup"><span data-stu-id="96f45-241">Here, we will use the [Split Data][split] module to create 2 subsets of the data, train on the first, and score and evaluate on the second.</span></span> <span data-ttu-id="96f45-242">Zestaw danych Iris jest ogólnie dostępna w [UCI Machine Learning repozytorium](http://archive.ics.uci.edu/ml/index.html)i może zostać pobrany przy użyciu [i zaimportuj dane] [ import-data] modułu.</span><span class="sxs-lookup"><span data-stu-id="96f45-242">The Iris dataset is publicly available on the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html), and can be downloaded using an [Import Data][import-data] module.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="96f45-243">Tworzenie eksperymentu</span><span class="sxs-lookup"><span data-stu-id="96f45-243">Creating the Experiment</span></span>
<span data-ttu-id="96f45-244">Dodaj następujące moduły do swojego obszaru roboczego w usłudze Azure Machine Learning Studio:</span><span class="sxs-lookup"><span data-stu-id="96f45-244">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="96f45-245">[Importowanie danych][import-data]</span><span class="sxs-lookup"><span data-stu-id="96f45-245">[Import Data][import-data]</span></span>
* <span data-ttu-id="96f45-246">[Multiklasa decyzji lasu][multiclass-decision-forest]</span><span class="sxs-lookup"><span data-stu-id="96f45-246">[Multiclass Decision Forest][multiclass-decision-forest]</span></span>
* <span data-ttu-id="96f45-247">[Podział danych][split]</span><span class="sxs-lookup"><span data-stu-id="96f45-247">[Split Data][split]</span></span>
* <span data-ttu-id="96f45-248">[Train Model][train-model]</span><span class="sxs-lookup"><span data-stu-id="96f45-248">[Train Model][train-model]</span></span>
* <span data-ttu-id="96f45-249">[Score Model][score-model]</span><span class="sxs-lookup"><span data-stu-id="96f45-249">[Score Model][score-model]</span></span>
* <span data-ttu-id="96f45-250">[Ocena modelu][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="96f45-250">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="96f45-251">Połącz porty, jak pokazano poniżej na rysunku nr 10.</span><span class="sxs-lookup"><span data-stu-id="96f45-251">Connect the ports as shown below in Figure 10.</span></span>

<span data-ttu-id="96f45-252">Ustaw etykietę indeks kolumny [Train Model] [ train-model] modułu do 5.</span><span class="sxs-lookup"><span data-stu-id="96f45-252">Set the Label column index of the [Train Model][train-model] module to 5.</span></span> <span data-ttu-id="96f45-253">Element dataset nie zawiera żadnego wiersza nagłówka, ale wiemy, że etykiety klasy znajdują się w kolumnie piątej.</span><span class="sxs-lookup"><span data-stu-id="96f45-253">The dataset has no header row but we know that the class labels are in the fifth column.</span></span>

<span data-ttu-id="96f45-254">Polecenie [i zaimportuj dane] [ import-data] moduł i zestaw *źródła danych* właściwości *adres URL sieci Web za pośrednictwem protokołu HTTP*i *adres URL* do http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span><span class="sxs-lookup"><span data-stu-id="96f45-254">Click on the [Import Data][import-data] module and set the *Data source* property to *Web URL via HTTP*, and the *URL* to http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span></span>

<span data-ttu-id="96f45-255">Ustaw ułamek wystąpień można użyć do trenowania w [podziału danych] [ split] modułu (0,7 na przykład).</span><span class="sxs-lookup"><span data-stu-id="96f45-255">Set the fraction of instances to be used for training in the [Split Data][split] module (0.7 for example).</span></span>

![Ocena Wieloklasowej klasyfikatora](media/machine-learning-evaluate-model-performance/10.png)

<span data-ttu-id="96f45-257">Rysunek 10.</span><span class="sxs-lookup"><span data-stu-id="96f45-257">Figure 10.</span></span> <span data-ttu-id="96f45-258">Ocena Wieloklasowej klasyfikatora</span><span class="sxs-lookup"><span data-stu-id="96f45-258">Evaluating a Multiclass Classifier</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="96f45-259">Sprawdzanie wyników oceny</span><span class="sxs-lookup"><span data-stu-id="96f45-259">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="96f45-260">Uruchom eksperyment, a następnie kliknij port wyjściowy [Evaluate Model][evaluate-model].</span><span class="sxs-lookup"><span data-stu-id="96f45-260">Run the experiment and click on the output port of [Evaluate Model][evaluate-model].</span></span> <span data-ttu-id="96f45-261">Wyniki oceny są prezentowane w postaci macierzy pomyłek, w tym przypadku.</span><span class="sxs-lookup"><span data-stu-id="96f45-261">The evaluation results are presented in the form of a confusion matrix, in this case.</span></span> <span data-ttu-id="96f45-262">Porównanie przewidywane wystąpień dla wszystkich klas 3 rzeczywistych pokazuje macierzy.</span><span class="sxs-lookup"><span data-stu-id="96f45-262">The matrix shows the actual vs. predicted instances for all 3 classes.</span></span>

![Wyniki oceny wieloklasowej klasyfikacji](media/machine-learning-evaluate-model-performance/11.png)

<span data-ttu-id="96f45-264">Rysunek 11.</span><span class="sxs-lookup"><span data-stu-id="96f45-264">Figure 11.</span></span> <span data-ttu-id="96f45-265">Wyniki oceny wieloklasowej klasyfikacji.</span><span class="sxs-lookup"><span data-stu-id="96f45-265">Multiclass Classification Evaluation Results.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="96f45-266">Za pomocą innej sprawdzania poprawności</span><span class="sxs-lookup"><span data-stu-id="96f45-266">Using Cross Validation</span></span>
<span data-ttu-id="96f45-267">Jak wspomniano wcześniej, można wykonać powtarzane szkolenia, ocenianie i oceny automatycznie za pomocą [krzyżowa Weryfikacja modelu] [ cross-validate-model] modułu.</span><span class="sxs-lookup"><span data-stu-id="96f45-267">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="96f45-268">Będzie potrzebny zestawu danych, model nieprzeszkolonych i [krzyżowa Weryfikacja modelu] [ cross-validate-model] modułu (zobacz rysunek poniżej).</span><span class="sxs-lookup"><span data-stu-id="96f45-268">You would need a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="96f45-269">Ponownie należy ustawić kolumnie Etykieta [krzyżowa Weryfikacja modelu] [ cross-validate-model] modułu (indeks kolumny 5 w tym przypadku).</span><span class="sxs-lookup"><span data-stu-id="96f45-269">Again you need to set the label column of the [Cross-Validate Model][cross-validate-model] module (column index 5 in this case).</span></span> <span data-ttu-id="96f45-270">Po wykonać eksperyment, a następnie klikając polecenie prawo output port [krzyżowa Weryfikacja modelu][cross-validate-model], możesz sprawdzić wartości metryki dla każdej złożenia, a także odchylenie średnią i standard.</span><span class="sxs-lookup"><span data-stu-id="96f45-270">After running the experiment and clicking the right output port of the [Cross-Validate Model][cross-validate-model], you can inspect the metric values for each fold as well as the mean and standard deviation.</span></span> <span data-ttu-id="96f45-271">Metryki wyświetlane w tym miejscu są podobne do tych omówione w przypadku klasyfikacji binarnej.</span><span class="sxs-lookup"><span data-stu-id="96f45-271">The metrics displayed here are the similar to the ones discussed in the binary classification case.</span></span> <span data-ttu-id="96f45-272">Jednak należy pamiętać, że w wieloklasowej klasyfikacji, obliczeniowych alarmów true/negatywów i fałszywych alarmów/wyników negatywnych polega na zliczania na podstawie według klasy, ponieważ nie ma żadnych klasy ogólnej dodatnią lub ujemną.</span><span class="sxs-lookup"><span data-stu-id="96f45-272">However, note that in multiclass classification, computing the true positives/negatives and false positives/negatives is done by counting on a per-class basis, as there is no overall positive or negative class.</span></span> <span data-ttu-id="96f45-273">Na przykład przy obliczaniu dokładności lub odwołania klasy "Iris setosa", zakłada się, to jest dodatnią klasy i wszystkie inne jako ujemne.</span><span class="sxs-lookup"><span data-stu-id="96f45-273">For example, when computing the precision or recall of the ‘Iris-setosa’ class, it is assumed that this is the positive class and all others as negative.</span></span>

![Krzyżowe sprawdzanie modelu Wieloklasowej klasyfikacji](media/machine-learning-evaluate-model-performance/12.png)

<span data-ttu-id="96f45-275">Rysunek 12.</span><span class="sxs-lookup"><span data-stu-id="96f45-275">Figure 12.</span></span> <span data-ttu-id="96f45-276">Weryfikowanie między modelu Wieloklasowej klasyfikacji.</span><span class="sxs-lookup"><span data-stu-id="96f45-276">Cross-Validating a Multiclass Classification Model.</span></span>

![Wyników krzyżowego sprawdzania poprawności modelu Wieloklasowej klasyfikacji](media/machine-learning-evaluate-model-performance/13.png)

<span data-ttu-id="96f45-278">Rysunek 13.</span><span class="sxs-lookup"><span data-stu-id="96f45-278">Figure 13.</span></span> <span data-ttu-id="96f45-279">Wyników krzyżowego sprawdzania poprawności modelu Wieloklasowej klasyfikacji.</span><span class="sxs-lookup"><span data-stu-id="96f45-279">Cross-Validation Results of a Multiclass Classification Model.</span></span>

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/


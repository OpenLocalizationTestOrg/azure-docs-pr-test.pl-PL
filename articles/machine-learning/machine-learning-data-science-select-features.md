---
title: Funkcja zaznaczenia w procesie nauki danych Team | Dokumentacja firmy Microsoft
description: "Objaśnienie jego przeznaczenia wybór funkcji i przykłady ich roli w procesie rozszerzenie danych usługi machine learning."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 878541f5-1df8-4368-889a-ced6852aba47
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/24/2017
ms.author: zhangya;bradsev
ms.openlocfilehash: ab97ee8278be567ff46d9b0f762d3c5c6cafa412
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 07/11/2017
---
# <a name="feature-selection-in-the-team-data-science-process-tdsp"></a><span data-ttu-id="8f483-103">Wybór funkcji w zespołowym przetwarzaniu danych dla celów naukowych</span><span class="sxs-lookup"><span data-stu-id="8f483-103">Feature selection in the Team Data Science Process (TDSP)</span></span>
<span data-ttu-id="8f483-104">W tym artykule opisano na potrzeby funkcji wyboru oraz przykłady swoją rolę w procesie rozszerzenie danych usługi machine learning.</span><span class="sxs-lookup"><span data-stu-id="8f483-104">This article explains the purposes of feature selection and provides examples of its role in the data enhancement process of machine learning.</span></span> <span data-ttu-id="8f483-105">Przykłady te są pobierane z usługi Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="8f483-105">These examples are drawn from Azure Machine Learning Studio.</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="8f483-106">Inżynieryjne i wybór funkcji jest jedną z części z zespołu danych nauki procesu (TDSP) opisane w temacie [co to jest proces zespołu danych nauki?](data-science-process-overview.md).</span><span class="sxs-lookup"><span data-stu-id="8f483-106">The engineering and selection of features is one part of the Team Data Science Process (TDSP) outlined in [What is the Team Data Science Process?](data-science-process-overview.md).</span></span> <span data-ttu-id="8f483-107">Funkcja inżynieryjne i wyboru są częściami **opracowywania funkcji** krok TDSP.</span><span class="sxs-lookup"><span data-stu-id="8f483-107">Feature engineering and selection are parts of the **Develop features** step of the TDSP.</span></span>

* <span data-ttu-id="8f483-108">**Inżynieria**: ten proces próbuje utworzyć dodatkowe istotne cechy z istniejących funkcji pierwotnych danych i zwiększyć predykcyjnej zasilania Algorytm uczenia.</span><span class="sxs-lookup"><span data-stu-id="8f483-108">**feature engineering**: This process attempts to create additional relevant features from the existing raw features in the data, and to increase predictive power to the learning algorithm.</span></span>
* <span data-ttu-id="8f483-109">**Wybór funkcji**: tego procesu wybiera klucza podzbioru cech oryginalnych danych w celu zmniejszenia wymiarach problemu szkolenia.</span><span class="sxs-lookup"><span data-stu-id="8f483-109">**feature selection**: This process selects the key subset of original data features in an attempt to reduce the dimensionality of the training problem.</span></span>

<span data-ttu-id="8f483-110">Zwykle **Inżynieria** zostanie zastosowana jako pierwsza, aby wygenerować dodatkowe funkcje, a następnie **funkcji wyboru** kroku jest wykonywana w celu wyeliminowania nie ma znaczenia, nadmiarowe lub dużej skorelowane funkcji.</span><span class="sxs-lookup"><span data-stu-id="8f483-110">Normally **feature engineering** is applied first to generate additional features, and then the **feature selection** step is performed to eliminate irrelevant, redundant, or highly correlated features.</span></span>

## <a name="filtering-features-from-your-data---feature-selection"></a><span data-ttu-id="8f483-111">Funkcje filtrowania danych - wybór funkcji</span><span class="sxs-lookup"><span data-stu-id="8f483-111">Filtering Features from Your Data - Feature Selection</span></span>
<span data-ttu-id="8f483-112">Wybór funkcji jest procesem, powszechnie stosowany do tworzenia zbiorów danych szkoleniowych modelowania predykcyjnego zadań, takich jak zadania klasyfikacji lub regresji.</span><span class="sxs-lookup"><span data-stu-id="8f483-112">Feature selection is a process that is commonly applied for the construction of training datasets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="8f483-113">Celem jest Wybierz podzbiór funkcji z oryginalnego zestawu danych zmniejszyć jego wymiary za pomocą minimalny zestaw funkcji do reprezentowania maksymalną ilość wariancji w danych.</span><span class="sxs-lookup"><span data-stu-id="8f483-113">The goal is to select a subset of the features from the original dataset that reduce its dimensions by using a minimal set of features to represent the maximum amount of variance in the data.</span></span> <span data-ttu-id="8f483-114">Następnie ten podzestaw funkcji są tylko funkcje do uwzględnienia do nauczenia modelu.</span><span class="sxs-lookup"><span data-stu-id="8f483-114">This subset of features are, then, the only features to be included to train the model.</span></span> <span data-ttu-id="8f483-115">Wybór funkcji służy dwa główne cele.</span><span class="sxs-lookup"><span data-stu-id="8f483-115">Feature selection serves two main purposes.</span></span>

* <span data-ttu-id="8f483-116">Po pierwsze wybór funkcji często zwiększa dokładność klasyfikacji przez wyeliminowanie nie ma znaczenia, nadmiarowe lub ściśle powiązane funkcje.</span><span class="sxs-lookup"><span data-stu-id="8f483-116">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="8f483-117">Po drugie zmniejsza liczbę funkcji, dzięki czemu większą wydajność procesu uczenia modelu.</span><span class="sxs-lookup"><span data-stu-id="8f483-117">Second, it decreases the number of features which makes model training process more efficient.</span></span> <span data-ttu-id="8f483-118">Jest to szczególnie ważne w przypadku uczących, które są kosztowne do uczenia, takich jak obsługa wektor maszyny.</span><span class="sxs-lookup"><span data-stu-id="8f483-118">This is particularly important for learners that are expensive to train such as support vector machines.</span></span>

<span data-ttu-id="8f483-119">Mimo że wybór funkcji wyszukiwania ograniczyć liczbę funkcji w zestawie danych używany do nauczenia modelu, jego jest nie zazwyczaj określone przez termin "wymiarach redukcji".</span><span class="sxs-lookup"><span data-stu-id="8f483-119">Although feature selection does seek to reduce the number of features in the dataset used to train the model, it is not usually referred to by the term "dimensionality reduction".</span></span> <span data-ttu-id="8f483-120">Metody wyboru funkcji Wyodrębnij podzbioru cech oryginalnych danych bez konieczności ich zmieniania.</span><span class="sxs-lookup"><span data-stu-id="8f483-120">Feature selection methods extract a subset of original features in the data without changing them.</span></span>  <span data-ttu-id="8f483-121">Wymiary metod redukcji stosować odtworzone funkcje, które można przekształcić funkcji oryginalnego i w związku z tym ich modyfikować.</span><span class="sxs-lookup"><span data-stu-id="8f483-121">Dimensionality reduction methods employ engineered features that can transform the original features and thus modify them.</span></span> <span data-ttu-id="8f483-122">Przykładami metod redukcji wymiary analizy składnika podmiot zabezpieczeń, analiza canonical korelacji i pojedynczą wartość rozkładu.</span><span class="sxs-lookup"><span data-stu-id="8f483-122">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</span></span>

<span data-ttu-id="8f483-123">Między innymi jedną z powszechnie stosowanych kategorii metody wyboru funkcji w kontekście nadzorowany jest nazywany "Wybór funkcji Filtr na podstawie".</span><span class="sxs-lookup"><span data-stu-id="8f483-123">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</span></span> <span data-ttu-id="8f483-124">Wyniku obliczenia korelacji między każdej funkcji i atrybut target, te metody się statystyczne miarę w celu Przypisz wynik do każdej funkcji.</span><span class="sxs-lookup"><span data-stu-id="8f483-124">By evaluating the correlation between each feature and the target attribute, these methods apply a statistical measure to assign a score to each feature.</span></span> <span data-ttu-id="8f483-125">Funkcje są następnie uporządkowane według wynik, który może służyć do ustawiać wartości progowej dla utrzymywanie lub wyeliminowanie określonych funkcji.</span><span class="sxs-lookup"><span data-stu-id="8f483-125">The features are then ranked by the score, which may be used to help set the threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="8f483-126">Przykładami miar statystyczne w tych metod korelacji osoby, wzajemne informacji i test Chi kwadrat.</span><span class="sxs-lookup"><span data-stu-id="8f483-126">Examples of the statistical measures used in these methods include Person correlation, mutual information, and the Chi squared test.</span></span>

<span data-ttu-id="8f483-127">W usłudze Azure Machine Learning Studio istnieją modułów dla funkcji wyboru cech.</span><span class="sxs-lookup"><span data-stu-id="8f483-127">In Azure Machine Learning Studio, there are modules provided for feature selection.</span></span> <span data-ttu-id="8f483-128">Jak pokazano na poniższej ilustracji, te moduły obejmują [na podstawie filtru wybór funkcji] [ filter-based-feature-selection] i [analiza liniowa Discriminant Fishera][fisher-linear-discriminant-analysis].</span><span class="sxs-lookup"><span data-stu-id="8f483-128">As shown in the following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![Przykład wybór funkcji](./media/machine-learning-data-science-select-features/feature-Selection.png)

<span data-ttu-id="8f483-130">Na przykład, rozważ użycie [na podstawie filtru wybór funkcji] [ filter-based-feature-selection] modułu.</span><span class="sxs-lookup"><span data-stu-id="8f483-130">Consider, for example, the use of the [Filter-Based Feature Selection][filter-based-feature-selection] module.</span></span> <span data-ttu-id="8f483-131">W celu zapewnienia wygody firma Microsoft nadal używać przykład wyszukiwania tekstu opisanych powyżej.</span><span class="sxs-lookup"><span data-stu-id="8f483-131">For the purpose of convenience, we continue to use the text mining example outlined above.</span></span> <span data-ttu-id="8f483-132">Załóżmy chęć kompilacji modelu regresji po utworzeniu przez zestaw funkcji 256 [Tworzenie skrótu funkcji] [ feature-hashing] modułu, a zmienna odpowiedzi jest "Col1" reprezentuje książkę Przejrzyj klasyfikacje z zakresu od 1 do 5.</span><span class="sxs-lookup"><span data-stu-id="8f483-132">Assume that we want to build a regression model after a set of 256 features are created through the [Feature Hashing][feature-hashing] module, and that the response variable is the "Col1" and represents a book review ratings ranging from 1 to 5.</span></span> <span data-ttu-id="8f483-133">Przez ustawienie "Funkcji oceniania metody" jako "Wariancji x korelacji", "kolumna docelowa" jako "Col1" i "Liczba żądanych funkcji" do 50.</span><span class="sxs-lookup"><span data-stu-id="8f483-133">By setting "Feature scoring method" to be "Pearson Correlation", the "Target column" to be "Col1", and the "Number of desired features" to 50.</span></span> <span data-ttu-id="8f483-134">Następnie moduł [na podstawie filtru wybór funkcji] [ filter-based-feature-selection] spowoduje utworzenie zestawu danych zawierającego 50 funkcji z atrybut target "Col1".</span><span class="sxs-lookup"><span data-stu-id="8f483-134">Then the module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with the target attribute "Col1".</span></span> <span data-ttu-id="8f483-135">Na poniższej ilustracji przedstawiono przepływ tego eksperymentu i parametrów wejściowych, które firma Microsoft opisane.</span><span class="sxs-lookup"><span data-stu-id="8f483-135">The following figure shows the flow of this experiment and the input parameters we just described.</span></span>

![Przykład wybór funkcji](./media/machine-learning-data-science-select-features/feature-Selection1.png)

<span data-ttu-id="8f483-137">Na poniższej ilustracji przedstawiono Wynikowy zestaw danych.</span><span class="sxs-lookup"><span data-stu-id="8f483-137">The following figure shows the resulting datasets.</span></span> <span data-ttu-id="8f483-138">Każdej funkcji są oceniane na podstawie na korelacji wariancji x między sobą i atrybut target "Col1".</span><span class="sxs-lookup"><span data-stu-id="8f483-138">Each feature is scored based on the Pearson Correlation between itself and the target attribute "Col1".</span></span> <span data-ttu-id="8f483-139">Funkcje z najwyższym wyniki są zachowywane.</span><span class="sxs-lookup"><span data-stu-id="8f483-139">The features with top scores are kept.</span></span>

![Przykład wybór funkcji](./media/machine-learning-data-science-select-features/feature-Selection2.png)

<span data-ttu-id="8f483-141">Odpowiednie wyniki wybrane funkcje są wyświetlane na poniższej ilustracji.</span><span class="sxs-lookup"><span data-stu-id="8f483-141">The corresponding scores of the selected features are shown in the following figure.</span></span>

![Przykład wybór funkcji](./media/machine-learning-data-science-select-features/feature-Selection3.png)

<span data-ttu-id="8f483-143">Stosując to [na podstawie filtru wybór funkcji] [ filter-based-feature-selection] modułu, 50 poza 256 funkcje są wybrane, ponieważ mają one funkcji najbardziej skorelowane z Zmienna docelowa "Col1", na podstawie wyników metody "Wariancji x korelacji".</span><span class="sxs-lookup"><span data-stu-id="8f483-143">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have the most correlated features with the target variable "Col1", based on the scoring method "Pearson Correlation".</span></span>

## <a name="conclusion"></a><span data-ttu-id="8f483-144">Podsumowanie</span><span class="sxs-lookup"><span data-stu-id="8f483-144">Conclusion</span></span>
<span data-ttu-id="8f483-145">Funkcja inżynieryjne i wybór funkcji są dwa najczęściej odtwarzane i wybranych funkcji zwiększyć wydajność procesu szkolenia, który próbuje wyodrębnić informacje o kluczu zawarte w danych.</span><span class="sxs-lookup"><span data-stu-id="8f483-145">Feature engineering and feature selection are two commonly Engineered and selected features increase the efficiency of the training process which attempts to extract the key information contained in the data.</span></span> <span data-ttu-id="8f483-146">Poprawiają również uprawnienia tych modeli dokładnie klasyfikowania danych wejściowych oraz do przewidywania wyników odsetek bardziej niezawodnie.</span><span class="sxs-lookup"><span data-stu-id="8f483-146">They also improve the power of these models to classify the input data accurately and to predict outcomes of interest more robustly.</span></span> <span data-ttu-id="8f483-147">Funkcja inżynieryjne i wyboru można także połączyć dokonanie więcej praktyce tractable learning.</span><span class="sxs-lookup"><span data-stu-id="8f483-147">Feature engineering and selection can also combine to make the learning more computationally tractable.</span></span> <span data-ttu-id="8f483-148">Robi to udoskonalanie, a następnie zmniejszenie liczby potrzeby kalibrować lub uczenie modelu przy użyciu funkcji.</span><span class="sxs-lookup"><span data-stu-id="8f483-148">It does so by enhancing and then reducing the number of features needed to calibrate or train a model.</span></span> <span data-ttu-id="8f483-149">Funkcje wybrane do nauczenia modelu ze sobą matematycznie rzecz biorąc, są minimalny zbiór zmienne niezależne, które wyjaśniają wzorce w danych, a następnie pomyślnie przewidywania wyników.</span><span class="sxs-lookup"><span data-stu-id="8f483-149">Mathematically speaking, the features selected to train the model are a minimal set of independent variables that explain the patterns in the data and then predict outcomes successfully.</span></span>

<span data-ttu-id="8f483-150">Należy pamiętać, że nie zawsze musi przeprowadzić wybór funkcji engineering lub funkcji.</span><span class="sxs-lookup"><span data-stu-id="8f483-150">Note that it is not always necessarily to perform feature engineering or feature selection.</span></span> <span data-ttu-id="8f483-151">Określa, czy jest potrzebna, lub nie zależy od tego, firma Microsoft ma lub zbierać dane, algorytmu, który mamy pobranie i celem eksperymentu.</span><span class="sxs-lookup"><span data-stu-id="8f483-151">Whether it is needed or not depends on the data we have or collect, the algorithm we pick, and the objective of the experiment.</span></span>

<!-- Module References -->
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/


---
title: "Wybór aaaFeature w hello proces nauki danych Team | Dokumentacja firmy Microsoft"
description: "Wyjaśnia hello celem wybór funkcji i przykłady ich roli w procesie rozszerzenie danych hello uczenia maszynowego."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 878541f5-1df8-4368-889a-ced6852aba47
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/24/2017
ms.author: zhangya;bradsev
ms.openlocfilehash: 54af93c83e4cc6a3670b3ad62490e0f74082b4ee
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 10/06/2017
---
# <a name="feature-selection-in-hello-team-data-science-process-tdsp"></a><span data-ttu-id="50c62-103">Wybór funkcji w hello zespołu danych nauki procesu (TDSP)</span><span class="sxs-lookup"><span data-stu-id="50c62-103">Feature selection in hello Team Data Science Process (TDSP)</span></span>
<span data-ttu-id="50c62-104">W tym artykule opisano hello celów wybór funkcji oraz przykłady swoją rolę w procesie rozszerzenie danych hello uczenia maszynowego.</span><span class="sxs-lookup"><span data-stu-id="50c62-104">This article explains hello purposes of feature selection and provides examples of its role in hello data enhancement process of machine learning.</span></span> <span data-ttu-id="50c62-105">Przykłady te są pobierane z usługi Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="50c62-105">These examples are drawn from Azure Machine Learning Studio.</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="50c62-106">Witaj, inżynieria i wybór funkcji ma jedną część hello zespołu danych nauki procesu (TDSP) opisane w [co to jest hello proces nauki danych zespołu?](data-science-process-overview.md).</span><span class="sxs-lookup"><span data-stu-id="50c62-106">hello engineering and selection of features is one part of hello Team Data Science Process (TDSP) outlined in [What is hello Team Data Science Process?](data-science-process-overview.md).</span></span> <span data-ttu-id="50c62-107">Funkcja inżynieryjne i wyboru są części hello **opracowywania funkcji** krok hello TDSP.</span><span class="sxs-lookup"><span data-stu-id="50c62-107">Feature engineering and selection are parts of hello **Develop features** step of hello TDSP.</span></span>

* <span data-ttu-id="50c62-108">**Inżynieria**: ten proces próbuje toocreate dodatkowe istotne cechy z hello istniejących funkcji nieprzetworzone dane hello i algorytm uczenia toohello predykcyjnej zasilania tooincrease.</span><span class="sxs-lookup"><span data-stu-id="50c62-108">**feature engineering**: This process attempts toocreate additional relevant features from hello existing raw features in hello data, and tooincrease predictive power toohello learning algorithm.</span></span>
* <span data-ttu-id="50c62-109">**Wybór funkcji**: tego procesu wybiera hello klucza podzbioru cech oryginalnych danych w wymiarach hello tooreduce próba hello szkolenia problemu.</span><span class="sxs-lookup"><span data-stu-id="50c62-109">**feature selection**: This process selects hello key subset of original data features in an attempt tooreduce hello dimensionality of hello training problem.</span></span>

<span data-ttu-id="50c62-110">Zwykle **Inżynieria** zostanie zastosowane pierwszy toogenerate funkcje dodatkowe, a następnie hello **funkcji wyboru** krokiem jest wykonywane tooeliminate nie ma znaczenia, nadmiarowe lub dużej skorelowane funkcje.</span><span class="sxs-lookup"><span data-stu-id="50c62-110">Normally **feature engineering** is applied first toogenerate additional features, and then hello **feature selection** step is performed tooeliminate irrelevant, redundant, or highly correlated features.</span></span>

## <a name="filtering-features-from-your-data---feature-selection"></a><span data-ttu-id="50c62-111">Funkcje filtrowania danych - wybór funkcji</span><span class="sxs-lookup"><span data-stu-id="50c62-111">Filtering Features from Your Data - Feature Selection</span></span>
<span data-ttu-id="50c62-112">Wybór funkcji jest procesem, powszechnie stosowany do tworzenia hello zestawów danych szkoleniowych modelowania predykcyjnego zadań, takich jak zadania klasyfikacji lub regresji.</span><span class="sxs-lookup"><span data-stu-id="50c62-112">Feature selection is a process that is commonly applied for hello construction of training datasets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="50c62-113">Celem Hello jest tooselect podzbiór funkcji hello z oryginalnego zestawu danych hello zmniejszających wymiary przy użyciu minimalny zestaw funkcji toorepresent hello maksymalną ilość wariancji w hello danych.</span><span class="sxs-lookup"><span data-stu-id="50c62-113">hello goal is tooselect a subset of hello features from hello original dataset that reduce its dimensions by using a minimal set of features toorepresent hello maximum amount of variance in hello data.</span></span> <span data-ttu-id="50c62-114">Są to podzbiór funkcji, a następnie hello tylko toobe funkcje uwzględnione tootrain hello modelu.</span><span class="sxs-lookup"><span data-stu-id="50c62-114">This subset of features are, then, hello only features toobe included tootrain hello model.</span></span> <span data-ttu-id="50c62-115">Wybór funkcji służy dwa główne cele.</span><span class="sxs-lookup"><span data-stu-id="50c62-115">Feature selection serves two main purposes.</span></span>

* <span data-ttu-id="50c62-116">Po pierwsze wybór funkcji często zwiększa dokładność klasyfikacji przez wyeliminowanie nie ma znaczenia, nadmiarowe lub ściśle powiązane funkcje.</span><span class="sxs-lookup"><span data-stu-id="50c62-116">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="50c62-117">Po drugie zmniejsza hello wiele funkcji, dzięki czemu większą wydajność procesu uczenia modelu.</span><span class="sxs-lookup"><span data-stu-id="50c62-117">Second, it decreases hello number of features which makes model training process more efficient.</span></span> <span data-ttu-id="50c62-118">Jest to szczególnie ważne w przypadku uczących będących tootrain kosztowne, takich jak obsługa wektor maszyny.</span><span class="sxs-lookup"><span data-stu-id="50c62-118">This is particularly important for learners that are expensive tootrain such as support vector machines.</span></span>

<span data-ttu-id="50c62-119">Mimo że wybór funkcji wyszukiwania tooreduce hello liczbę funkcji hello zestawu danych używane tootrain hello modelu, nie jest zazwyczaj określonego tooby hello termin "wymiarach redukcji".</span><span class="sxs-lookup"><span data-stu-id="50c62-119">Although feature selection does seek tooreduce hello number of features in hello dataset used tootrain hello model, it is not usually referred tooby hello term "dimensionality reduction".</span></span> <span data-ttu-id="50c62-120">Metody wyboru funkcji Wyodrębnij podzbiór funkcji oryginalnego hello danych bez konieczności ich zmieniania.</span><span class="sxs-lookup"><span data-stu-id="50c62-120">Feature selection methods extract a subset of original features in hello data without changing them.</span></span>  <span data-ttu-id="50c62-121">Wymiary metod redukcji stosować odtworzone funkcje, które można przekształcić funkcji oryginalnego hello i w związku z tym ich modyfikować.</span><span class="sxs-lookup"><span data-stu-id="50c62-121">Dimensionality reduction methods employ engineered features that can transform hello original features and thus modify them.</span></span> <span data-ttu-id="50c62-122">Przykładami metod redukcji wymiary analizy składnika podmiot zabezpieczeń, analiza canonical korelacji i pojedynczą wartość rozkładu.</span><span class="sxs-lookup"><span data-stu-id="50c62-122">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</span></span>

<span data-ttu-id="50c62-123">Między innymi jedną z powszechnie stosowanych kategorii metody wyboru funkcji w kontekście nadzorowany jest nazywany "Wybór funkcji Filtr na podstawie".</span><span class="sxs-lookup"><span data-stu-id="50c62-123">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</span></span> <span data-ttu-id="50c62-124">Wyniku obliczenia hello korelacja poszczególnych funkcji i hello atrybut target, te metody mają zastosowanie tooassign statystyczne miary funkcji tooeach wynik.</span><span class="sxs-lookup"><span data-stu-id="50c62-124">By evaluating hello correlation between each feature and hello target attribute, these methods apply a statistical measure tooassign a score tooeach feature.</span></span> <span data-ttu-id="50c62-125">Funkcje Hello następnie są uporządkowane według hello wynik, który może być używane toohelp zestaw hello próg utrzymywanie lub wyeliminowanie określonych funkcji.</span><span class="sxs-lookup"><span data-stu-id="50c62-125">hello features are then ranked by hello score, which may be used toohelp set hello threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="50c62-126">Przykładami hello miar statystyczne w tych metod korelacji osoby, wzajemne informacji i hello Chi kwadrat testu.</span><span class="sxs-lookup"><span data-stu-id="50c62-126">Examples of hello statistical measures used in these methods include Person correlation, mutual information, and hello Chi squared test.</span></span>

<span data-ttu-id="50c62-127">W usłudze Azure Machine Learning Studio istnieją modułów dla funkcji wyboru cech.</span><span class="sxs-lookup"><span data-stu-id="50c62-127">In Azure Machine Learning Studio, there are modules provided for feature selection.</span></span> <span data-ttu-id="50c62-128">Jak pokazano na następującej ilustracji hello, te moduły obejmują [na podstawie filtru wybór funkcji] [ filter-based-feature-selection] i [analiza liniowa Discriminant Fishera] [ fisher-linear-discriminant-analysis].</span><span class="sxs-lookup"><span data-stu-id="50c62-128">As shown in hello following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![Przykład wybór funkcji](./media/machine-learning-data-science-select-features/feature-Selection.png)

<span data-ttu-id="50c62-130">Należy wziąć pod uwagę, na przykład użycie hello hello [na podstawie filtru wybór funkcji] [ filter-based-feature-selection] modułu.</span><span class="sxs-lookup"><span data-stu-id="50c62-130">Consider, for example, hello use of hello [Filter-Based Feature Selection][filter-based-feature-selection] module.</span></span> <span data-ttu-id="50c62-131">Witaj w celu zapewnienia wygody, w dalszym ciągu toouse hello wyszukiwania przykład tekstu opisanych powyżej.</span><span class="sxs-lookup"><span data-stu-id="50c62-131">For hello purpose of convenience, we continue toouse hello text mining example outlined above.</span></span> <span data-ttu-id="50c62-132">Załóżmy, że chcemy toobuild modelu regresji po zestaw funkcji 256 są tworzone za pomocą hello [Tworzenie skrótu funkcji] [ feature-hashing] modułu i zmiennej odpowiedzi hello jest hello "Col1" i reprezentuje książkę Przejrzyj klasyfikacje z zakresu od 1 too5.</span><span class="sxs-lookup"><span data-stu-id="50c62-132">Assume that we want toobuild a regression model after a set of 256 features are created through hello [Feature Hashing][feature-hashing] module, and that hello response variable is hello "Col1" and represents a book review ratings ranging from 1 too5.</span></span> <span data-ttu-id="50c62-133">Ustawiając "Funkcja oceniania metody" toobe "Wariancji x korelacji" hello "Kolumna docelowa" toobe "Col1" i too50 "Liczba żądanych funkcji" hello.</span><span class="sxs-lookup"><span data-stu-id="50c62-133">By setting "Feature scoring method" toobe "Pearson Correlation", hello "Target column" toobe "Col1", and hello "Number of desired features" too50.</span></span> <span data-ttu-id="50c62-134">Następnie moduł hello [na podstawie filtru wybór funkcji] [ filter-based-feature-selection] spowoduje utworzenie zestawu danych zawierającego 50 funkcji z hello atrybut target "Col1".</span><span class="sxs-lookup"><span data-stu-id="50c62-134">Then hello module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with hello target attribute "Col1".</span></span> <span data-ttu-id="50c62-135">Hello następujący rysunek przedstawia przepływ hello tego eksperymentu i hello parametrów wejściowych, które firma Microsoft opisane.</span><span class="sxs-lookup"><span data-stu-id="50c62-135">hello following figure shows hello flow of this experiment and hello input parameters we just described.</span></span>

![Przykład wybór funkcji](./media/machine-learning-data-science-select-features/feature-Selection1.png)

<span data-ttu-id="50c62-137">Witaj poniższej ilustracji przedstawiono hello Wynikowy zestaw danych.</span><span class="sxs-lookup"><span data-stu-id="50c62-137">hello following figure shows hello resulting datasets.</span></span> <span data-ttu-id="50c62-138">Każdej funkcji są oceniane na podstawie na powitania wariancji x korelacja sam i hello atrybut target "Col1".</span><span class="sxs-lookup"><span data-stu-id="50c62-138">Each feature is scored based on hello Pearson Correlation between itself and hello target attribute "Col1".</span></span> <span data-ttu-id="50c62-139">Funkcje Hello z najwyższym wyniki są zachowywane.</span><span class="sxs-lookup"><span data-stu-id="50c62-139">hello features with top scores are kept.</span></span>

![Przykład wybór funkcji](./media/machine-learning-data-science-select-features/feature-Selection2.png)

<span data-ttu-id="50c62-141">w hello następującej ilustracji przedstawiono Hello odpowiednie wyniki hello wybrane funkcje.</span><span class="sxs-lookup"><span data-stu-id="50c62-141">hello corresponding scores of hello selected features are shown in hello following figure.</span></span>

![Przykład wybór funkcji](./media/machine-learning-data-science-select-features/feature-Selection3.png)

<span data-ttu-id="50c62-143">Stosując to [na podstawie filtru wybór funkcji] [ filter-based-feature-selection] modułu, 50 poza 256 funkcje są wybrane, ponieważ mają one hello większość skorelowane funkcji z Zmienna docelowa hello "Col1" oparte na powitania oceniania Metoda "Wariancji x korelacji".</span><span class="sxs-lookup"><span data-stu-id="50c62-143">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have hello most correlated features with hello target variable "Col1", based on hello scoring method "Pearson Correlation".</span></span>

## <a name="conclusion"></a><span data-ttu-id="50c62-144">Podsumowanie</span><span class="sxs-lookup"><span data-stu-id="50c62-144">Conclusion</span></span>
<span data-ttu-id="50c62-145">Funkcja inżynieryjne i wybór funkcji są dwa najczęściej odtwarzane i wybranych funkcji zwiększyć wydajność hello hello szkolenia procesu, który próbuje tooextract hello najważniejsze informacje zawarte w danych hello.</span><span class="sxs-lookup"><span data-stu-id="50c62-145">Feature engineering and feature selection are two commonly Engineered and selected features increase hello efficiency of hello training process which attempts tooextract hello key information contained in hello data.</span></span> <span data-ttu-id="50c62-146">One również poprawić zasilania hello te modele tooclassify hello danych wejściowych dokładnie i wyniki toopredict odsetek więcej niezawodnie.</span><span class="sxs-lookup"><span data-stu-id="50c62-146">They also improve hello power of these models tooclassify hello input data accurately and toopredict outcomes of interest more robustly.</span></span> <span data-ttu-id="50c62-147">Funkcja inżynieryjne i wyboru można także połączyć learning hello toomake więcej praktyce tractable.</span><span class="sxs-lookup"><span data-stu-id="50c62-147">Feature engineering and selection can also combine toomake hello learning more computationally tractable.</span></span> <span data-ttu-id="50c62-148">Robi to przez rozszerzanie i następnie zmniejszeniu liczby hello funkcje wymagane toocalibrate lub train model.</span><span class="sxs-lookup"><span data-stu-id="50c62-148">It does so by enhancing and then reducing hello number of features needed toocalibrate or train a model.</span></span> <span data-ttu-id="50c62-149">Ze sobą matematycznie rzecz biorąc, model hello tootrain wybrane funkcje hello są minimalny zbiór zmienne niezależne, hello wzorce w danych hello wyjaśnienia, które następnie pomyślnie przewidywania wyników.</span><span class="sxs-lookup"><span data-stu-id="50c62-149">Mathematically speaking, hello features selected tootrain hello model are a minimal set of independent variables that explain hello patterns in hello data and then predict outcomes successfully.</span></span>

<span data-ttu-id="50c62-150">Należy pamiętać, że nie zawsze jest zawsze tooperform funkcji engineering lub funkcji wyboru cech.</span><span class="sxs-lookup"><span data-stu-id="50c62-150">Note that it is not always necessarily tooperform feature engineering or feature selection.</span></span> <span data-ttu-id="50c62-151">Określa, czy jest potrzebna, lub nie zależy od danych hello mają lub zbierane hello algorytmu, który mamy pobranie i hello cel hello eksperymentu.</span><span class="sxs-lookup"><span data-stu-id="50c62-151">Whether it is needed or not depends on hello data we have or collect, hello algorithm we pick, and hello objective of hello experiment.</span></span>

<!-- Module References -->
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/


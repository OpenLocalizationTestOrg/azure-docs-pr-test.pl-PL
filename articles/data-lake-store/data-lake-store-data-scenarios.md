---
title: "Scenariusze danych dotyczących usługi Data Lake Store | Dokumentacja firmy Microsoft"
description: "Zapoznanie się z różnych scenariuszy i narzędzi przy użyciu danych można pozyskanych, przetwarzane pobrane i wizualizowane w Data Lake Store"
services: data-lake-store
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
ms.assetid: 37409a71-a563-4bb7-bc46-2cbd426a2ece
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 05/10/2017
ms.author: nitinme
ms.openlocfilehash: 2a2801e5c506dcc8aa9ca2ecd275b52c72d5fbbf
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 08/29/2017
---
# <a name="using-azure-data-lake-store-for-big-data-requirements"></a><span data-ttu-id="feddd-103">Za pomocą usługi Azure Data Lake Store wymagania danych big data</span><span class="sxs-lookup"><span data-stu-id="feddd-103">Using Azure Data Lake Store for big data requirements</span></span>
<span data-ttu-id="feddd-104">Istnieją cztery etapy klucza podczas przetwarzania danych big:</span><span class="sxs-lookup"><span data-stu-id="feddd-104">There are four key stages in big data processing:</span></span>

* <span data-ttu-id="feddd-105">Wprowadzania dużych ilości danych do magazynu danych, w czasie rzeczywistym lub w partiach</span><span class="sxs-lookup"><span data-stu-id="feddd-105">Ingesting large amounts of data into a data store, at real-time or in batches</span></span>
* <span data-ttu-id="feddd-106">Przetwarzanie danych</span><span class="sxs-lookup"><span data-stu-id="feddd-106">Processing the data</span></span>
* <span data-ttu-id="feddd-107">Pobieranie danych</span><span class="sxs-lookup"><span data-stu-id="feddd-107">Downloading the data</span></span>
* <span data-ttu-id="feddd-108">Wizualizacja danych</span><span class="sxs-lookup"><span data-stu-id="feddd-108">Visualizing the data</span></span>

<span data-ttu-id="feddd-109">W tym artykule opisano te etapy względem Azure Data Lake Store, aby zrozumieć opcje i dostępne narzędzia do własnych potrzeb danych big data.</span><span class="sxs-lookup"><span data-stu-id="feddd-109">In this article, we look at these stages with respect to Azure Data Lake Store to understand the options and tools available to meet your big data needs.</span></span>

## <a name="ingest-data-into-data-lake-store"></a><span data-ttu-id="feddd-110">Pozyskiwania danych w usłudze Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="feddd-110">Ingest data into Data Lake Store</span></span>
<span data-ttu-id="feddd-111">W tej sekcji opisano różne źródła danych i różne sposoby, w którym można pozyskanych danych, do konta usługi Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="feddd-111">This section highlights the different sources of data and the different ways in which that data can be ingested into a Data Lake Store account.</span></span>

<span data-ttu-id="feddd-112">![Pozyskiwania danych w usłudze Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "pozyskiwania danych w usłudze Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="feddd-112">![Ingest data into Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Ingest data into Data Lake Store")</span></span>

### <a name="ad-hoc-data"></a><span data-ttu-id="feddd-113">Ad hoc danych</span><span class="sxs-lookup"><span data-stu-id="feddd-113">Ad hoc data</span></span>
<span data-ttu-id="feddd-114">Ta pozycja reprezentuje mniejszych zestawów danych, które są używane do tworzenia prototypów aplikacji danych big data.</span><span class="sxs-lookup"><span data-stu-id="feddd-114">This represents smaller data sets that are used for prototyping a big data application.</span></span> <span data-ttu-id="feddd-115">Istnieją różne sposoby wprowadzania danych ad hoc w zależności od źródła danych.</span><span class="sxs-lookup"><span data-stu-id="feddd-115">There are different ways of ingesting ad hoc data depending on the source of the data.</span></span>

| <span data-ttu-id="feddd-116">Źródło danych</span><span class="sxs-lookup"><span data-stu-id="feddd-116">Data Source</span></span> | <span data-ttu-id="feddd-117">Za pomocą pozyskiwania</span><span class="sxs-lookup"><span data-stu-id="feddd-117">Ingest it using</span></span> |
| --- | --- |
| <span data-ttu-id="feddd-118">Komputer lokalny</span><span class="sxs-lookup"><span data-stu-id="feddd-118">Local computer</span></span> |<ul> <li>[<span data-ttu-id="feddd-119">Azure Portal</span><span class="sxs-lookup"><span data-stu-id="feddd-119">Azure Portal</span></span>](/data-lake-store-get-started-portal.md)</li> <li>[<span data-ttu-id="feddd-120">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="feddd-120">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)</li> <li>[<span data-ttu-id="feddd-121">Azure CLI wieloplatformowych 2.0</span><span class="sxs-lookup"><span data-stu-id="feddd-121">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)</li> <li>[<span data-ttu-id="feddd-122">Przy użyciu narzędzi Data Lake Tools dla programu Visual Studio</span><span class="sxs-lookup"><span data-stu-id="feddd-122">Using Data Lake Tools for Visual Studio</span></span>](../data-lake-analytics/data-lake-analytics-data-lake-tools-get-started.md) </li></ul> |
| <span data-ttu-id="feddd-123">Obiektu Blob magazynu Azure</span><span class="sxs-lookup"><span data-stu-id="feddd-123">Azure Storage Blob</span></span> |<ul> <li>[<span data-ttu-id="feddd-124">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="feddd-124">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)</li> <li>[<span data-ttu-id="feddd-125">Narzędzie AdlCopy</span><span class="sxs-lookup"><span data-stu-id="feddd-125">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="feddd-126">Narzędzia DistCp uruchomiona w klastrze usługi HDInsight</span><span class="sxs-lookup"><span data-stu-id="feddd-126">DistCp running on HDInsight cluster</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li> </ul> |

### <a name="streamed-data"></a><span data-ttu-id="feddd-127">Strumienia danych</span><span class="sxs-lookup"><span data-stu-id="feddd-127">Streamed data</span></span>
<span data-ttu-id="feddd-128">Reprezentuje dane, które mogą być generowane przez różnych źródeł, takich jak aplikacje, urządzeń, czujników, itp. Te dane mogą pozyskanych do usługi Data Lake Store za pomocą różnych narzędzi.</span><span class="sxs-lookup"><span data-stu-id="feddd-128">This represents data that can be generated by various sources such as applications, devices, sensors, etc. This data can be ingested into a Data Lake Store by variety tools.</span></span> <span data-ttu-id="feddd-129">Te narzędzia zazwyczaj będzie przechwytywania i przetwarzania danych na podstawie zdarzeń przez zdarzenie w czasie rzeczywistym, a następnie wpisz zdarzeń w partiach do usługi Data Lake Store, aby mogą być dalej przetwarzane.</span><span class="sxs-lookup"><span data-stu-id="feddd-129">These tools will usually capture and process the data on an event-by-event basis in real-time, and then write the events in batches into Data Lake Store so that they can be further processed.</span></span>

<span data-ttu-id="feddd-130">Poniżej przedstawiono narzędzia, których można użyć:</span><span class="sxs-lookup"><span data-stu-id="feddd-130">Following are tools that you can use:</span></span>

* <span data-ttu-id="feddd-131">[Usługa Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md) -zdarzeń pozyskanych w usłudze Event Hubs można zapisać usługi Azure Data Lake za pomocą usługi Azure Data Lake Store danych wyjściowych.</span><span class="sxs-lookup"><span data-stu-id="feddd-131">[Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md) - Events ingested into Event Hubs can be written to Azure Data Lake using an Azure Data Lake Store output.</span></span>
* <span data-ttu-id="feddd-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) — możesz zapisać dane bezpośrednio do usługi Data Lake Store z klastra Storm.</span><span class="sxs-lookup"><span data-stu-id="feddd-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) - You can write data directly to Data Lake Store from the Storm cluster.</span></span>
* <span data-ttu-id="feddd-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) — można odbieranie zdarzeń z usługi Event Hubs i zapisać go do usługi Data Lake Store za pomocą [zestawu SDK .NET Data Lake Store](data-lake-store-get-started-net-sdk.md).</span><span class="sxs-lookup"><span data-stu-id="feddd-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – You can receive events from Event Hubs and then write it to Data Lake Store using the [Data Lake Store .NET SDK](data-lake-store-get-started-net-sdk.md).</span></span>

### <a name="relational-data"></a><span data-ttu-id="feddd-134">Danych relacyjnych</span><span class="sxs-lookup"><span data-stu-id="feddd-134">Relational data</span></span>
<span data-ttu-id="feddd-135">Może również pobierać dane z relacyjnej bazy danych.</span><span class="sxs-lookup"><span data-stu-id="feddd-135">You can also source data from relational databases.</span></span> <span data-ttu-id="feddd-136">W danym okresie czasu relacyjnych baz danych, Zbierz dużych ilości danych, które zapewniają wgląd klucza przetwarzanie przez potok danych big data.</span><span class="sxs-lookup"><span data-stu-id="feddd-136">Over a period of time, relational databases collect huge amounts of data which can provide key insights if processed through a big data pipeline.</span></span> <span data-ttu-id="feddd-137">Aby przenieść tych danych do usługi Data Lake Store, można użyć następujących narzędzi.</span><span class="sxs-lookup"><span data-stu-id="feddd-137">You can use the following tools to move such data into Data Lake Store.</span></span>

* [<span data-ttu-id="feddd-138">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="feddd-138">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="feddd-139">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="feddd-139">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

### <a name="web-server-log-data-upload-using-custom-applications"></a><span data-ttu-id="feddd-140">Dane dziennika serwera sieci Web (przy użyciu niestandardowych aplikacji przekazywania)</span><span class="sxs-lookup"><span data-stu-id="feddd-140">Web server log data (upload using custom applications)</span></span>
<span data-ttu-id="feddd-141">Tego typu dataset jest zwrócono szczególną uwagę, ponieważ analizy danych dziennika serwera sieci web jest przypadek użycia typowe dla danych big data aplikacji i wymaga dużych woluminów, plików dziennika do przekazania do usługi Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="feddd-141">This type of dataset is specifically called out because analysis of web server log data is a common use case for big data applications and requires large volumes of log files to be uploaded to the Data Lake Store.</span></span> <span data-ttu-id="feddd-142">Żadnego z następujących narzędzi umożliwia pisanie własnych skryptów lub aplikacji na przekazywanie tych danych.</span><span class="sxs-lookup"><span data-stu-id="feddd-142">You can use any of the following tools to write your own scripts or applications to upload such data.</span></span>

* [<span data-ttu-id="feddd-143">Azure CLI wieloplatformowych 2.0</span><span class="sxs-lookup"><span data-stu-id="feddd-143">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="feddd-144">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="feddd-144">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="feddd-145">Zestaw .NET SDK usługi Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="feddd-145">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="feddd-146">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="feddd-146">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

<span data-ttu-id="feddd-147">Do przekazywania danych dziennika serwera sieci web, a także do przekazywania innych typów danych (np. społecznościowych opinie) jest sposobem zapisać własnych skryptów niestandardowych/aplikacji, ponieważ zapewnia elastyczność do dołączenia danych przekazywania większych aplikacji danych big data w ramach składnika.</span><span class="sxs-lookup"><span data-stu-id="feddd-147">For uploading web server log data, and also for uploading other kinds of data (e.g. social sentiments data), it is a good approach to write your own custom scripts/applications because it gives you the flexibility to include your data uploading component as part of your larger big data application.</span></span> <span data-ttu-id="feddd-148">W niektórych przypadkach ten kod może mieć postać skryptu lub narzędzia wiersza polecenia proste.</span><span class="sxs-lookup"><span data-stu-id="feddd-148">In some cases this code may take the form of a script or simple command line utility.</span></span> <span data-ttu-id="feddd-149">W innych przypadkach kod może być używany do przetwarzania danych big integracji aplikacji biznesowej lub rozwiązania.</span><span class="sxs-lookup"><span data-stu-id="feddd-149">In other cases, the code may be used to integrate big data processing into a business application or solution.</span></span>

### <a name="data-associated-with-azure-hdinsight-clusters"></a><span data-ttu-id="feddd-150">Dane skojarzone z klastrami Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="feddd-150">Data associated with Azure HDInsight clusters</span></span>
<span data-ttu-id="feddd-151">Większość typów klastra usługi HDInsight (Hadoop, HBase, Storm) obsługuje usługi Data Lake Store jako repozytorium magazynu danych.</span><span class="sxs-lookup"><span data-stu-id="feddd-151">Most HDInsight cluster types (Hadoop, HBase, Storm) support Data Lake Store as a data storage repository.</span></span> <span data-ttu-id="feddd-152">Klastry HDInsight dostęp do danych z usługi Azure blob Storage (WASB).</span><span class="sxs-lookup"><span data-stu-id="feddd-152">HDInsight clusters access data from Azure Storage Blobs (WASB).</span></span> <span data-ttu-id="feddd-153">W celu poprawy wydajności można skopiować danych z WASB do konta usługi Data Lake Store skojarzony z klastrem.</span><span class="sxs-lookup"><span data-stu-id="feddd-153">For better performance, you can copy the data from WASB into a Data Lake Store account associated with the cluster.</span></span> <span data-ttu-id="feddd-154">Aby skopiować dane, można użyć następujących narzędzi.</span><span class="sxs-lookup"><span data-stu-id="feddd-154">You can use the following tools to copy the data.</span></span>

* [<span data-ttu-id="feddd-155">Narzędzia DistCp Apache</span><span class="sxs-lookup"><span data-stu-id="feddd-155">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)
* [<span data-ttu-id="feddd-156">Usługa AdlCopy</span><span class="sxs-lookup"><span data-stu-id="feddd-156">AdlCopy Service</span></span>](data-lake-store-copy-data-azure-storage-blob.md)
* [<span data-ttu-id="feddd-157">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="feddd-157">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)

### <a name="data-stored-in-on-premises-or-iaas-hadoop-clusters"></a><span data-ttu-id="feddd-158">Dane przechowywane w lokalnych lub IaaS Hadoop klastrów</span><span class="sxs-lookup"><span data-stu-id="feddd-158">Data stored in on-premises or IaaS Hadoop clusters</span></span>
<span data-ttu-id="feddd-159">Duże ilości danych może być przechowywany w istniejących klastrów platformy Hadoop, lokalnie na komputerach przy użyciu systemu plików HDFS.</span><span class="sxs-lookup"><span data-stu-id="feddd-159">Large amounts of data may be stored in existing Hadoop clusters, locally on machines using HDFS.</span></span> <span data-ttu-id="feddd-160">Klastry Hadoop może być we wdrożeniu lokalnymi lub może być w klastrze IaaS na platformie Azure.</span><span class="sxs-lookup"><span data-stu-id="feddd-160">The Hadoop clusters may be in an on-premises deployment or may be within an IaaS cluster on Azure.</span></span> <span data-ttu-id="feddd-161">Może to być wymagania, aby skopiować tych danych do usługi Azure Data Lake Store podejścia jednorazowe lub w sposób cykliczny.</span><span class="sxs-lookup"><span data-stu-id="feddd-161">There could be requirements to copy such data to Azure Data Lake Store for a one-off approach or in a recurring fashion.</span></span> <span data-ttu-id="feddd-162">Istnieją różne opcje, których można to osiągnąć.</span><span class="sxs-lookup"><span data-stu-id="feddd-162">There are various options that you can use to achieve this.</span></span> <span data-ttu-id="feddd-163">Poniżej znajduje się lista alternatyw i skojarzone kompromis.</span><span class="sxs-lookup"><span data-stu-id="feddd-163">Below is a list of alternatives and the associated trade-offs.</span></span>

| <span data-ttu-id="feddd-164">Podejście</span><span class="sxs-lookup"><span data-stu-id="feddd-164">Approach</span></span> | <span data-ttu-id="feddd-165">Szczegóły</span><span class="sxs-lookup"><span data-stu-id="feddd-165">Details</span></span> | <span data-ttu-id="feddd-166">Zalety</span><span class="sxs-lookup"><span data-stu-id="feddd-166">Advantages</span></span> | <span data-ttu-id="feddd-167">Zagadnienia do rozważenia</span><span class="sxs-lookup"><span data-stu-id="feddd-167">Considerations</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="feddd-168">Kopiuj dane bezpośrednio z klastrów platformy Hadoop do usługi Azure Data Lake Store za pomocą fabryki danych Azure (ADF)</span><span class="sxs-lookup"><span data-stu-id="feddd-168">Use Azure Data Factory (ADF) to copy data directly from Hadoop clusters to Azure Data Lake Store</span></span> |[<span data-ttu-id="feddd-169">ADF obsługuje system plików HDFS jako źródła danych</span><span class="sxs-lookup"><span data-stu-id="feddd-169">ADF supports HDFS as a data source</span></span>](../data-factory/data-factory-hdfs-connector.md) |<span data-ttu-id="feddd-170">ADF obsługuje system plików HDFS i pierwszej klasy end-to-end zarządzania i monitorowania poza pole</span><span class="sxs-lookup"><span data-stu-id="feddd-170">ADF provides out-of-the-box support for HDFS and first class end-to-end management and monitoring</span></span> |<span data-ttu-id="feddd-171">Wymaga brama zarządzania danymi jest wdrożony na lokalnym lub w IaaS klastra</span><span class="sxs-lookup"><span data-stu-id="feddd-171">Requires Data Management Gateway to be deployed on-premises or in the IaaS cluster</span></span> |
| <span data-ttu-id="feddd-172">Eksportowanie danych z usługi Hadoop jako plików.</span><span class="sxs-lookup"><span data-stu-id="feddd-172">Export data from Hadoop as files.</span></span> <span data-ttu-id="feddd-173">Następnie skopiuj pliki do usługi Azure Data Lake Store przy użyciu mechanizmu odpowiednie.</span><span class="sxs-lookup"><span data-stu-id="feddd-173">Then copy the files to Azure Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="feddd-174">Możesz skopiować pliki przy użyciu usługi Azure Data Lake Store:</span><span class="sxs-lookup"><span data-stu-id="feddd-174">You can copy files to Azure Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="feddd-175">Program Azure PowerShell dla systemu operacyjnego Windows</span><span class="sxs-lookup"><span data-stu-id="feddd-175">Azure PowerShell for Windows OS</span></span>](data-lake-store-get-started-powershell.md)</li><li>[<span data-ttu-id="feddd-176">Azure CLI wieloplatformowych 2.0 OS z systemem innym niż Windows</span><span class="sxs-lookup"><span data-stu-id="feddd-176">Azure Cross-platform CLI 2.0 for non-Windows OS</span></span>](data-lake-store-get-started-cli-2.0.md)</li><li><span data-ttu-id="feddd-177">Niestandardowych aplikacji przy użyciu zestawu SDK wszelkich Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="feddd-177">Custom app using any Data Lake Store SDK</span></span></li></ul> |<span data-ttu-id="feddd-178">Szybko rozpocząć pracę.</span><span class="sxs-lookup"><span data-stu-id="feddd-178">Quick to get started.</span></span> <span data-ttu-id="feddd-179">Możliwość przekazywania dostosowane</span><span class="sxs-lookup"><span data-stu-id="feddd-179">Can do customized uploads</span></span> |<span data-ttu-id="feddd-180">Proces wieloetapowych, która obejmuje wiele technologii.</span><span class="sxs-lookup"><span data-stu-id="feddd-180">Multi-step process that involves multiple technologies.</span></span> <span data-ttu-id="feddd-181">Zarządzanie i monitorowanie wzrośnie stanowić nie lada wyzwanie wraz z upływem czasu charakter niestandardowych narzędzi</span><span class="sxs-lookup"><span data-stu-id="feddd-181">Management and monitoring will grow to be a challenge over time given the customized nature of the tools</span></span> |
| <span data-ttu-id="feddd-182">Aby skopiować dane z usługi Hadoop do usługi Azure Storage za pomocą narzędzia Distcp.</span><span class="sxs-lookup"><span data-stu-id="feddd-182">Use Distcp to copy data from Hadoop to Azure Storage.</span></span> <span data-ttu-id="feddd-183">Następnie skopiuj dane z usługi Magazyn Azure Data Lake Store przy użyciu mechanizmu odpowiednie.</span><span class="sxs-lookup"><span data-stu-id="feddd-183">Then copy data from Azure Storage to Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="feddd-184">Można skopiować danych z magazynu Azure do usługi Data Lake Store za pomocą:</span><span class="sxs-lookup"><span data-stu-id="feddd-184">You can copy data from Azure Storage to Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="feddd-185">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="feddd-185">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)</li><li>[<span data-ttu-id="feddd-186">Narzędzie AdlCopy</span><span class="sxs-lookup"><span data-stu-id="feddd-186">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="feddd-187">Narzędzia DistCp Apache uruchamianych w klastrach usługi HDInsight</span><span class="sxs-lookup"><span data-stu-id="feddd-187">Apache DistCp running on HDInsight clusters</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li></ul> |<span data-ttu-id="feddd-188">Można użyć narzędzia open source.</span><span class="sxs-lookup"><span data-stu-id="feddd-188">You can use open-source tools.</span></span> |<span data-ttu-id="feddd-189">Proces wieloetapowych, który obejmuje wiele technologii</span><span class="sxs-lookup"><span data-stu-id="feddd-189">Multi-step process that involves multiple technologies</span></span> |

### <a name="really-large-datasets"></a><span data-ttu-id="feddd-190">Naprawdę dużych zestawów danych</span><span class="sxs-lookup"><span data-stu-id="feddd-190">Really large datasets</span></span>
<span data-ttu-id="feddd-191">Do przekazywania zestawów danych w wielu terabajtów, za pomocą metod opisanych wyżej może być czasem powolne i kosztowne.</span><span class="sxs-lookup"><span data-stu-id="feddd-191">For uploading datasets that range in several terabytes, using the methods described above can sometimes be slow and costly.</span></span> <span data-ttu-id="feddd-192">W takich przypadkach można użyć poniższych opcji.</span><span class="sxs-lookup"><span data-stu-id="feddd-192">In such cases, you can use the options below.</span></span>

* <span data-ttu-id="feddd-193">**Za pomocą usługi Azure ExpressRoute**.</span><span class="sxs-lookup"><span data-stu-id="feddd-193">**Using Azure ExpressRoute**.</span></span> <span data-ttu-id="feddd-194">Usługa Azure ExpressRoute umożliwia tworzenie prywatnych połączeń między centrach danych platformy Azure i infrastruktury lokalnie.</span><span class="sxs-lookup"><span data-stu-id="feddd-194">Azure ExpressRoute lets you create private connections between Azure datacenters and infrastructure on your premises.</span></span> <span data-ttu-id="feddd-195">To zapewnia niezawodne opcję transferowania dużych ilości danych.</span><span class="sxs-lookup"><span data-stu-id="feddd-195">This provides a reliable option for transferring large amounts of data.</span></span> <span data-ttu-id="feddd-196">Aby uzyskać więcej informacji, zobacz [dokumentacja usługi Azure ExpressRoute](../expressroute/expressroute-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="feddd-196">For more information, see [Azure ExpressRoute documentation](../expressroute/expressroute-introduction.md).</span></span>
* <span data-ttu-id="feddd-197">**"Offline" przekazywanie danych**.</span><span class="sxs-lookup"><span data-stu-id="feddd-197">**"Offline" upload of data**.</span></span> <span data-ttu-id="feddd-198">Jeśli przy użyciu usługi Azure ExpressRoute nie jest jakiegokolwiek powodu możliwe, można użyć [usługi Import/Eksport Azure](../storage/common/storage-import-export-service.md) na potrzeby wysłania dysków twardych z danymi umieszczanymi w centrum danych Azure.</span><span class="sxs-lookup"><span data-stu-id="feddd-198">If using Azure ExpressRoute is not feasible for any reason, you can use [Azure Import/Export service](../storage/common/storage-import-export-service.md) to ship hard disk drives with your data to an Azure data center.</span></span> <span data-ttu-id="feddd-199">Dane najpierw zostało załadowane na obiektach blob magazynu Azure.</span><span class="sxs-lookup"><span data-stu-id="feddd-199">Your data is first uploaded to Azure Storage Blobs.</span></span> <span data-ttu-id="feddd-200">Następnie można użyć [fabryki danych Azure](../data-factory/data-factory-azure-datalake-connector.md) lub [AdlCopy narzędzia](data-lake-store-copy-data-azure-storage-blob.md) można skopiować danych z obiektów blob magazynu Azure do usługi Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="feddd-200">You can then use [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) or [AdlCopy tool](data-lake-store-copy-data-azure-storage-blob.md) to copy data from Azure Storage Blobs to Data Lake Store.</span></span>

  > [!NOTE]
  > <span data-ttu-id="feddd-201">Podczas używania usługi Import/Eksport rozmiary plików na dyskach, które są dostarczane do centrum danych Azure nie powinna być większa niż 195 GB.</span><span class="sxs-lookup"><span data-stu-id="feddd-201">While using the Import/Export service, the file sizes on the disks that you ship to Azure data center should not be greater than 195 GB.</span></span>
  >
  >

## <a name="process-data-stored-in-data-lake-store"></a><span data-ttu-id="feddd-202">Przetwarzaj dane przechowywane w usłudze Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="feddd-202">Process data stored in Data Lake Store</span></span>
<span data-ttu-id="feddd-203">Gdy dane są dostępne w usłudze Data Lake Store można uruchomić analizy danych za pomocą aplikacji obsługiwanych danych big data.</span><span class="sxs-lookup"><span data-stu-id="feddd-203">Once the data is available in Data Lake Store you can run analysis on that data using the supported big data applications.</span></span> <span data-ttu-id="feddd-204">Do uruchomienia zadań analizy danych na dane przechowywane w usłudze Data Lake Store można obecnie używać Azure HDInsight i usługą Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="feddd-204">Currently, you can use Azure HDInsight and Azure Data Lake Analytics to run data analysis jobs on the data stored in Data Lake Store.</span></span>

<span data-ttu-id="feddd-205">![Analizowanie danych w usłudze Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "analizowanie danych w usłudze Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="feddd-205">![Analyze data in Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Analyze data in Data Lake Store")</span></span>

<span data-ttu-id="feddd-206">Można przyjrzeć się następujące przykłady.</span><span class="sxs-lookup"><span data-stu-id="feddd-206">You can look at the following examples.</span></span>

* [<span data-ttu-id="feddd-207">Tworzenie klastra usługi HDInsight z usługą Data Lake Store jako magazyn</span><span class="sxs-lookup"><span data-stu-id="feddd-207">Create an HDInsight cluster with Data Lake Store as storage</span></span>](data-lake-store-hdinsight-hadoop-use-portal.md)
* [<span data-ttu-id="feddd-208">Korzystanie z usługi Azure Data Lake Analytics z usługą Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="feddd-208">Use Azure Data Lake Analytics with Data Lake Store</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)

## <a name="download-data-from-data-lake-store"></a><span data-ttu-id="feddd-209">Pobierz dane z usługi Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="feddd-209">Download data from Data Lake Store</span></span>
<span data-ttu-id="feddd-210">Można również pobrać lub przenieść dane z usługi Azure Data Lake Store w scenariuszach, takich jak:</span><span class="sxs-lookup"><span data-stu-id="feddd-210">You might also want to download or move data from Azure Data Lake Store for scenarios such as:</span></span>

* <span data-ttu-id="feddd-211">Przenoszenie danych do innych repozytoria do interfejsu z Twoje istniejące potoków przetwarzania danych.</span><span class="sxs-lookup"><span data-stu-id="feddd-211">Move data to other repositories to interface with your existing data processing pipelines.</span></span> <span data-ttu-id="feddd-212">Na przykład można przenieść dane z usługi Data Lake Store do bazy danych SQL Azure lub lokalnego programu SQL Server.</span><span class="sxs-lookup"><span data-stu-id="feddd-212">For example, you might want to move data from Data Lake Store to Azure SQL Database or on-premises SQL Server.</span></span>
* <span data-ttu-id="feddd-213">Pobierz dane na komputerze lokalnym do przetwarzania w środowisku IDE podczas kompilowania aplikacji prototypów.</span><span class="sxs-lookup"><span data-stu-id="feddd-213">Download data to your local computer for processing in IDE environments while building application prototypes.</span></span>

<span data-ttu-id="feddd-214">![Wyjściowych danych z usługi Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "wyjściowych danych z usługi Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="feddd-214">![Egress data from Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Egress data from Data Lake Store")</span></span>

<span data-ttu-id="feddd-215">W takich przypadkach można użyć dowolnego z następujących opcji:</span><span class="sxs-lookup"><span data-stu-id="feddd-215">In such cases, you can use any of the following options:</span></span>

* [<span data-ttu-id="feddd-216">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="feddd-216">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="feddd-217">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="feddd-217">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)
* [<span data-ttu-id="feddd-218">Narzędzia DistCp Apache</span><span class="sxs-lookup"><span data-stu-id="feddd-218">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)

<span data-ttu-id="feddd-219">Następujące metody umożliwia również napisać własny skrypt/aplikację w celu pobierania danych z usługi Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="feddd-219">You can also use the following methods to write your own script/application to download data from Data Lake Store.</span></span>

* [<span data-ttu-id="feddd-220">Azure CLI wieloplatformowych 2.0</span><span class="sxs-lookup"><span data-stu-id="feddd-220">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="feddd-221">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="feddd-221">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="feddd-222">Zestaw .NET SDK usługi Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="feddd-222">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)

## <a name="visualize-data-in-data-lake-store"></a><span data-ttu-id="feddd-223">Wizualizuj dane w usłudze Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="feddd-223">Visualize data in Data Lake Store</span></span>
<span data-ttu-id="feddd-224">Kombinacja usługi służy do tworzenia wizualnej reprezentacji danych przechowywanych w usłudze Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="feddd-224">You can use a mix of services to create visual representations of data stored in Data Lake Store.</span></span>

<span data-ttu-id="feddd-225">![Wizualizuj dane w usłudze Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "wizualizacji danych w usłudze Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="feddd-225">![Visualize data in Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualize data in Data Lake Store")</span></span>

* <span data-ttu-id="feddd-226">Można uruchomić przy użyciu [fabryki danych Azure, aby przenieść dane z usługi Data Lake Store do usługi Azure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span><span class="sxs-lookup"><span data-stu-id="feddd-226">You can start by using [Azure Data Factory to move data from Data Lake Store to Azure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span></span>
* <span data-ttu-id="feddd-227">Następnie można [integracji usługi Power BI z usługą Magazyn danych SQL Azure](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) utworzyć wizualną reprezentację danych.</span><span class="sxs-lookup"><span data-stu-id="feddd-227">After that, you can [integrate Power BI with Azure SQL Data Warehouse](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) to create visual representation of the data.</span></span>

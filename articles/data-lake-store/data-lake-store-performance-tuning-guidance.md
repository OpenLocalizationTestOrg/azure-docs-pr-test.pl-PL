---
title: "Dostosowywanie wskazówki dotyczące wydajności usługi Azure Data Lake Store | Dokumentacja firmy Microsoft"
description: "Dostosowywanie wskazówki dotyczące wydajności usługi Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: cgronlun
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 06/30/2017
ms.author: stewu
ms.openlocfilehash: e7ea83465328bd4c7479dec4093cd94700463854
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: pl-PL
ms.lasthandoff: 07/11/2017
---
# <a name="tuning-azure-data-lake-store-for-performance"></a><span data-ttu-id="bcbd1-103">Dostrajanie wydajności usługi Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="bcbd1-103">Tuning Azure Data Lake Store for performance</span></span>

<span data-ttu-id="bcbd1-104">Data Lake Store obsługuje wysokiej przepustowości dla analizy intensywne operacje We/Wy i przenoszenia danych.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-104">Data Lake Store supports high-throughput for I/O intensive analytics and data movement.</span></span>  <span data-ttu-id="bcbd1-105">W usłudze Azure Data Lake Store przy użyciu wszystkich dostępnych przepływności — ilość danych, które mogły być odczytywane i zapisywane na sekundę — ważne jest, aby uzyskać najlepszą wydajność.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-105">In Azure Data Lake Store, using all available throughput – the amount of data that can be read or written per second – is important to get the best performance.</span></span>  <span data-ttu-id="bcbd1-106">To jest osiągane, wykonując dowolną liczbę operacji odczytu i zapisu równoległe, jak to możliwe.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-106">This is achieved by performing as many reads and writes in parallel as possible.</span></span>

![Wydajność usługi Data Lake Store](./media/data-lake-store-performance-tuning-guidance/throughput.png)

<span data-ttu-id="bcbd1-108">Azure Data Lake Store można skalować, podaj przepływności niezbędne dla wszystkich scenariuszy analizy.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-108">Azure Data Lake Store can scale to provide the necessary throughput for all analytics scenario.</span></span> <span data-ttu-id="bcbd1-109">Domyślnie konto usługi Azure Data Lake Store zapewnia automatycznie za mało przepływności na potrzeby szerokiej kategorii przypadków użycia.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-109">By default, an Azure Data Lake Store account provides automatically enough throughput to meet the needs of a broad category of use cases.</span></span> <span data-ttu-id="bcbd1-110">W przypadkach, gdy klienci funkcjonowaniem domyślny limit można skonfigurować na koncie ADLS zapewnienie więcej przepustowości, kontaktując się z pomocą techniczną firmy Microsoft.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-110">For the cases where customers run into the default limit, the ADLS account can be configured to provide more throughput by contacting Microsoft support.</span></span>

## <a name="data-ingestion"></a><span data-ttu-id="bcbd1-111">Wprowadzanie danych</span><span class="sxs-lookup"><span data-stu-id="bcbd1-111">Data ingestion</span></span>

<span data-ttu-id="bcbd1-112">Podczas pobierania danych z systemu źródłowego do ADLS, należy wziąć pod uwagę, że sprzętu źródłowego, sprzęt sieciowy źródła i łączność sieciową ADLS może być wąskie gardło.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-112">When ingesting data from a source system to ADLS, it is important to consider that the source hardware, source network hardware, and network connectivity to ADLS can be the bottleneck.</span></span>  

![Wydajność usługi Data Lake Store](./media/data-lake-store-performance-tuning-guidance/bottleneck.png)

<span data-ttu-id="bcbd1-114">Jest ważne upewnić się, że ruch danych nie ma wpływu na te czynniki.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-114">It is important to ensure that the data movement is not affected by these factors.</span></span>

### <a name="source-hardware"></a><span data-ttu-id="bcbd1-115">Źródło sprzętu</span><span class="sxs-lookup"><span data-stu-id="bcbd1-115">Source Hardware</span></span>

<span data-ttu-id="bcbd1-116">Czy korzystasz z maszyny lokalnej lub maszyn wirtualnych na platformie Azure, należy wybrać uważnie odpowiedni sprzęt.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-116">Whether you are using on-premises machines or VMs in Azure, you should carefully select the appropriate hardware.</span></span> <span data-ttu-id="bcbd1-117">Sprzętu z dysku źródłowego wolą dysków SSD dyski twarde i wybierz sprzętu dysku z jednostkami szybsze.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-117">For Source Disk Hardware, prefer SSDs to HDDs and pick disk hardware with faster spindles.</span></span> <span data-ttu-id="bcbd1-118">Źródła sprzętu sieciowego należy używać jak najszybsze karty sieciowe.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-118">For Source Network Hardware, use the fastest NICs possible.</span></span>  <span data-ttu-id="bcbd1-119">Na platformie Azure firma Microsoft zaleca D14 maszynach wirtualnych platformy Azure, którym odpowiedniego zaawansowanym dysku i sprzęt sieciowy.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-119">On Azure, we recommend Azure D14 VMs which have the appropriately powerful disk and networking hardware.</span></span>

### <a name="network-connectivity-to-azure-data-lake-store"></a><span data-ttu-id="bcbd1-120">Połączenie sieciowe z usługi Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="bcbd1-120">Network Connectivity to Azure Data Lake Store</span></span>

<span data-ttu-id="bcbd1-121">Połączenie sieciowe między źródła danych i usługi Azure Data Lake store może być czasem wąskie gardło.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-121">The network connectivity between your source data and Azure Data Lake store can sometimes be the bottleneck.</span></span> <span data-ttu-id="bcbd1-122">Jeśli źródło danych działa lokalnie, należy rozważyć użycie dedykowanego łącza z [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span><span class="sxs-lookup"><span data-stu-id="bcbd1-122">When your source data is On-Premises, consider using a dedicated link with [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span></span> <span data-ttu-id="bcbd1-123">Jeśli źródło danych jest na platformie Azure, wydajność będzie najlepiej, gdy dane są tego samego regionu Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-123">If your source data is in Azure, the performance will be best when the data is in the same Azure region as the Data Lake Store.</span></span>

### <a name="configure-data-ingestion-tools-for-maximum-parallelization"></a><span data-ttu-id="bcbd1-124">Konfigurowanie narzędzia wprowadzanie danych do maksymalnego paralelizacja</span><span class="sxs-lookup"><span data-stu-id="bcbd1-124">Configure Data Ingestion tools for maximum parallelization</span></span>

<span data-ttu-id="bcbd1-125">Po usunąć sprzętu źródła i wąskich gardeł łączności powyżej sieci, możesz przystąpić do konfigurowania narzędziami wprowadzanie.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-125">Once you have addressed the source hardware and network connectivity bottlenecks above, you are ready to configure your ingestion tools.</span></span> <span data-ttu-id="bcbd1-126">Poniższa tabela zawiera podsumowanie ustawień klucza dla kilku popularnych wprowadzanie narzędzi oraz zapewnia szczegółowe wydajność dostrajanie artykułów dla nich.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-126">The following table summarizes the key settings for several popular ingestion tools and provides in-depth performance tuning articles for them.</span></span>  <span data-ttu-id="bcbd1-127">Aby dowiedzieć się więcej na temat które narzędzie do użycia na potrzeby danego scenariusza, odwiedź [artykułu](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span><span class="sxs-lookup"><span data-stu-id="bcbd1-127">To learn more about which tool to use for your scenario, visit this [article](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span></span>

| <span data-ttu-id="bcbd1-128">Narzędzie</span><span class="sxs-lookup"><span data-stu-id="bcbd1-128">Tool</span></span>               | <span data-ttu-id="bcbd1-129">Ustawienia</span><span class="sxs-lookup"><span data-stu-id="bcbd1-129">Settings</span></span>     | <span data-ttu-id="bcbd1-130">Więcej informacji</span><span class="sxs-lookup"><span data-stu-id="bcbd1-130">More Details</span></span>                                                                 |
|--------------------|------------------------------------------------------|------------------------------|
| <span data-ttu-id="bcbd1-131">PowerShell</span><span class="sxs-lookup"><span data-stu-id="bcbd1-131">Powershell</span></span>       | <span data-ttu-id="bcbd1-132">PerFileThreadCount, ConcurrentFileCount</span><span class="sxs-lookup"><span data-stu-id="bcbd1-132">PerFileThreadCount, ConcurrentFileCount</span></span> |  [<span data-ttu-id="bcbd1-133">Link</span><span class="sxs-lookup"><span data-stu-id="bcbd1-133">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-get-started-powershell#performance-guidance-while-using-powershell)   |
| <span data-ttu-id="bcbd1-134">AdlCopy</span><span class="sxs-lookup"><span data-stu-id="bcbd1-134">AdlCopy</span></span>    | <span data-ttu-id="bcbd1-135">Usługa Azure Data Lake Analytics jednostki</span><span class="sxs-lookup"><span data-stu-id="bcbd1-135">Azure Data Lake Analytics units</span></span>  |   [<span data-ttu-id="bcbd1-136">Link</span><span class="sxs-lookup"><span data-stu-id="bcbd1-136">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob#performance-considerations-for-using-adlcopy)         |
| <span data-ttu-id="bcbd1-137">Narzędzia DistCp</span><span class="sxs-lookup"><span data-stu-id="bcbd1-137">DistCp</span></span>            | <span data-ttu-id="bcbd1-138">-m (mapowanie)</span><span class="sxs-lookup"><span data-stu-id="bcbd1-138">-m (mapper)</span></span>   | [<span data-ttu-id="bcbd1-139">Link</span><span class="sxs-lookup"><span data-stu-id="bcbd1-139">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-wasb-distcp#performance-considerations-while-using-distcp)                             |
| <span data-ttu-id="bcbd1-140">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="bcbd1-140">Azure Data Factory</span></span>| <span data-ttu-id="bcbd1-141">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="bcbd1-141">parallelCopies</span></span>    | [<span data-ttu-id="bcbd1-142">Link</span><span class="sxs-lookup"><span data-stu-id="bcbd1-142">Link</span></span>](../data-factory/data-factory-copy-activity-performance.md)                          |
| <span data-ttu-id="bcbd1-143">Sqoop</span><span class="sxs-lookup"><span data-stu-id="bcbd1-143">Sqoop</span></span>           | <span data-ttu-id="bcbd1-144">FS.Azure.Block.size, -m (mapowanie)</span><span class="sxs-lookup"><span data-stu-id="bcbd1-144">fs.azure.block.size, -m (mapper)</span></span>    |   [<span data-ttu-id="bcbd1-145">Link</span><span class="sxs-lookup"><span data-stu-id="bcbd1-145">Link</span></span>](https://blogs.msdn.microsoft.com/bigdatasupport/2015/02/17/sqoop-job-performance-tuning-in-hdinsight-hadoop/)        |

## <a name="structure-your-data-set"></a><span data-ttu-id="bcbd1-146">Struktury zestawu danych</span><span class="sxs-lookup"><span data-stu-id="bcbd1-146">Structure your data set</span></span>

<span data-ttu-id="bcbd1-147">Gdy dane są przechowywane w usłudze Data Lake Store, rozmiar pliku, liczbę plików i struktury folderów będzie mieć wpływ na wydajność.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-147">When data is stored in Data Lake Store, the file size, number of files, and folder structure have an impact on performance.</span></span>  <span data-ttu-id="bcbd1-148">W poniższej sekcji opisano najlepsze rozwiązania w następujących obszarach.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-148">The following section describes best practices in these areas.</span></span>  

### <a name="file-size"></a><span data-ttu-id="bcbd1-149">Rozmiar pliku</span><span class="sxs-lookup"><span data-stu-id="bcbd1-149">File size</span></span>

<span data-ttu-id="bcbd1-150">Aparaty analizy, takie jak usługi HDInsight i usługą Azure Data Lake Analytics ma zwykle, obciążenie dla plików.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-150">Typically, analytics engines such as HDInsight and Azure Data Lake Analytics have a per-file overhead.</span></span>  <span data-ttu-id="bcbd1-151">Jeśli dane są przechowywane jako wiele małych plików, może to negatywnie wpłynąć na wydajność.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-151">If you store your data as many small files, this can negatively affect performance.</span></span>  

<span data-ttu-id="bcbd1-152">Ogólnie rzecz biorąc organizowania danych w większe pliki o rozmiarze w celu poprawy wydajności.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-152">In general, organize your data into larger sized files for better performance.</span></span>  <span data-ttu-id="bcbd1-153">Jako zasadą organizowanie zestawów danych w plikach 256MB lub większy.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-153">As a rule of thumb, organize data sets in files of 256MB or larger.</span></span> <span data-ttu-id="bcbd1-154">W niektórych przypadkach, takich jak obrazy i danych binarnych nie jest możliwe do ich przetworzenia równolegle.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-154">In some cases such as images and binary data, it is not possible to process them in parallel.</span></span>  <span data-ttu-id="bcbd1-155">W takich przypadkach zaleca się zachowanie poszczególnych plików mniej niż 2GB.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-155">In these cases, it is recommended to keep individual files under 2GB.</span></span>

<span data-ttu-id="bcbd1-156">Czasami potoki danych mają ograniczoną kontrolę nad nieprzetworzone dane, które zawiera wiele małych plików.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-156">Sometimes, data pipelines have limited control over the raw data which has lots of small files.</span></span>  <span data-ttu-id="bcbd1-157">Zalecane jest "gotowania" procesu, który generuje większe pliki służące do podrzędnych aplikacji.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-157">It is recommended to have a “cooking” process that generates larger files to use for downstream applications.</span></span>  

### <a name="organizing-time-series-data-in-folders"></a><span data-ttu-id="bcbd1-158">Organizowanie danych szeregów czasowych w folderach</span><span class="sxs-lookup"><span data-stu-id="bcbd1-158">Organizing Time Series data in folders</span></span>

<span data-ttu-id="bcbd1-159">W przypadku obciążeń Hive i ADLA partycji oczyszczania danych szeregu czasowego może pomóc niektórych kwerend odczytać tylko podzestaw danych, co zwiększa wydajność.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-159">For Hive and ADLA workloads, partition pruning of time-series data can help some queries read only a subset of the data which improves performance.</span></span>    

<span data-ttu-id="bcbd1-160">Potoki, które pozyskiwania danych szeregu czasowego, często umieść ich pliki z bardzo strukturalnych nazewnictwa plików i folderów.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-160">Those pipelines that ingest time-series data, often place their files with a very structured naming for files and folders.</span></span> <span data-ttu-id="bcbd1-161">Poniżej znajdują się bardzo typowym przykładem, który widzimy dla danych, które mają strukturę według daty:</span><span class="sxs-lookup"><span data-stu-id="bcbd1-161">Below is a very common example we see for data that is structured by date:</span></span>

    \DataSet\YYYY\MM\DD\datafile_YYYY_MM_DD.tsv

<span data-ttu-id="bcbd1-162">Należy zauważyć, że informacje daty i godziny są wyświetlane folderów oraz w nazwie pliku.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-162">Notice that the datetime information appears both as folders and in the filename.</span></span>

<span data-ttu-id="bcbd1-163">Daty i godziny Oto wspólnego wzorca</span><span class="sxs-lookup"><span data-stu-id="bcbd1-163">For date and time, the following is a common pattern</span></span>

    \DataSet\YYYY\MM\DD\HH\mm\datafile_YYYY_MM_DD_HH_mm.tsv

<span data-ttu-id="bcbd1-164">Ponownie wybór za pomocą folderu i pliku organizacji powinien optymalizować większych plików i uzasadnione liczba plików w każdym folderze.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-164">Again, the choice you make with the folder and file organization should optimize for the larger file sizes and a reasonable number of files in each folder.</span></span>

## <a name="optimizing-io-intensive-jobs-on-hadoop-and-spark-workloads-on-hdinsight"></a><span data-ttu-id="bcbd1-165">Optymalizacja znacznym zadania we/wy na obciążenie Hadoop i Spark w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcbd1-165">Optimizing I/O intensive jobs on Hadoop and Spark workloads on HDInsight</span></span>

<span data-ttu-id="bcbd1-166">Zadania można podzielić na następujące trzy kategorie:</span><span class="sxs-lookup"><span data-stu-id="bcbd1-166">Jobs fall into one of the following three categories:</span></span>

* <span data-ttu-id="bcbd1-167">**Procesora CPU.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-167">**CPU intensive.**</span></span>  <span data-ttu-id="bcbd1-168">Te zadania mają obliczeń długie czasy wraz z minimalnym czasem we/wy.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-168">These jobs have long computation times with minimal I/O times.</span></span>  <span data-ttu-id="bcbd1-169">Przykładami uczenie maszynowe i przetwarzania zadań języka naturalnego.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-169">Examples include machine learning and natural language processing jobs.</span></span>  
* <span data-ttu-id="bcbd1-170">**Pamięci.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-170">**Memory intensive.**</span></span>  <span data-ttu-id="bcbd1-171">Te zadania korzystają z dużej ilości pamięci.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-171">These jobs use lots of memory.</span></span>  <span data-ttu-id="bcbd1-172">Przykładami PageRank i zadania usługi analiza w czasie rzeczywistym.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-172">Examples include PageRank and real-time analytics jobs.</span></span>  
* <span data-ttu-id="bcbd1-173">**Operacji We/Wy.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-173">**I/O intensive.**</span></span>  <span data-ttu-id="bcbd1-174">Te zadania spędzają większość czasu wykonywania operacji We/Wy.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-174">These jobs spend most of their time doing I/O.</span></span>  <span data-ttu-id="bcbd1-175">Typowym przykładem jest zadanie kopiowania, które tylko do odczytu i zapisu.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-175">A common example is a copy job which does only read and write operations.</span></span>  <span data-ttu-id="bcbd1-176">Przykładami inne zadania przygotowywania danych, które dużą ilość danych do odczytu, przeprowadza niektórych transformacji danych, a następnie ponownie zapisuje dane do magazynu.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-176">Other examples include data preparation jobs that read a lot of data, performs some data transformation, and then writes the data back to the store.</span></span>  

<span data-ttu-id="bcbd1-177">Poniższe wskazówki ma zastosowanie tylko do zadań intensywne operacje We/Wy.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-177">The following guidance is only applicable to I/O intensive jobs.</span></span>

### <a name="general-considerations-for-an-hdinsight-cluster"></a><span data-ttu-id="bcbd1-178">Ogólne zagadnienia dotyczące klastra usługi HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcbd1-178">General Considerations for an HDInsight cluster</span></span>

* <span data-ttu-id="bcbd1-179">**Wersje usługi HDInsight.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-179">**HDInsight versions.**</span></span> <span data-ttu-id="bcbd1-180">Aby uzyskać najlepszą wydajność należy używać najnowszej wersji usługi HDInsight.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-180">For best performance, use the latest release of HDInsight.</span></span>
* <span data-ttu-id="bcbd1-181">**Regiony.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-181">**Regions.**</span></span> <span data-ttu-id="bcbd1-182">Umieść usługi Data Lake Store, w tym samym regionie co klaster usługi HDInsight.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-182">Place the Data Lake Store in the same region as the HDInsight cluster.</span></span>  

<span data-ttu-id="bcbd1-183">Klaster usługi HDInsight składa się z dwóch węzłów głównych i niektóre węzły procesów roboczych.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-183">An HDInsight cluster is composed of two head nodes and some worker nodes.</span></span> <span data-ttu-id="bcbd1-184">Każdego węzła procesu roboczego zawiera określonej liczby rdzeni i ilości pamięci, który jest określany przez typu maszyny Wirtualnej.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-184">Each worker node provides a specific number of cores and memory, which is determined by the VM-type.</span></span>  <span data-ttu-id="bcbd1-185">Podczas wykonywania zadania, YARN jest moduł negocjowania zasobów, przydzielanej dostępnej pamięci i rdzeni do utworzenia kontenerów.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-185">When running a job, YARN is the resource negotiator that allocates the available memory and cores to create containers.</span></span>  <span data-ttu-id="bcbd1-186">Każdy kontener uruchamia zadania wymagane do ukończenia zadania.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-186">Each container runs the tasks needed to complete the job.</span></span>  <span data-ttu-id="bcbd1-187">Równolegle kontenerów do szybkiego przetwarzania zadań.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-187">Containers run in parallel to process tasks quickly.</span></span> <span data-ttu-id="bcbd1-188">W związku z tym lepsza wydajność, uruchamiając dowolną liczbę kontenerów równoległych, jak to możliwe.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-188">Therefore, performance is improved by running as many parallel containers as possible.</span></span>

<span data-ttu-id="bcbd1-189">Istnieją trzy warstwy w ramach klastra usługi HDInsight, który można przedstawić aby zwiększyć liczbę kontenerów i używać wszystkich dostępnych przepływności.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-189">There are three layers within an HDInsight cluster that can be tuned to increase the number of containers and use all available throughput.</span></span>  

* <span data-ttu-id="bcbd1-190">**W warstwie fizycznej**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-190">**Physical layer**</span></span>
* <span data-ttu-id="bcbd1-191">**YARN warstwy**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-191">**YARN layer**</span></span>
* <span data-ttu-id="bcbd1-192">**Obciążenie warstwy**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-192">**Workload layer**</span></span>

### <a name="physical-layer"></a><span data-ttu-id="bcbd1-193">W warstwie fizycznej</span><span class="sxs-lookup"><span data-stu-id="bcbd1-193">Physical Layer</span></span>

<span data-ttu-id="bcbd1-194">**Uruchomienie klastra z więcej węzłów i/lub większy rozmiar maszyn wirtualnych.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-194">**Run cluster with more nodes and/or larger sized VMs.**</span></span>  <span data-ttu-id="bcbd1-195">Większego klastra umożliwi uruchomienie więcej kontenerów YARN, jak pokazano na rysunku poniżej.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-195">A larger cluster will enable you to run more YARN containers as shown in the picture below.</span></span>

![Wydajność usługi Data Lake Store](./media/data-lake-store-performance-tuning-guidance/VM.png)

<span data-ttu-id="bcbd1-197">**Użyj maszyn wirtualnych z większej przepustowości sieci.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-197">**Use VMs with more network bandwidth.**</span></span>  <span data-ttu-id="bcbd1-198">Przepustowość sieci może być wąskie gardło, jeśli istnieje mniej przepustowości sieci niż przepływności usługi Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-198">The amount of network bandwidth can be a bottleneck if there is less network bandwidth than Data Lake Store throughput.</span></span>  <span data-ttu-id="bcbd1-199">Różnych maszyn wirtualnych będą mieć różne rozmiary przepustowości sieci.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-199">Different VMs will have varying network bandwidth sizes.</span></span>  <span data-ttu-id="bcbd1-200">Wybierz maszyny Wirtualnej — typ, który ma największy przepustowości sieci.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-200">Choose a VM-type that has the largest possible network bandwidth.</span></span>

### <a name="yarn-layer"></a><span data-ttu-id="bcbd1-201">YARN warstwy</span><span class="sxs-lookup"><span data-stu-id="bcbd1-201">YARN Layer</span></span>

<span data-ttu-id="bcbd1-202">**Używanie mniejszych kontenerów YARN.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-202">**Use smaller YARN containers.**</span></span>  <span data-ttu-id="bcbd1-203">Zmniejsz rozmiar każdego kontenera YARN, aby utworzyć więcej kontenerów za pomocą tego samego ilość zasobów.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-203">Reduce the size of each YARN container to create more containers with the same amount of resources.</span></span>

![Wydajność usługi Data Lake Store](./media/data-lake-store-performance-tuning-guidance/small-containers.png)

<span data-ttu-id="bcbd1-205">W zależności od obciążenia będą zawsze miały minimalny rozmiar kontenera YARN, który jest wymagany.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-205">Depending on your workload, there will always be a minimum YARN container size that is needed.</span></span> <span data-ttu-id="bcbd1-206">W przypadku wybrania za mały kontener Twoje zadania będą uruchamiane w problemów braku pamięci.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-206">If you pick too small a container, your jobs will run into out-of-memory issues.</span></span> <span data-ttu-id="bcbd1-207">Zazwyczaj kontenerów YARN nie powinien być mniejszy niż 1GB.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-207">Typically YARN containers should be no smaller than 1GB.</span></span> <span data-ttu-id="bcbd1-208">Jest to częściej można zobaczyć kontenery YARN 3GB.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-208">It’s common to see 3GB YARN containers.</span></span> <span data-ttu-id="bcbd1-209">Dla niektórych zadań może być konieczne większe kontenery YARN.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-209">For some workloads, you may need larger YARN containers.</span></span>  

<span data-ttu-id="bcbd1-210">**Zwiększ rdzeni w jednym YARN kontenera.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-210">**Increase cores per YARN container.**</span></span>  <span data-ttu-id="bcbd1-211">Zwiększ liczbę rdzeni przydzielone do każdego kontenera, aby zwiększyć liczbę zadań uruchamianych w każdego kontenera.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-211">Increase the number of cores allocated to each container to increase the number of parallel tasks that run in each container.</span></span>  <span data-ttu-id="bcbd1-212">Działa to w przypadku aplikacji, takich jak Spark, których uruchamianie wielu zadań na kontenera.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-212">This works for applications like Spark which run multiple tasks per container.</span></span>  <span data-ttu-id="bcbd1-213">Dla aplikacji, takich jak Hive uruchamianych jednym wątku w poszczególnych kontenerach lepiej jest kontenery więcej niż większej liczby rdzeni na kontenera.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-213">For applications like Hive which run a single thread in each container, it is better to have more containers rather than more cores per container.</span></span>   

### <a name="workload-layer"></a><span data-ttu-id="bcbd1-214">Obciążenie warstwy</span><span class="sxs-lookup"><span data-stu-id="bcbd1-214">Workload Layer</span></span>

<span data-ttu-id="bcbd1-215">**Użyj wszystkich dostępnych kontenerów.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-215">**Use all available containers.**</span></span>  <span data-ttu-id="bcbd1-216">Ustaw liczbę zadań, jakie mają być równa lub większa niż liczba dostępnych kontenerów, tak aby wszystkie zasoby są wykorzystywane.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-216">Set the number of tasks to be equal or larger than the number of available containers so that all resources are utilized.</span></span>

![Wydajność usługi Data Lake Store](./media/data-lake-store-performance-tuning-guidance/use-containers.png)

<span data-ttu-id="bcbd1-218">**Zadania zakończone niepowodzeniem są kosztowne.**</span><span class="sxs-lookup"><span data-stu-id="bcbd1-218">**Failed tasks are costly.**</span></span> <span data-ttu-id="bcbd1-219">Jeśli każde zadanie ma dużą ilość danych do przetwarzania, następnie niepowodzenia zadania powoduje kosztowne ponów próbę.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-219">If each task has a large amount of data to process, then failure of a task results in an expensive retry.</span></span>  <span data-ttu-id="bcbd1-220">W związku z tym warto utworzyć więcej zadań, z których każdy przetwarza niewielką ilość danych.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-220">Therefore, it is better to create more tasks, each of which processes a small amount of data.</span></span>

<span data-ttu-id="bcbd1-221">Oprócz ogólne wytyczne powyżej każda aplikacja ma różnych parametry dostępne do dopasowywania dla tej konkretnej aplikacji.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-221">In addition to the general guidelines above, each application has different parameters available to tune for that specific application.</span></span> <span data-ttu-id="bcbd1-222">W poniższej tabeli przedstawiono niektóre z tych parametrów i łącza, aby zacząć korzystać z wydajności dostrajania dla każdej aplikacji.</span><span class="sxs-lookup"><span data-stu-id="bcbd1-222">The table below lists some of the parameters and links to get started with performance tuning for each application.</span></span>

| <span data-ttu-id="bcbd1-223">Obciążenie</span><span class="sxs-lookup"><span data-stu-id="bcbd1-223">Workload</span></span>               | <span data-ttu-id="bcbd1-224">Aby ustawić zadania</span><span class="sxs-lookup"><span data-stu-id="bcbd1-224">Parameter to set tasks</span></span>                                                         |
|--------------------|-------------------------------------------------------------------------------------|
| [<span data-ttu-id="bcbd1-225">Platforma Spark w HDInisight</span><span class="sxs-lookup"><span data-stu-id="bcbd1-225">Spark on HDInisight</span></span>](data-lake-store-performance-tuning-spark.md)       | <ul><li><span data-ttu-id="bcbd1-226">Liczba modułów</span><span class="sxs-lookup"><span data-stu-id="bcbd1-226">Num-executors</span></span></li><li><span data-ttu-id="bcbd1-227">Moduł wykonujący pamięci</span><span class="sxs-lookup"><span data-stu-id="bcbd1-227">Executor-memory</span></span></li><li><span data-ttu-id="bcbd1-228">Moduł wykonujący rdzeni</span><span class="sxs-lookup"><span data-stu-id="bcbd1-228">Executor-cores</span></span></li></ul> |
| [<span data-ttu-id="bcbd1-229">Hive w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcbd1-229">Hive on HDInsight</span></span>](data-lake-store-performance-tuning-hive.md)    | <ul><li><span data-ttu-id="bcbd1-230">hive.tez.container.size</span><span class="sxs-lookup"><span data-stu-id="bcbd1-230">hive.tez.container.size</span></span></li></ul>         |
| [<span data-ttu-id="bcbd1-231">MapReduce w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcbd1-231">MapReduce on HDInsight</span></span>](data-lake-store-performance-tuning-mapreduce.md)            | <ul><li><span data-ttu-id="bcbd1-232">mapreduce.map.Memory</span><span class="sxs-lookup"><span data-stu-id="bcbd1-232">Mapreduce.map.memory</span></span></li><li><span data-ttu-id="bcbd1-233">Mapreduce.job.Maps</span><span class="sxs-lookup"><span data-stu-id="bcbd1-233">Mapreduce.job.maps</span></span></li><li><span data-ttu-id="bcbd1-234">mapreduce.Reduce.Memory</span><span class="sxs-lookup"><span data-stu-id="bcbd1-234">Mapreduce.reduce.memory</span></span></li><li><span data-ttu-id="bcbd1-235">Mapreduce.job.reduces</span><span class="sxs-lookup"><span data-stu-id="bcbd1-235">Mapreduce.job.reduces</span></span></li></ul> |
| [<span data-ttu-id="bcbd1-236">STORM w usłudze HDInsight</span><span class="sxs-lookup"><span data-stu-id="bcbd1-236">Storm on HDInsight</span></span>](data-lake-store-performance-tuning-storm.md)| <ul><li><span data-ttu-id="bcbd1-237">Liczba procesów roboczych</span><span class="sxs-lookup"><span data-stu-id="bcbd1-237">Number of worker processes</span></span></li><li><span data-ttu-id="bcbd1-238">Liczba wystąpień Moduł wykonujący spout</span><span class="sxs-lookup"><span data-stu-id="bcbd1-238">Number of spout executor instances</span></span></li><li><span data-ttu-id="bcbd1-239">Liczba wystąpień Moduł wykonujący bolt</span><span class="sxs-lookup"><span data-stu-id="bcbd1-239">Number of bolt executor instances</span></span> </li><li><span data-ttu-id="bcbd1-240">Liczba zadań spout</span><span class="sxs-lookup"><span data-stu-id="bcbd1-240">Number of spout tasks</span></span></li><li><span data-ttu-id="bcbd1-241">Liczba zadań bolt</span><span class="sxs-lookup"><span data-stu-id="bcbd1-241">Number of bolt tasks</span></span></li></ul>|

## <a name="see-also"></a><span data-ttu-id="bcbd1-242">Zobacz też</span><span class="sxs-lookup"><span data-stu-id="bcbd1-242">See also</span></span>
* [<span data-ttu-id="bcbd1-243">Omówienie usługi Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="bcbd1-243">Overview of Azure Data Lake Store</span></span>](data-lake-store-overview.md)
* [<span data-ttu-id="bcbd1-244">Rozpoczynanie pracy z usługą Azure Data Lake Analytics</span><span class="sxs-lookup"><span data-stu-id="bcbd1-244">Get Started with Azure Data Lake Analytics</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)
